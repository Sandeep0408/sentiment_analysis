{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2RVzhLx3a8p1"
      },
      "source": [
        "# Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-z9lxskLzjW",
        "outputId": "a8e987c6-a098-4ac3-fe0c-5d09e697b11b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import stopwords\n",
        "from numpy import array\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from keras.preprocessing.text import one_hot, Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, GlobalMaxPooling1D, Embedding, Conv1D, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wm26T7UpbTHi"
      },
      "source": [
        "# Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3jmRPSVbQLA",
        "outputId": "6cb6f4cd-ff2f-45cb-9d72-73b52f733876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Amazon_Products.csv\")\n",
        "\n",
        "data.dropna(subset=['Body'], inplace=True)\n",
        "data.dropna(subset=['Title'], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "nNM6EFbkL6T8",
        "outputId": "2604889e-05dc-4e44-b4b6-839484d5c894"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-870dd1ec-a053-4d9d-bdba-c31926472a72\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ASIN</th>\n",
              "      <th>Product</th>\n",
              "      <th>Title</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Date</th>\n",
              "      <th>Body</th>\n",
              "      <th>Brand</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Text</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B0741D7LRD</td>\n",
              "      <td>Princess 182050 Digital air Fryer, Black</td>\n",
              "      <td>Great product</td>\n",
              "      <td>5</td>\n",
              "      <td>22 February 2020</td>\n",
              "      <td>This is a brilliant product...I'd had the Tefa...</td>\n",
              "      <td>Princess</td>\n",
              "      <td>positive</td>\n",
              "      <td>This is a brilliant product...I'd had the Tefa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B0741D7LRD</td>\n",
              "      <td>Princess 182050 Digital air Fryer, Black</td>\n",
              "      <td>I love mine, pity the non stick coating comes ...</td>\n",
              "      <td>1</td>\n",
              "      <td>25 June 2019</td>\n",
              "      <td>I love mine, pity the non stick coating comes ...</td>\n",
              "      <td>Princess</td>\n",
              "      <td>negative</td>\n",
              "      <td>I love mine, pity the non stick coating comes ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B0741D7LRD</td>\n",
              "      <td>Princess 182050 Digital air Fryer, Black</td>\n",
              "      <td>Digital programming broke down</td>\n",
              "      <td>1</td>\n",
              "      <td>21 March 2019</td>\n",
              "      <td>Thought this product would be great but had it...</td>\n",
              "      <td>Princess</td>\n",
              "      <td>negative</td>\n",
              "      <td>Thought this product would be great but had it...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B00P0V5IYW</td>\n",
              "      <td>Smartwares RM370 , Carbon Monoxide Alarm, 1 Ye...</td>\n",
              "      <td>Perfect</td>\n",
              "      <td>5</td>\n",
              "      <td>4 July 2022</td>\n",
              "      <td>This is my second one of these the 1st lasted ...</td>\n",
              "      <td>Smartwares</td>\n",
              "      <td>positive</td>\n",
              "      <td>This is my second one of these the 1st lasted ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B00P0V5IYW</td>\n",
              "      <td>Smartwares RM370 , Carbon Monoxide Alarm, 1 Ye...</td>\n",
              "      <td>Great item</td>\n",
              "      <td>5</td>\n",
              "      <td>22 February 2022</td>\n",
              "      <td>Great item</td>\n",
              "      <td>Smartwares</td>\n",
              "      <td>positive</td>\n",
              "      <td>Great itemGreat item</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-870dd1ec-a053-4d9d-bdba-c31926472a72')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-870dd1ec-a053-4d9d-bdba-c31926472a72 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-870dd1ec-a053-4d9d-bdba-c31926472a72');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         ASIN                                            Product  \\\n",
              "0  B0741D7LRD           Princess 182050 Digital air Fryer, Black   \n",
              "1  B0741D7LRD           Princess 182050 Digital air Fryer, Black   \n",
              "2  B0741D7LRD           Princess 182050 Digital air Fryer, Black   \n",
              "3  B00P0V5IYW  Smartwares RM370 , Carbon Monoxide Alarm, 1 Ye...   \n",
              "4  B00P0V5IYW  Smartwares RM370 , Carbon Monoxide Alarm, 1 Ye...   \n",
              "\n",
              "                                               Title  Rating  \\\n",
              "0                                      Great product       5   \n",
              "1  I love mine, pity the non stick coating comes ...       1   \n",
              "2                     Digital programming broke down       1   \n",
              "3                                            Perfect       5   \n",
              "4                                         Great item       5   \n",
              "\n",
              "               Date                                               Body  \\\n",
              "0  22 February 2020  This is a brilliant product...I'd had the Tefa...   \n",
              "1      25 June 2019  I love mine, pity the non stick coating comes ...   \n",
              "2     21 March 2019  Thought this product would be great but had it...   \n",
              "3       4 July 2022  This is my second one of these the 1st lasted ...   \n",
              "4  22 February 2022                                         Great item   \n",
              "\n",
              "        Brand Sentiment                                               Text  id  \n",
              "0    Princess  positive  This is a brilliant product...I'd had the Tefa...   0  \n",
              "1    Princess  negative  I love mine, pity the non stick coating comes ...   1  \n",
              "2    Princess  negative  Thought this product would be great but had it...   2  \n",
              "3  Smartwares  positive  This is my second one of these the 1st lasted ...   3  \n",
              "4  Smartwares  positive                               Great itemGreat item   4  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['Sentiment'] = data['Rating'].apply(lambda x: 'positive' if x >=3  else 'negative')\n",
        "data['Text'] = data['Body'] + data['Title']\n",
        "data['id'] = np.arange(data.shape[0])\n",
        "data.head(5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6zSwicviQvw-"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m79Yfha3MKfq",
        "outputId": "063d0dd9-e05e-4c87-8565-3b39f520c430"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isnull().values.any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "fEG0ke2eMYIe",
        "outputId": "caa24391-fb27-4b94-ca3d-41c5653c6760"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='Sentiment', ylabel='count'>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#distribution of positive / negative sentiments in dataset\n",
        "\n",
        "import seaborn as sns\n",
        "sns.countplot(x='Sentiment', data=data)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3X3PYSmRQ18g"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iDGeYobMavS"
      },
      "outputs": [],
      "source": [
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    '''Removes HTML tags: replaces anything between opening and closing <> with empty space'''\n",
        "\n",
        "    return TAG_RE.sub('', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxprSx01Mmr9"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(sen):\n",
        "    '''Cleans text data up, leaving only 2 or more char long non-stepwords composed of A-Z & a-z only\n",
        "    in lowercase'''\n",
        "    \n",
        "    sentence = sen.lower()\n",
        "\n",
        "    # Remove html tags\n",
        "    sentence = remove_tags(sentence)\n",
        "\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)  # When we remove apostrophe from the word \"Mark's\", the apostrophe is replaced by an empty space. Hence, we are left with single character \"s\" that we are removing here.\n",
        "\n",
        "    # Remove multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)  # Next, we remove all the single characters and replace it by a space which creates multiple spaces in our text. Finally, we remove the multiple spaces from our text as well.\n",
        "\n",
        "    # Remove Stopwords\n",
        "    #pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
        "    #sentence = pattern.sub('', sentence)\n",
        "\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvXo-EooFxPr"
      },
      "outputs": [],
      "source": [
        "# Calling preprocessing_text function on Amazon_reviews\n",
        "X = []\n",
        "sentences = list(data['Text'])\n",
        "for sen in sentences:\n",
        "    X.append(preprocess_text(sen))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNLBMrdGMozB"
      },
      "outputs": [],
      "source": [
        "\n",
        "y = data['Sentiment']\n",
        "\n",
        "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lcdFpUWwQ8OR"
      },
      "source": [
        "# Train-Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp43luJMNHK_",
        "outputId": "3ae5e73d-b25e-44c0-9a7c-71553e11766b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape 9694\n",
            "x_test shape 2424\n",
            "y_train shape 9694\n",
            "y_test shape 2424\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "print(\"x_train shape\",len(X_train))\n",
        "print(\"x_test shape\",len(X_test))\n",
        "print(\"y_train shape\",len(y_train))\n",
        "print(\"y_test shape\",len(y_test))\n",
        "\n",
        "# The train set will be used to train our deep learning models \n",
        "# while test set will be used to evaluate how well our model performs "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeYU0T0KNJBx"
      },
      "outputs": [],
      "source": [
        "# Embedding layer expects the words to be in numeric form \n",
        "# Using Tokenizer function from keras.preprocessing.text library\n",
        "# Method fit_on_text trains the tokenizer \n",
        "# Method texts_to_sequences converts sentences to their numeric form\n",
        "\n",
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = word_tokenizer.texts_to_sequences(X_train)\n",
        "X_test = word_tokenizer.texts_to_sequences(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZMh27EENlpx",
        "outputId": "e7e7c5a7-f57c-4441-e179-78bdb3a9e6e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9281"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Adding 1 to store dimensions for words for which no pretrained word embeddings exist\n",
        "\n",
        "vocab_length = len(word_tokenizer.word_index) + 1\n",
        "\n",
        "vocab_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KARTsE0iNpFM"
      },
      "outputs": [],
      "source": [
        "# Padding all reviews to fixed length 100\n",
        "\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ONjlZK9tRC3V"
      },
      "source": [
        "# Word Embeddings using GloVe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UACIDjNuNi8l"
      },
      "outputs": [],
      "source": [
        "# source: https://nlp.stanford.edu/projects/glove/\n",
        "# Load GloVe word embeddings and create an Embeddings Dictionary\n",
        "\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('/content/drive/MyDrive/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "glove_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W03YxH1ZNs3q"
      },
      "outputs": [],
      "source": [
        "# Create Embedding Matrix having 100 columns \n",
        "# Containing 100-dimensional GloVe word embeddings for all words in our corpus.\n",
        "\n",
        "embedding_matrix = zeros((vocab_length, 100))\n",
        "for word, index in word_tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrmXJw5LP9CX",
        "outputId": "60863fcf-1f3f-4e97-f507-76d0c16d2130"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9281, 100)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_f-XTDCPRJop"
      },
      "source": [
        "# Neural Network architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whBkjfx0aLbY"
      },
      "outputs": [],
      "source": [
        "lr = 5e-5\n",
        "optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "# Class weights\n",
        "class_weights = { # Newly added \n",
        "    0: 2.45, # Class 0 has the fewest samples, so we weight it higher\n",
        "    1: 0.63   # Class 1 has the most samples, so we weight it lower}\n",
        "}\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biLdNna9P-qJ"
      },
      "outputs": [],
      "source": [
        "# Neural Network architecture\n",
        "\n",
        "snn_model = Sequential()\n",
        "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "\n",
        "snn_model.add(embedding_layer)\n",
        "\n",
        "snn_model.add(Flatten())\n",
        "snn_model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3yuuQn2QEKm",
        "outputId": "8676030c-1cc0-4c64-ee39-4d3d854ad198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 100)          928100    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 10000)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 10001     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 938,101\n",
            "Trainable params: 10,001\n",
            "Non-trainable params: 928,100\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Model compiling\n",
        "\n",
        "snn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "print(snn_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkY1h6HEQGcf",
        "outputId": "c67f813a-eeb2-4780-e374-f87633776519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "61/61 [==============================] - 5s 6ms/step - loss: 0.5723 - acc: 0.7239 - val_loss: 0.5293 - val_acc: 0.7555\n",
            "Epoch 2/6\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.3996 - acc: 0.8548 - val_loss: 0.4375 - val_acc: 0.8221\n",
            "Epoch 3/6\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.3321 - acc: 0.8930 - val_loss: 0.3786 - val_acc: 0.8510\n",
            "Epoch 4/6\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.2880 - acc: 0.9090 - val_loss: 0.3087 - val_acc: 0.8917\n",
            "Epoch 5/6\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.2593 - acc: 0.9229 - val_loss: 0.2947 - val_acc: 0.8948\n",
            "Epoch 6/6\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.2369 - acc: 0.9317 - val_loss: 0.2892 - val_acc: 0.8963\n"
          ]
        }
      ],
      "source": [
        "# Model training\n",
        "\n",
        "snn_model_history = snn_model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2,class_weight=class_weights, callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5iM-twiQJhI",
        "outputId": "a60ac25d-ed46-4d01-94fb-c5ca5c417f9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "76/76 [==============================] - 0s 2ms/step - loss: 0.2883 - acc: 0.9022\n"
          ]
        }
      ],
      "source": [
        "# Predictions on the Test Set\n",
        "\n",
        "score = snn_model.evaluate(X_test, y_test, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nZK4EobQQE3",
        "outputId": "2de9f1a3-03df-41e6-f225-b7129d725f18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Score: 0.2883240282535553\n",
            "Test Accuracy: 0.9022276997566223\n"
          ]
        }
      ],
      "source": [
        "# Model Performance\n",
        "\n",
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "ahtMMqvuQWET",
        "outputId": "74338b9c-74e5-4146-cc1b-774e9532e885"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Model Performance Charts\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(snn_model_history.history['acc'])\n",
        "plt.plot(snn_model_history.history['val_acc'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(snn_model_history.history['loss'])\n",
        "plt.plot(snn_model_history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MNxMdOXuQere"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRNNGJwjQYk1"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Conv1D\n",
        "import keras\n",
        "import numpy as np\n",
        "np.random.seed(121)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_AxUDxxOt3H",
        "outputId": "2093b850-f9d1-401f-8f0a-7d7bb03a3823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6471 - acc: 0.5404 - val_loss: 0.6815 - val_acc: 0.5642\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.6431 - acc: 0.5720 - val_loss: 0.6762 - val_acc: 0.5792\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.6392 - acc: 0.5821 - val_loss: 0.6696 - val_acc: 0.6034\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6354 - acc: 0.6121 - val_loss: 0.6660 - val_acc: 0.6086\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6317 - acc: 0.6107 - val_loss: 0.6622 - val_acc: 0.6147\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6281 - acc: 0.6161 - val_loss: 0.6582 - val_acc: 0.6184\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.6246 - acc: 0.6313 - val_loss: 0.6536 - val_acc: 0.6271\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6212 - acc: 0.6326 - val_loss: 0.6502 - val_acc: 0.6318\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6178 - acc: 0.6475 - val_loss: 0.6459 - val_acc: 0.6441\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6145 - acc: 0.6554 - val_loss: 0.6416 - val_acc: 0.6534\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6114 - acc: 0.6575 - val_loss: 0.6395 - val_acc: 0.6555\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6083 - acc: 0.6687 - val_loss: 0.6339 - val_acc: 0.6627\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6052 - acc: 0.6750 - val_loss: 0.6317 - val_acc: 0.6679\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6022 - acc: 0.6796 - val_loss: 0.6279 - val_acc: 0.6751\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5993 - acc: 0.6900 - val_loss: 0.6256 - val_acc: 0.6782\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5965 - acc: 0.6923 - val_loss: 0.6220 - val_acc: 0.6823\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5937 - acc: 0.6970 - val_loss: 0.6190 - val_acc: 0.6818\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5909 - acc: 0.6919 - val_loss: 0.6153 - val_acc: 0.6880\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5882 - acc: 0.7079 - val_loss: 0.6112 - val_acc: 0.7035\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.5855 - acc: 0.7144 - val_loss: 0.6077 - val_acc: 0.7081\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5829 - acc: 0.7175 - val_loss: 0.6062 - val_acc: 0.7081\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5803 - acc: 0.7145 - val_loss: 0.6020 - val_acc: 0.7158\n",
            "With filter = 128, kernel_size = 8, layer_activation = sigmoid, dense_layer = 1, dense_activation = sigmoid, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 15ms/step - loss: 0.6865 - acc: 0.3114 - val_loss: 0.6964 - val_acc: 0.4590\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 0.6621 - acc: 0.5280 - val_loss: 0.6562 - val_acc: 0.6895\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 0.6419 - acc: 0.6137 - val_loss: 0.6431 - val_acc: 0.6885\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.6249 - acc: 0.6645 - val_loss: 0.6303 - val_acc: 0.6885\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 0.6100 - acc: 0.6927 - val_loss: 0.6147 - val_acc: 0.7060\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 0.5964 - acc: 0.7341 - val_loss: 0.6198 - val_acc: 0.6746\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.5841 - acc: 0.7140 - val_loss: 0.5905 - val_acc: 0.7308\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 0.5728 - acc: 0.7501 - val_loss: 0.5823 - val_acc: 0.7359\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.5620 - acc: 0.7603 - val_loss: 0.5678 - val_acc: 0.7597\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.5521 - acc: 0.7605 - val_loss: 0.5549 - val_acc: 0.7767\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 0.5429 - acc: 0.7711 - val_loss: 0.5458 - val_acc: 0.7803\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 0.5341 - acc: 0.7798 - val_loss: 0.5409 - val_acc: 0.7798\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.5259 - acc: 0.7798 - val_loss: 0.5238 - val_acc: 0.7973\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.5180 - acc: 0.7963 - val_loss: 0.5247 - val_acc: 0.7901\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.5105 - acc: 0.7903 - val_loss: 0.5141 - val_acc: 0.8014\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.5033 - acc: 0.7947 - val_loss: 0.4983 - val_acc: 0.8128\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4965 - acc: 0.8072 - val_loss: 0.4972 - val_acc: 0.8097\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4900 - acc: 0.8076 - val_loss: 0.4932 - val_acc: 0.8107\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4838 - acc: 0.8135 - val_loss: 0.4895 - val_acc: 0.8107\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4779 - acc: 0.8160 - val_loss: 0.4832 - val_acc: 0.8118\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4720 - acc: 0.8208 - val_loss: 0.4710 - val_acc: 0.8210\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4663 - acc: 0.8213 - val_loss: 0.4674 - val_acc: 0.8216\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4610 - acc: 0.8273 - val_loss: 0.4624 - val_acc: 0.8216\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4558 - acc: 0.8275 - val_loss: 0.4579 - val_acc: 0.8257\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4507 - acc: 0.8308 - val_loss: 0.4591 - val_acc: 0.8205\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4459 - acc: 0.8331 - val_loss: 0.4524 - val_acc: 0.8241\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4410 - acc: 0.8396 - val_loss: 0.4528 - val_acc: 0.8221\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4363 - acc: 0.8409 - val_loss: 0.4479 - val_acc: 0.8226\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4318 - acc: 0.8411 - val_loss: 0.4371 - val_acc: 0.8360\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4273 - acc: 0.8450 - val_loss: 0.4350 - val_acc: 0.8365\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4230 - acc: 0.8445 - val_loss: 0.4225 - val_acc: 0.8494\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4187 - acc: 0.8498 - val_loss: 0.4268 - val_acc: 0.8412\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4146 - acc: 0.8503 - val_loss: 0.4161 - val_acc: 0.8520\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4106 - acc: 0.8543 - val_loss: 0.4139 - val_acc: 0.8515\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4067 - acc: 0.8567 - val_loss: 0.4162 - val_acc: 0.8468\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4028 - acc: 0.8585 - val_loss: 0.4102 - val_acc: 0.8504\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3989 - acc: 0.8596 - val_loss: 0.4093 - val_acc: 0.8494\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3952 - acc: 0.8619 - val_loss: 0.4082 - val_acc: 0.8494\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3918 - acc: 0.8610 - val_loss: 0.3970 - val_acc: 0.8597\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3879 - acc: 0.8690 - val_loss: 0.4072 - val_acc: 0.8489\n",
            "With filter = 128, kernel_size = 8, layer_activation = sigmoid, dense_layer = 1, dense_activation = sigmoid, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 17ms/step - loss: 0.7617 - acc: 0.2049 - val_loss: 0.8321 - val_acc: 0.2114\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.7110 - acc: 0.2306 - val_loss: 0.7523 - val_acc: 0.2965\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6928 - acc: 0.3301 - val_loss: 0.7260 - val_acc: 0.4079\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6772 - acc: 0.4291 - val_loss: 0.7102 - val_acc: 0.4528\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6631 - acc: 0.5217 - val_loss: 0.6990 - val_acc: 0.4941\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6499 - acc: 0.5234 - val_loss: 0.6820 - val_acc: 0.5534\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6378 - acc: 0.5781 - val_loss: 0.6627 - val_acc: 0.6132\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6269 - acc: 0.6116 - val_loss: 0.6441 - val_acc: 0.6658\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6168 - acc: 0.6583 - val_loss: 0.6300 - val_acc: 0.6952\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6075 - acc: 0.6672 - val_loss: 0.6250 - val_acc: 0.6957\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5987 - acc: 0.7114 - val_loss: 0.6206 - val_acc: 0.6942\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5906 - acc: 0.7006 - val_loss: 0.6177 - val_acc: 0.6854\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5829 - acc: 0.7079 - val_loss: 0.6011 - val_acc: 0.7251\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.5755 - acc: 0.7106 - val_loss: 0.5928 - val_acc: 0.7375\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5687 - acc: 0.7398 - val_loss: 0.5862 - val_acc: 0.7421\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5617 - acc: 0.7368 - val_loss: 0.5749 - val_acc: 0.7550\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5552 - acc: 0.7523 - val_loss: 0.5759 - val_acc: 0.7478\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5490 - acc: 0.7482 - val_loss: 0.5670 - val_acc: 0.7571\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5430 - acc: 0.7497 - val_loss: 0.5589 - val_acc: 0.7643\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.5372 - acc: 0.7656 - val_loss: 0.5580 - val_acc: 0.7581\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5318 - acc: 0.7626 - val_loss: 0.5430 - val_acc: 0.7767\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.5263 - acc: 0.7644 - val_loss: 0.5404 - val_acc: 0.7777\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5211 - acc: 0.7741 - val_loss: 0.5420 - val_acc: 0.7684\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5160 - acc: 0.7826 - val_loss: 0.5342 - val_acc: 0.7767\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5111 - acc: 0.7758 - val_loss: 0.5215 - val_acc: 0.7927\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.5064 - acc: 0.7868 - val_loss: 0.5190 - val_acc: 0.7916\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5018 - acc: 0.7961 - val_loss: 0.5214 - val_acc: 0.7844\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4974 - acc: 0.7941 - val_loss: 0.5116 - val_acc: 0.7947\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4929 - acc: 0.7939 - val_loss: 0.5035 - val_acc: 0.8056\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.4888 - acc: 0.8040 - val_loss: 0.5073 - val_acc: 0.7937\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.4846 - acc: 0.8064 - val_loss: 0.5015 - val_acc: 0.7963\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4805 - acc: 0.8061 - val_loss: 0.4958 - val_acc: 0.8040\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4768 - acc: 0.8068 - val_loss: 0.4894 - val_acc: 0.8081\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4728 - acc: 0.8150 - val_loss: 0.4865 - val_acc: 0.8071\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4690 - acc: 0.8057 - val_loss: 0.4781 - val_acc: 0.8123\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4655 - acc: 0.8173 - val_loss: 0.4785 - val_acc: 0.8102\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4619 - acc: 0.8152 - val_loss: 0.4722 - val_acc: 0.8133\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4583 - acc: 0.8213 - val_loss: 0.4740 - val_acc: 0.8123\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4549 - acc: 0.8187 - val_loss: 0.4667 - val_acc: 0.8154\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4516 - acc: 0.8223 - val_loss: 0.4604 - val_acc: 0.8195\n",
            "With filter = 128, kernel_size = 8, layer_activation = sigmoid, dense_layer = 1, dense_activation = sigmoid, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 11ms/step - loss: 0.6955 - acc: 0.2931 - val_loss: 0.6904 - val_acc: 0.5271\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.6518 - acc: 0.5911 - val_loss: 0.6591 - val_acc: 0.6271\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.6210 - acc: 0.6531 - val_loss: 0.6360 - val_acc: 0.6643\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.5959 - acc: 0.7073 - val_loss: 0.6061 - val_acc: 0.7127\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.5747 - acc: 0.7359 - val_loss: 0.5880 - val_acc: 0.7215\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.5563 - acc: 0.7546 - val_loss: 0.5762 - val_acc: 0.7267\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.5395 - acc: 0.7480 - val_loss: 0.5297 - val_acc: 0.7999\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.5251 - acc: 0.7737 - val_loss: 0.5409 - val_acc: 0.7602\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.5115 - acc: 0.7822 - val_loss: 0.5309 - val_acc: 0.7633\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4993 - acc: 0.7896 - val_loss: 0.5004 - val_acc: 0.7978\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4880 - acc: 0.8041 - val_loss: 0.4900 - val_acc: 0.8128\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4775 - acc: 0.8120 - val_loss: 0.4819 - val_acc: 0.8143\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4674 - acc: 0.8200 - val_loss: 0.4500 - val_acc: 0.8556\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4587 - acc: 0.8311 - val_loss: 0.4662 - val_acc: 0.8252\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4499 - acc: 0.8339 - val_loss: 0.4636 - val_acc: 0.8221\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4418 - acc: 0.8360 - val_loss: 0.4518 - val_acc: 0.8288\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4341 - acc: 0.8432 - val_loss: 0.4469 - val_acc: 0.8298\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4266 - acc: 0.8462 - val_loss: 0.4334 - val_acc: 0.8396\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4192 - acc: 0.8511 - val_loss: 0.4363 - val_acc: 0.8308\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4126 - acc: 0.8535 - val_loss: 0.4241 - val_acc: 0.8412\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.4061 - acc: 0.8611 - val_loss: 0.4289 - val_acc: 0.8350\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3996 - acc: 0.8631 - val_loss: 0.4217 - val_acc: 0.8386\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3937 - acc: 0.8634 - val_loss: 0.4075 - val_acc: 0.8494\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3878 - acc: 0.8668 - val_loss: 0.4084 - val_acc: 0.8468\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3820 - acc: 0.8694 - val_loss: 0.3993 - val_acc: 0.8540\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3767 - acc: 0.8695 - val_loss: 0.3816 - val_acc: 0.8669\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3709 - acc: 0.8769 - val_loss: 0.3922 - val_acc: 0.8571\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3659 - acc: 0.8762 - val_loss: 0.3696 - val_acc: 0.8742\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3608 - acc: 0.8811 - val_loss: 0.3742 - val_acc: 0.8659\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3559 - acc: 0.8799 - val_loss: 0.3670 - val_acc: 0.8706\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3510 - acc: 0.8852 - val_loss: 0.3771 - val_acc: 0.8587\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3462 - acc: 0.8841 - val_loss: 0.3580 - val_acc: 0.8762\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3415 - acc: 0.8836 - val_loss: 0.3455 - val_acc: 0.8865\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3374 - acc: 0.8914 - val_loss: 0.3499 - val_acc: 0.8793\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3326 - acc: 0.8925 - val_loss: 0.3496 - val_acc: 0.8788\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3284 - acc: 0.8927 - val_loss: 0.3474 - val_acc: 0.8793\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3241 - acc: 0.8944 - val_loss: 0.3400 - val_acc: 0.8824\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3200 - acc: 0.8958 - val_loss: 0.3404 - val_acc: 0.8819\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3160 - acc: 0.8977 - val_loss: 0.3373 - val_acc: 0.8819\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.3121 - acc: 0.8984 - val_loss: 0.3288 - val_acc: 0.8871\n",
            "With filter = 128, kernel_size = 8, layer_activation = sigmoid, dense_layer = 1, dense_activation = sigmoid, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 17ms/step - loss: 0.7201 - acc: 0.7867 - val_loss: 0.6423 - val_acc: 0.6833\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6619 - acc: 0.5760 - val_loss: 0.6695 - val_acc: 0.5297\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6470 - acc: 0.5608 - val_loss: 0.6494 - val_acc: 0.5946\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6329 - acc: 0.6159 - val_loss: 0.6331 - val_acc: 0.6452\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.6198 - acc: 0.6878 - val_loss: 0.6294 - val_acc: 0.6400\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.6079 - acc: 0.6888 - val_loss: 0.6079 - val_acc: 0.6890\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.5957 - acc: 0.6993 - val_loss: 0.5926 - val_acc: 0.7267\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5846 - acc: 0.7425 - val_loss: 0.5773 - val_acc: 0.7509\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5740 - acc: 0.7353 - val_loss: 0.5676 - val_acc: 0.7597\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5645 - acc: 0.7716 - val_loss: 0.5649 - val_acc: 0.7519\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5543 - acc: 0.7580 - val_loss: 0.5479 - val_acc: 0.7757\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5453 - acc: 0.7712 - val_loss: 0.5343 - val_acc: 0.7922\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5366 - acc: 0.7755 - val_loss: 0.5236 - val_acc: 0.7989\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5284 - acc: 0.7930 - val_loss: 0.5253 - val_acc: 0.7886\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5204 - acc: 0.7906 - val_loss: 0.5152 - val_acc: 0.7963\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.5128 - acc: 0.7946 - val_loss: 0.5050 - val_acc: 0.8051\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.5056 - acc: 0.8084 - val_loss: 0.5012 - val_acc: 0.8045\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.4984 - acc: 0.8107 - val_loss: 0.5014 - val_acc: 0.7953\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.4917 - acc: 0.8123 - val_loss: 0.4949 - val_acc: 0.7994\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.4852 - acc: 0.8134 - val_loss: 0.4841 - val_acc: 0.8102\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.4790 - acc: 0.8246 - val_loss: 0.4944 - val_acc: 0.7932\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.4731 - acc: 0.8160 - val_loss: 0.4766 - val_acc: 0.8128\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.4673 - acc: 0.8230 - val_loss: 0.4605 - val_acc: 0.8293\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.4621 - acc: 0.8340 - val_loss: 0.4650 - val_acc: 0.8200\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4563 - acc: 0.8308 - val_loss: 0.4623 - val_acc: 0.8205\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4510 - acc: 0.8340 - val_loss: 0.4534 - val_acc: 0.8308\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.4459 - acc: 0.8397 - val_loss: 0.4563 - val_acc: 0.8216\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4411 - acc: 0.8387 - val_loss: 0.4474 - val_acc: 0.8283\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4361 - acc: 0.8418 - val_loss: 0.4432 - val_acc: 0.8334\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4312 - acc: 0.8414 - val_loss: 0.4290 - val_acc: 0.8427\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.4268 - acc: 0.8462 - val_loss: 0.4254 - val_acc: 0.8437\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4223 - acc: 0.8529 - val_loss: 0.4328 - val_acc: 0.8360\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4179 - acc: 0.8494 - val_loss: 0.4146 - val_acc: 0.8530\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4135 - acc: 0.8556 - val_loss: 0.4198 - val_acc: 0.8432\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4093 - acc: 0.8545 - val_loss: 0.4190 - val_acc: 0.8422\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 0.4052 - acc: 0.8583 - val_loss: 0.4148 - val_acc: 0.8448\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.4010 - acc: 0.8600 - val_loss: 0.4077 - val_acc: 0.8484\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.3972 - acc: 0.8611 - val_loss: 0.4133 - val_acc: 0.8412\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.3933 - acc: 0.8623 - val_loss: 0.4047 - val_acc: 0.8468\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 0.3893 - acc: 0.8651 - val_loss: 0.3976 - val_acc: 0.8556\n",
            "With filter = 128, kernel_size = 8, layer_activation = sigmoid, dense_layer = 1, dense_activation = sigmoid, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 11ms/step - loss: 4.9276 - acc: 0.0000e+00 - val_loss: 5.8259 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.9090 - acc: 0.0000e+00 - val_loss: 5.8038 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.9015 - acc: 0.0000e+00 - val_loss: 5.7985 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8949 - acc: 0.0000e+00 - val_loss: 5.7924 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8889 - acc: 0.0000e+00 - val_loss: 5.7825 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8836 - acc: 0.0000e+00 - val_loss: 5.7791 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8786 - acc: 0.0000e+00 - val_loss: 5.7732 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8741 - acc: 0.0000e+00 - val_loss: 5.7683 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8699 - acc: 0.0000e+00 - val_loss: 5.7620 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8660 - acc: 0.0000e+00 - val_loss: 5.7623 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8622 - acc: 0.0000e+00 - val_loss: 5.7574 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8586 - acc: 0.0000e+00 - val_loss: 5.7510 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8553 - acc: 0.0000e+00 - val_loss: 5.7472 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8521 - acc: 0.0000e+00 - val_loss: 5.7458 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8490 - acc: 0.0000e+00 - val_loss: 5.7454 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8459 - acc: 0.0000e+00 - val_loss: 5.7394 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8430 - acc: 0.0000e+00 - val_loss: 5.7382 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8401 - acc: 0.0000e+00 - val_loss: 5.7315 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8374 - acc: 0.0000e+00 - val_loss: 5.7323 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8348 - acc: 0.0000e+00 - val_loss: 5.7290 - val_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8322 - acc: 0.0000e+00 - val_loss: 5.7256 - val_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8297 - acc: 0.0000e+00 - val_loss: 5.7259 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8273 - acc: 0.0000e+00 - val_loss: 5.7217 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8249 - acc: 0.0000e+00 - val_loss: 5.7152 - val_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8226 - acc: 0.0000e+00 - val_loss: 5.7169 - val_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8204 - acc: 0.0000e+00 - val_loss: 5.7120 - val_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8182 - acc: 0.0000e+00 - val_loss: 5.7144 - val_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8162 - acc: 0.0000e+00 - val_loss: 5.7102 - val_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8141 - acc: 0.0000e+00 - val_loss: 5.7127 - val_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8122 - acc: 0.0000e+00 - val_loss: 5.7061 - val_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8102 - acc: 0.0000e+00 - val_loss: 5.7042 - val_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8083 - acc: 0.0000e+00 - val_loss: 5.7020 - val_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8065 - acc: 0.0000e+00 - val_loss: 5.6982 - val_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8047 - acc: 0.0000e+00 - val_loss: 5.6966 - val_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8030 - acc: 0.0000e+00 - val_loss: 5.6954 - val_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.8013 - acc: 0.0000e+00 - val_loss: 5.6953 - val_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.7996 - acc: 0.0000e+00 - val_loss: 5.6920 - val_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.7981 - acc: 0.0000e+00 - val_loss: 5.6919 - val_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.7965 - acc: 0.0000e+00 - val_loss: 5.6913 - val_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.7950 - acc: 0.0000e+00 - val_loss: 5.6921 - val_acc: 0.0000e+00\n",
            "With filter = 128, kernel_size = 8, layer_activation = sigmoid, dense_layer = 10, dense_activation = relu, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 17ms/step - loss: 4.5333 - acc: 0.6632 - val_loss: 4.8381 - val_acc: 0.6751\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.3288 - acc: 0.6687 - val_loss: 4.7844 - val_acc: 0.6761\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2911 - acc: 0.6709 - val_loss: 4.7510 - val_acc: 0.6772\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 4.2708 - acc: 0.6731 - val_loss: 4.7312 - val_acc: 0.6787\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2590 - acc: 0.6738 - val_loss: 4.7173 - val_acc: 0.6823\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2502 - acc: 0.6756 - val_loss: 4.7069 - val_acc: 0.6844\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2432 - acc: 0.6767 - val_loss: 4.6982 - val_acc: 0.6854\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2375 - acc: 0.6779 - val_loss: 4.6916 - val_acc: 0.6859\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2328 - acc: 0.6807 - val_loss: 4.6859 - val_acc: 0.6875\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2287 - acc: 0.6821 - val_loss: 4.6819 - val_acc: 0.6890\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2252 - acc: 0.6829 - val_loss: 4.6782 - val_acc: 0.6890\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2221 - acc: 0.6841 - val_loss: 4.6750 - val_acc: 0.6900\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2194 - acc: 0.6860 - val_loss: 4.6722 - val_acc: 0.6900\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2169 - acc: 0.6870 - val_loss: 4.6694 - val_acc: 0.6900\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2148 - acc: 0.6874 - val_loss: 4.6677 - val_acc: 0.6916\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2128 - acc: 0.6881 - val_loss: 4.6659 - val_acc: 0.6916\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2110 - acc: 0.6886 - val_loss: 4.6646 - val_acc: 0.6926\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2094 - acc: 0.6896 - val_loss: 4.6628 - val_acc: 0.6931\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2079 - acc: 0.6904 - val_loss: 4.6614 - val_acc: 0.6937\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2065 - acc: 0.6907 - val_loss: 4.6605 - val_acc: 0.6937\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2052 - acc: 0.6907 - val_loss: 4.6591 - val_acc: 0.6937\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2039 - acc: 0.6910 - val_loss: 4.6579 - val_acc: 0.6937\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2027 - acc: 0.6914 - val_loss: 4.6568 - val_acc: 0.6947\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2016 - acc: 0.6916 - val_loss: 4.6559 - val_acc: 0.6947\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2005 - acc: 0.6914 - val_loss: 4.6554 - val_acc: 0.6947\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1994 - acc: 0.6914 - val_loss: 4.6532 - val_acc: 0.6952\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1983 - acc: 0.6917 - val_loss: 4.6525 - val_acc: 0.6952\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1973 - acc: 0.6926 - val_loss: 4.6522 - val_acc: 0.6952\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1962 - acc: 0.6930 - val_loss: 4.6507 - val_acc: 0.6952\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1952 - acc: 0.6932 - val_loss: 4.6496 - val_acc: 0.6952\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1941 - acc: 0.6932 - val_loss: 4.6479 - val_acc: 0.6952\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1930 - acc: 0.6934 - val_loss: 4.6475 - val_acc: 0.6952\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1920 - acc: 0.6934 - val_loss: 4.6455 - val_acc: 0.6957\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1909 - acc: 0.6934 - val_loss: 4.6467 - val_acc: 0.6957\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1899 - acc: 0.6932 - val_loss: 4.6446 - val_acc: 0.6957\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1888 - acc: 0.6936 - val_loss: 4.6427 - val_acc: 0.6957\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1877 - acc: 0.6937 - val_loss: 4.6417 - val_acc: 0.6942\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1866 - acc: 0.6932 - val_loss: 4.6420 - val_acc: 0.6942\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1855 - acc: 0.6930 - val_loss: 4.6392 - val_acc: 0.6937\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1844 - acc: 0.6928 - val_loss: 4.6385 - val_acc: 0.6937\n",
            "With filter = 128, kernel_size = 8, layer_activation = sigmoid, dense_layer = 10, dense_activation = relu, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 11ms/step - loss: 2.9433 - acc: 0.2049 - val_loss: 3.2592 - val_acc: 0.2114\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.8025 - acc: 0.2049 - val_loss: 3.2453 - val_acc: 0.2114\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7906 - acc: 0.2049 - val_loss: 3.2391 - val_acc: 0.2114\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7800 - acc: 0.2049 - val_loss: 3.2330 - val_acc: 0.2114\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7700 - acc: 0.2049 - val_loss: 3.2127 - val_acc: 0.2114\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7604 - acc: 0.2049 - val_loss: 3.2030 - val_acc: 0.2114\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.7507 - acc: 0.2049 - val_loss: 3.2024 - val_acc: 0.2114\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.7424 - acc: 0.2049 - val_loss: 3.1962 - val_acc: 0.2114\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.7352 - acc: 0.2049 - val_loss: 3.1811 - val_acc: 0.2114\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.7285 - acc: 0.2049 - val_loss: 3.1703 - val_acc: 0.2114\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.7220 - acc: 0.2049 - val_loss: 3.1741 - val_acc: 0.2114\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.7155 - acc: 0.2049 - val_loss: 3.1717 - val_acc: 0.2114\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.7092 - acc: 0.2049 - val_loss: 3.1572 - val_acc: 0.2114\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.7027 - acc: 0.2049 - val_loss: 3.1583 - val_acc: 0.2114\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.6963 - acc: 0.2049 - val_loss: 3.1428 - val_acc: 0.2114\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.6899 - acc: 0.2049 - val_loss: 3.1532 - val_acc: 0.2114\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.6840 - acc: 0.2049 - val_loss: 3.1405 - val_acc: 0.2114\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.6774 - acc: 0.2049 - val_loss: 3.1162 - val_acc: 0.2114\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.6711 - acc: 0.2049 - val_loss: 3.1195 - val_acc: 0.2114\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.6650 - acc: 0.2049 - val_loss: 3.1114 - val_acc: 0.2114\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6589 - acc: 0.2049 - val_loss: 3.1082 - val_acc: 0.2114\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6528 - acc: 0.2049 - val_loss: 3.1056 - val_acc: 0.2114\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6469 - acc: 0.2049 - val_loss: 3.0973 - val_acc: 0.2114\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6410 - acc: 0.2049 - val_loss: 3.0834 - val_acc: 0.2114\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6353 - acc: 0.2049 - val_loss: 3.0842 - val_acc: 0.2114\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6299 - acc: 0.2049 - val_loss: 3.0916 - val_acc: 0.2114\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6245 - acc: 0.2049 - val_loss: 3.0880 - val_acc: 0.2114\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6190 - acc: 0.2049 - val_loss: 3.0706 - val_acc: 0.2114\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6137 - acc: 0.2049 - val_loss: 3.0665 - val_acc: 0.2114\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6088 - acc: 0.2049 - val_loss: 3.0710 - val_acc: 0.2114\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6037 - acc: 0.2049 - val_loss: 3.0580 - val_acc: 0.2114\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.5990 - acc: 0.2049 - val_loss: 3.0438 - val_acc: 0.2114\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.5942 - acc: 0.2049 - val_loss: 3.0631 - val_acc: 0.2114\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.5901 - acc: 0.2049 - val_loss: 3.0359 - val_acc: 0.2114\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.5854 - acc: 0.2049 - val_loss: 3.0375 - val_acc: 0.2114\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.5811 - acc: 0.2049 - val_loss: 3.0359 - val_acc: 0.2114\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.5771 - acc: 0.2049 - val_loss: 3.0316 - val_acc: 0.2114\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.5732 - acc: 0.2049 - val_loss: 3.0333 - val_acc: 0.2114\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.5691 - acc: 0.2049 - val_loss: 3.0269 - val_acc: 0.2114\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.5654 - acc: 0.2049 - val_loss: 3.0418 - val_acc: 0.2114\n",
            "With filter = 128, kernel_size = 8, layer_activation = sigmoid, dense_layer = 10, dense_activation = relu, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 17ms/step - loss: 7.1739 - acc: 0.0250 - val_loss: 11.0914 - val_acc: 5.1573e-04\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0501 - acc: 1.2895e-04 - val_loss: 11.0549 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 7.0412 - acc: 1.2895e-04 - val_loss: 11.0461 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0381 - acc: 0.0000e+00 - val_loss: 11.0301 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0291 - acc: 0.0000e+00 - val_loss: 11.0263 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0272 - acc: 0.0000e+00 - val_loss: 11.0250 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 7.0255 - acc: 0.0000e+00 - val_loss: 11.0236 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0239 - acc: 0.0000e+00 - val_loss: 11.0224 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0224 - acc: 0.0000e+00 - val_loss: 11.0204 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0210 - acc: 0.0000e+00 - val_loss: 11.0188 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0196 - acc: 0.0000e+00 - val_loss: 11.0178 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0182 - acc: 0.0000e+00 - val_loss: 11.0160 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0169 - acc: 0.0000e+00 - val_loss: 11.0146 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0157 - acc: 0.0000e+00 - val_loss: 11.0133 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0145 - acc: 0.0000e+00 - val_loss: 11.0117 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0133 - acc: 0.0000e+00 - val_loss: 11.0106 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0122 - acc: 0.0000e+00 - val_loss: 11.0092 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0111 - acc: 0.0000e+00 - val_loss: 11.0084 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0101 - acc: 0.0000e+00 - val_loss: 11.0066 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0090 - acc: 0.0000e+00 - val_loss: 11.0064 - val_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0080 - acc: 0.0000e+00 - val_loss: 11.0047 - val_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0071 - acc: 0.0000e+00 - val_loss: 11.0039 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0061 - acc: 0.0000e+00 - val_loss: 11.0032 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0052 - acc: 0.0000e+00 - val_loss: 11.0019 - val_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 7.0043 - acc: 5.1580e-04 - val_loss: 11.0013 - val_acc: 5.1573e-04\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 7.0035 - acc: 5.1580e-04 - val_loss: 10.9998 - val_acc: 5.1573e-04\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.5459 - acc: 3.8685e-04 - val_loss: 9.8491 - val_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.3024 - acc: 0.0000e+00 - val_loss: 9.8573 - val_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.2976 - acc: 0.0000e+00 - val_loss: 9.8543 - val_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.2945 - acc: 0.0000e+00 - val_loss: 9.8513 - val_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.2920 - acc: 0.0000e+00 - val_loss: 9.8483 - val_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.2897 - acc: 0.0000e+00 - val_loss: 9.8462 - val_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.2876 - acc: 0.0000e+00 - val_loss: 9.8440 - val_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.2857 - acc: 0.0000e+00 - val_loss: 9.8419 - val_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.2838 - acc: 0.0000e+00 - val_loss: 9.8400 - val_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.2821 - acc: 0.0000e+00 - val_loss: 9.8376 - val_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.2804 - acc: 0.0000e+00 - val_loss: 9.8368 - val_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.2789 - acc: 0.0000e+00 - val_loss: 9.8358 - val_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.2773 - acc: 0.0000e+00 - val_loss: 9.8325 - val_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 6.2759 - acc: 0.0000e+00 - val_loss: 9.8324 - val_acc: 0.0000e+00\n",
            "With filter = 128, kernel_size = 8, layer_activation = sigmoid, dense_layer = 10, dense_activation = relu, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 11ms/step - loss: 3.3615 - acc: 1.2895e-04 - val_loss: 4.1567 - val_acc: 0.0021\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.8352 - acc: 6.4475e-04 - val_loss: 4.1487 - val_acc: 0.0010\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.8219 - acc: 9.0264e-04 - val_loss: 4.1374 - val_acc: 0.0031\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.8132 - acc: 0.0068 - val_loss: 4.1354 - val_acc: 0.0093\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.8063 - acc: 0.0108 - val_loss: 4.1332 - val_acc: 0.0139\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.8004 - acc: 0.0195 - val_loss: 4.1262 - val_acc: 0.0273\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7950 - acc: 0.0309 - val_loss: 4.1221 - val_acc: 0.0351\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7897 - acc: 0.0402 - val_loss: 4.1145 - val_acc: 0.0423\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7848 - acc: 0.0472 - val_loss: 4.1166 - val_acc: 0.0505\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7794 - acc: 0.0512 - val_loss: 4.1126 - val_acc: 0.0516\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7744 - acc: 0.0515 - val_loss: 4.1017 - val_acc: 0.0691\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7690 - acc: 0.0573 - val_loss: 4.1018 - val_acc: 0.0727\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7635 - acc: 0.0606 - val_loss: 4.0996 - val_acc: 0.0691\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7581 - acc: 0.0607 - val_loss: 4.0923 - val_acc: 0.0737\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7526 - acc: 0.0658 - val_loss: 4.0841 - val_acc: 0.0774\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7472 - acc: 0.0634 - val_loss: 4.0742 - val_acc: 0.0681\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7415 - acc: 0.0674 - val_loss: 4.0741 - val_acc: 0.0737\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7355 - acc: 0.0682 - val_loss: 4.0692 - val_acc: 0.0722\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7298 - acc: 0.0705 - val_loss: 4.0578 - val_acc: 0.0799\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7240 - acc: 0.0694 - val_loss: 4.0571 - val_acc: 0.0768\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7178 - acc: 0.0721 - val_loss: 4.0663 - val_acc: 0.0701\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7120 - acc: 0.0686 - val_loss: 4.0399 - val_acc: 0.0794\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.7060 - acc: 0.0752 - val_loss: 4.0432 - val_acc: 0.0707\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6999 - acc: 0.0709 - val_loss: 4.0248 - val_acc: 0.0779\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6940 - acc: 0.0760 - val_loss: 4.0216 - val_acc: 0.0815\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6881 - acc: 0.0750 - val_loss: 4.0203 - val_acc: 0.0820\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6820 - acc: 0.0776 - val_loss: 4.0120 - val_acc: 0.0763\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6756 - acc: 0.0812 - val_loss: 4.0189 - val_acc: 0.0670\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6694 - acc: 0.0740 - val_loss: 3.9985 - val_acc: 0.0887\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6633 - acc: 0.0814 - val_loss: 4.0054 - val_acc: 0.0841\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6574 - acc: 0.0828 - val_loss: 4.0034 - val_acc: 0.0737\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6515 - acc: 0.0790 - val_loss: 3.9861 - val_acc: 0.0825\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6453 - acc: 0.0798 - val_loss: 3.9842 - val_acc: 0.0939\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6396 - acc: 0.0798 - val_loss: 3.9649 - val_acc: 0.0820\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6341 - acc: 0.0806 - val_loss: 3.9734 - val_acc: 0.0701\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6285 - acc: 0.0821 - val_loss: 3.9661 - val_acc: 0.0841\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6231 - acc: 0.0772 - val_loss: 3.9643 - val_acc: 0.0660\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6175 - acc: 0.0765 - val_loss: 3.9675 - val_acc: 0.0810\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6124 - acc: 0.0774 - val_loss: 3.9642 - val_acc: 0.0727\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.6073 - acc: 0.0748 - val_loss: 3.9404 - val_acc: 0.0640\n",
            "With filter = 128, kernel_size = 8, layer_activation = sigmoid, dense_layer = 10, dense_activation = relu, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 17ms/step - loss: 2.7792 - acc: 0.0000e+00 - val_loss: 2.2426 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.1381 - acc: 0.0000e+00 - val_loss: 2.1847 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.1211 - acc: 0.0000e+00 - val_loss: 2.1546 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.1107 - acc: 0.0000e+00 - val_loss: 2.1373 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.1018 - acc: 0.0000e+00 - val_loss: 2.1173 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.0931 - acc: 0.0000e+00 - val_loss: 2.1106 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.0847 - acc: 0.0000e+00 - val_loss: 2.0969 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.0762 - acc: 0.0000e+00 - val_loss: 2.0886 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.0682 - acc: 0.0000e+00 - val_loss: 2.0877 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.0600 - acc: 0.0000e+00 - val_loss: 2.0704 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.0522 - acc: 0.0000e+00 - val_loss: 2.0628 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.0444 - acc: 0.0000e+00 - val_loss: 2.0639 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.0369 - acc: 0.0000e+00 - val_loss: 2.0566 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.0296 - acc: 0.0000e+00 - val_loss: 2.0494 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.0221 - acc: 0.0000e+00 - val_loss: 2.0346 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.0148 - acc: 0.0000e+00 - val_loss: 2.0245 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.0076 - acc: 0.0000e+00 - val_loss: 2.0225 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 2.0006 - acc: 0.0000e+00 - val_loss: 2.0143 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.9935 - acc: 0.0000e+00 - val_loss: 2.0002 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.9869 - acc: 0.0000e+00 - val_loss: 1.9924 - val_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.9797 - acc: 0.0000e+00 - val_loss: 1.9937 - val_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.9729 - acc: 0.0000e+00 - val_loss: 1.9923 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.9661 - acc: 0.0000e+00 - val_loss: 1.9751 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.9596 - acc: 0.0000e+00 - val_loss: 1.9668 - val_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.9528 - acc: 0.0000e+00 - val_loss: 1.9565 - val_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.9464 - acc: 0.0000e+00 - val_loss: 1.9629 - val_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.9399 - acc: 0.0000e+00 - val_loss: 1.9490 - val_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.9336 - acc: 0.0000e+00 - val_loss: 1.9478 - val_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.9274 - acc: 0.0000e+00 - val_loss: 1.9266 - val_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.9214 - acc: 0.0000e+00 - val_loss: 1.9132 - val_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.9158 - acc: 0.0000e+00 - val_loss: 1.9223 - val_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 1.9094 - acc: 0.0000e+00 - val_loss: 1.9234 - val_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.9037 - acc: 0.0000e+00 - val_loss: 1.9067 - val_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.8982 - acc: 0.0000e+00 - val_loss: 1.9047 - val_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.8929 - acc: 0.0000e+00 - val_loss: 1.8989 - val_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.8874 - acc: 0.0000e+00 - val_loss: 1.8908 - val_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.8821 - acc: 0.0000e+00 - val_loss: 1.8950 - val_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.8770 - acc: 0.0000e+00 - val_loss: 1.8998 - val_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.8720 - acc: 0.0000e+00 - val_loss: 1.8798 - val_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 1.8672 - acc: 0.0000e+00 - val_loss: 1.8808 - val_acc: 0.0000e+00\n",
            "With filter = 128, kernel_size = 8, layer_activation = sigmoid, dense_layer = 10, dense_activation = relu, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 10ms/step - loss: 4.9093 - acc: 0.0000e+00 - val_loss: 6.7584 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.6103 - acc: 0.0000e+00 - val_loss: 6.3482 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.4094 - acc: 0.0000e+00 - val_loss: 6.1343 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.3260 - acc: 0.0000e+00 - val_loss: 6.0574 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.2907 - acc: 0.0000e+00 - val_loss: 6.0258 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.2726 - acc: 0.0000e+00 - val_loss: 6.0056 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.2632 - acc: 0.0000e+00 - val_loss: 5.9949 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.2563 - acc: 0.0000e+00 - val_loss: 5.9862 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.2513 - acc: 0.0000e+00 - val_loss: 5.9808 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.2474 - acc: 0.0000e+00 - val_loss: 5.9754 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.2440 - acc: 0.0000e+00 - val_loss: 5.9720 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.2411 - acc: 0.0000e+00 - val_loss: 5.9681 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.2380 - acc: 0.0000e+00 - val_loss: 5.9631 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.2347 - acc: 0.0000e+00 - val_loss: 5.9594 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.2325 - acc: 0.0000e+00 - val_loss: 5.9564 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.2291 - acc: 0.0000e+00 - val_loss: 5.9519 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.2188 - acc: 0.0000e+00 - val_loss: 5.9414 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.1593 - acc: 0.0000e+00 - val_loss: 5.9021 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.1095 - acc: 0.0000e+00 - val_loss: 5.8932 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.0998 - acc: 0.0000e+00 - val_loss: 5.8915 - val_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.0965 - acc: 0.0000e+00 - val_loss: 5.8890 - val_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.0943 - acc: 0.0000e+00 - val_loss: 5.8866 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.0924 - acc: 0.0000e+00 - val_loss: 5.8834 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.0909 - acc: 0.0000e+00 - val_loss: 5.8829 - val_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.0895 - acc: 0.0000e+00 - val_loss: 5.8796 - val_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.0882 - acc: 0.0000e+00 - val_loss: 5.8778 - val_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.0870 - acc: 0.0000e+00 - val_loss: 5.8778 - val_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.0859 - acc: 0.0000e+00 - val_loss: 5.8753 - val_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.0849 - acc: 0.0000e+00 - val_loss: 5.8743 - val_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.0839 - acc: 0.0000e+00 - val_loss: 5.8735 - val_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.0830 - acc: 0.0000e+00 - val_loss: 5.8727 - val_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.0821 - acc: 0.0000e+00 - val_loss: 5.8706 - val_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.0812 - acc: 0.0000e+00 - val_loss: 5.8689 - val_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.0804 - acc: 0.0000e+00 - val_loss: 5.8670 - val_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.0796 - acc: 0.0000e+00 - val_loss: 5.8661 - val_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 4.0778 - acc: 0.0000e+00 - val_loss: 5.8572 - val_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.9871 - acc: 0.0000e+00 - val_loss: 5.6605 - val_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 3.9460 - acc: 0.0000e+00 - val_loss: 5.6464 - val_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 3.9413 - acc: 0.0000e+00 - val_loss: 5.6439 - val_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 3.9400 - acc: 0.0000e+00 - val_loss: 5.6408 - val_acc: 0.0000e+00\n",
            "With filter = 128, kernel_size = 8, layer_activation = sigmoid, dense_layer = 50, dense_activation = relu, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 17ms/step - loss: 5.0602 - acc: 0.0000e+00 - val_loss: 6.4639 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.7257 - acc: 0.0000e+00 - val_loss: 6.1869 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.5337 - acc: 0.0000e+00 - val_loss: 5.9925 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.4007 - acc: 0.0000e+00 - val_loss: 5.9204 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.3515 - acc: 0.0000e+00 - val_loss: 5.8812 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.3153 - acc: 0.0000e+00 - val_loss: 5.8193 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2104 - acc: 0.0000e+00 - val_loss: 5.6458 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1424 - acc: 0.0000e+00 - val_loss: 5.6109 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.1174 - acc: 0.0000e+00 - val_loss: 5.5892 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.0819 - acc: 0.0000e+00 - val_loss: 5.5617 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.0323 - acc: 0.0000e+00 - val_loss: 5.5360 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.9949 - acc: 0.0000e+00 - val_loss: 5.5208 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.9778 - acc: 0.0000e+00 - val_loss: 5.5117 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.9634 - acc: 0.0000e+00 - val_loss: 5.5020 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.9491 - acc: 0.0000e+00 - val_loss: 5.4933 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.9349 - acc: 0.0000e+00 - val_loss: 5.4791 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8796 - acc: 0.0000e+00 - val_loss: 5.4592 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8661 - acc: 0.0000e+00 - val_loss: 5.4540 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8593 - acc: 0.0000e+00 - val_loss: 5.4493 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8555 - acc: 0.0000e+00 - val_loss: 5.4456 - val_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8510 - acc: 0.0000e+00 - val_loss: 5.4433 - val_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8484 - acc: 0.0000e+00 - val_loss: 5.4405 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8462 - acc: 0.0000e+00 - val_loss: 5.4372 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8441 - acc: 0.0000e+00 - val_loss: 5.4355 - val_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8421 - acc: 0.0000e+00 - val_loss: 5.4327 - val_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8402 - acc: 0.0000e+00 - val_loss: 5.4313 - val_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8384 - acc: 0.0000e+00 - val_loss: 5.4290 - val_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8368 - acc: 0.0000e+00 - val_loss: 5.4267 - val_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8352 - acc: 0.0000e+00 - val_loss: 5.4251 - val_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8337 - acc: 0.0000e+00 - val_loss: 5.4234 - val_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8323 - acc: 0.0000e+00 - val_loss: 5.4215 - val_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8310 - acc: 0.0000e+00 - val_loss: 5.4200 - val_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8295 - acc: 0.0000e+00 - val_loss: 5.4188 - val_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8281 - acc: 0.0000e+00 - val_loss: 5.4170 - val_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8268 - acc: 0.0000e+00 - val_loss: 5.4153 - val_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8257 - acc: 0.0000e+00 - val_loss: 5.4137 - val_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8245 - acc: 0.0000e+00 - val_loss: 5.4135 - val_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8234 - acc: 0.0000e+00 - val_loss: 5.4116 - val_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8224 - acc: 0.0000e+00 - val_loss: 5.4107 - val_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.8214 - acc: 0.0000e+00 - val_loss: 5.4101 - val_acc: 0.0000e+00\n",
            "With filter = 128, kernel_size = 8, layer_activation = sigmoid, dense_layer = 50, dense_activation = relu, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 11ms/step - loss: 3.8288 - acc: 0.0000e+00 - val_loss: 4.7472 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.3392 - acc: 0.0000e+00 - val_loss: 4.6369 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2940 - acc: 0.0000e+00 - val_loss: 4.5954 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2773 - acc: 0.0000e+00 - val_loss: 4.5703 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2667 - acc: 0.0000e+00 - val_loss: 4.5489 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2599 - acc: 0.0000e+00 - val_loss: 4.5406 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2548 - acc: 0.0000e+00 - val_loss: 4.5262 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2511 - acc: 0.0000e+00 - val_loss: 4.5210 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2483 - acc: 0.0000e+00 - val_loss: 4.5089 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2461 - acc: 0.0000e+00 - val_loss: 4.5072 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2440 - acc: 0.0000e+00 - val_loss: 4.5047 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2422 - acc: 0.0000e+00 - val_loss: 4.5093 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2407 - acc: 0.0000e+00 - val_loss: 4.4982 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2391 - acc: 0.0000e+00 - val_loss: 4.4927 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2375 - acc: 0.0000e+00 - val_loss: 4.4999 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2361 - acc: 0.0000e+00 - val_loss: 4.4902 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2346 - acc: 0.0000e+00 - val_loss: 4.4908 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2331 - acc: 0.0000e+00 - val_loss: 4.4889 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2315 - acc: 0.0000e+00 - val_loss: 4.4842 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2299 - acc: 0.0000e+00 - val_loss: 4.4853 - val_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2282 - acc: 0.0000e+00 - val_loss: 4.4885 - val_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2266 - acc: 0.0000e+00 - val_loss: 4.4719 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2249 - acc: 0.0000e+00 - val_loss: 4.4791 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2231 - acc: 0.0000e+00 - val_loss: 4.4725 - val_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2213 - acc: 0.0000e+00 - val_loss: 4.4693 - val_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2195 - acc: 0.0000e+00 - val_loss: 4.4653 - val_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2175 - acc: 0.0000e+00 - val_loss: 4.4686 - val_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2156 - acc: 0.0000e+00 - val_loss: 4.4667 - val_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2133 - acc: 0.0000e+00 - val_loss: 4.4596 - val_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2112 - acc: 0.0000e+00 - val_loss: 4.4657 - val_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2091 - acc: 0.0000e+00 - val_loss: 4.4644 - val_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2066 - acc: 0.0000e+00 - val_loss: 4.4561 - val_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2042 - acc: 0.0000e+00 - val_loss: 4.4541 - val_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2016 - acc: 0.0000e+00 - val_loss: 4.4467 - val_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.1990 - acc: 0.0000e+00 - val_loss: 4.4437 - val_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.1961 - acc: 0.0000e+00 - val_loss: 4.4512 - val_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.1933 - acc: 0.0000e+00 - val_loss: 4.4406 - val_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.1903 - acc: 0.0000e+00 - val_loss: 4.4362 - val_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.1871 - acc: 0.0000e+00 - val_loss: 4.4434 - val_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.1838 - acc: 0.0000e+00 - val_loss: 4.4267 - val_acc: 0.0000e+00\n",
            "With filter = 128, kernel_size = 8, layer_activation = sigmoid, dense_layer = 50, dense_activation = relu, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 17ms/step - loss: 4.1921 - acc: 0.0000e+00 - val_loss: 5.6055 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.7457 - acc: 0.0000e+00 - val_loss: 5.2619 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5901 - acc: 0.0000e+00 - val_loss: 5.2270 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5699 - acc: 0.0000e+00 - val_loss: 5.2096 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5581 - acc: 0.0000e+00 - val_loss: 5.1897 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5451 - acc: 0.0000e+00 - val_loss: 5.1747 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5379 - acc: 0.0000e+00 - val_loss: 5.1664 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5337 - acc: 0.0000e+00 - val_loss: 5.1607 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5305 - acc: 0.0000e+00 - val_loss: 5.1550 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5279 - acc: 0.0000e+00 - val_loss: 5.1529 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5258 - acc: 0.0000e+00 - val_loss: 5.1481 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5240 - acc: 0.0000e+00 - val_loss: 5.1438 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.5225 - acc: 0.0000e+00 - val_loss: 5.1401 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5212 - acc: 0.0000e+00 - val_loss: 5.1371 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5200 - acc: 0.0000e+00 - val_loss: 5.1371 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5189 - acc: 0.0000e+00 - val_loss: 5.1324 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5179 - acc: 0.0000e+00 - val_loss: 5.1304 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5169 - acc: 0.0000e+00 - val_loss: 5.1288 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.5160 - acc: 0.0000e+00 - val_loss: 5.1276 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5150 - acc: 0.0000e+00 - val_loss: 5.1254 - val_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5141 - acc: 0.0000e+00 - val_loss: 5.1247 - val_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5132 - acc: 0.0000e+00 - val_loss: 5.1211 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5123 - acc: 0.0000e+00 - val_loss: 5.1226 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5114 - acc: 0.0000e+00 - val_loss: 5.1164 - val_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5105 - acc: 0.0000e+00 - val_loss: 5.1168 - val_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5096 - acc: 0.0000e+00 - val_loss: 5.1167 - val_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5086 - acc: 0.0000e+00 - val_loss: 5.1152 - val_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5077 - acc: 0.0000e+00 - val_loss: 5.1158 - val_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5067 - acc: 0.0000e+00 - val_loss: 5.1137 - val_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5057 - acc: 0.0000e+00 - val_loss: 5.1113 - val_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.5048 - acc: 0.0000e+00 - val_loss: 5.1111 - val_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.5037 - acc: 0.0000e+00 - val_loss: 5.1105 - val_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.5027 - acc: 0.0000e+00 - val_loss: 5.1094 - val_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.5017 - acc: 0.0000e+00 - val_loss: 5.1100 - val_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.5007 - acc: 0.0000e+00 - val_loss: 5.1097 - val_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.4997 - acc: 0.0000e+00 - val_loss: 5.1045 - val_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.4985 - acc: 0.0000e+00 - val_loss: 5.1058 - val_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.4973 - acc: 0.0000e+00 - val_loss: 5.1031 - val_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 3.4962 - acc: 0.0000e+00 - val_loss: 5.1011 - val_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 15ms/step - loss: 3.4951 - acc: 0.0000e+00 - val_loss: 5.0993 - val_acc: 0.0000e+00\n",
            "With filter = 128, kernel_size = 8, layer_activation = sigmoid, dense_layer = 50, dense_activation = relu, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 11ms/step - loss: 3.8754 - acc: 0.0000e+00 - val_loss: 4.2905 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.5324 - acc: 0.0000e+00 - val_loss: 4.2601 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.4526 - acc: 0.0000e+00 - val_loss: 4.1873 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 3.2592 - acc: 0.0000e+00 - val_loss: 3.9601 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2345 - acc: 0.0000e+00 - val_loss: 3.9477 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2311 - acc: 0.0000e+00 - val_loss: 3.9452 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2283 - acc: 0.0000e+00 - val_loss: 3.9423 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2258 - acc: 0.0000e+00 - val_loss: 3.9392 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2233 - acc: 0.0000e+00 - val_loss: 3.9357 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2209 - acc: 0.0000e+00 - val_loss: 3.9333 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2184 - acc: 0.0000e+00 - val_loss: 3.9312 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2158 - acc: 0.0000e+00 - val_loss: 3.9371 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2132 - acc: 0.0000e+00 - val_loss: 3.9345 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2105 - acc: 0.0000e+00 - val_loss: 3.9291 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.2077 - acc: 0.0000e+00 - val_loss: 3.9226 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.1197 - acc: 0.0000e+00 - val_loss: 3.6952 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.0613 - acc: 0.0000e+00 - val_loss: 3.6817 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.0578 - acc: 0.0000e+00 - val_loss: 3.6852 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.0540 - acc: 0.0000e+00 - val_loss: 3.6763 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.0500 - acc: 0.0000e+00 - val_loss: 3.6826 - val_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.0457 - acc: 0.0000e+00 - val_loss: 3.6738 - val_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.0413 - acc: 0.0000e+00 - val_loss: 3.6666 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.0364 - acc: 0.0000e+00 - val_loss: 3.6676 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.0313 - acc: 0.0000e+00 - val_loss: 3.6420 - val_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.0261 - acc: 0.0000e+00 - val_loss: 3.6445 - val_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.0203 - acc: 0.0000e+00 - val_loss: 3.6369 - val_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.0145 - acc: 0.0000e+00 - val_loss: 3.6429 - val_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.0080 - acc: 0.0000e+00 - val_loss: 3.6352 - val_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 3.0014 - acc: 0.0000e+00 - val_loss: 3.6408 - val_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.9950 - acc: 0.0000e+00 - val_loss: 3.6178 - val_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.9881 - acc: 0.0000e+00 - val_loss: 3.6107 - val_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.9810 - acc: 0.0000e+00 - val_loss: 3.6104 - val_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.9737 - acc: 0.0000e+00 - val_loss: 3.5924 - val_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.9669 - acc: 0.0000e+00 - val_loss: 3.5806 - val_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.9591 - acc: 0.0000e+00 - val_loss: 3.5847 - val_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.9517 - acc: 0.0000e+00 - val_loss: 3.5882 - val_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.9449 - acc: 0.0000e+00 - val_loss: 3.5749 - val_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.9375 - acc: 0.0000e+00 - val_loss: 3.5672 - val_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.9305 - acc: 0.0000e+00 - val_loss: 3.5557 - val_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 2.9232 - acc: 0.0000e+00 - val_loss: 3.5599 - val_acc: 0.0000e+00\n",
            "With filter = 128, kernel_size = 8, layer_activation = sigmoid, dense_layer = 50, dense_activation = relu, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 17ms/step - loss: 4.6226 - acc: 0.0000e+00 - val_loss: 6.2903 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.3459 - acc: 0.0000e+00 - val_loss: 6.0034 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2514 - acc: 0.0000e+00 - val_loss: 5.9719 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2399 - acc: 0.0000e+00 - val_loss: 5.9531 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2342 - acc: 0.0000e+00 - val_loss: 5.9439 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2302 - acc: 0.0000e+00 - val_loss: 5.9325 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2273 - acc: 0.0000e+00 - val_loss: 5.9265 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2250 - acc: 0.0000e+00 - val_loss: 5.9231 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2232 - acc: 0.0000e+00 - val_loss: 5.9260 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2217 - acc: 0.0000e+00 - val_loss: 5.9115 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2204 - acc: 0.0000e+00 - val_loss: 5.9156 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2192 - acc: 0.0000e+00 - val_loss: 5.9125 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2181 - acc: 0.0000e+00 - val_loss: 5.9107 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2171 - acc: 0.0000e+00 - val_loss: 5.9100 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2161 - acc: 0.0000e+00 - val_loss: 5.9058 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2152 - acc: 0.0000e+00 - val_loss: 5.9101 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2142 - acc: 0.0000e+00 - val_loss: 5.9098 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2133 - acc: 0.0000e+00 - val_loss: 5.9054 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2124 - acc: 0.0000e+00 - val_loss: 5.9073 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2115 - acc: 0.0000e+00 - val_loss: 5.9022 - val_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2107 - acc: 0.0000e+00 - val_loss: 5.9051 - val_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2097 - acc: 0.0000e+00 - val_loss: 5.9016 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2088 - acc: 0.0000e+00 - val_loss: 5.8944 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2080 - acc: 0.0000e+00 - val_loss: 5.8974 - val_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2069 - acc: 0.0000e+00 - val_loss: 5.8995 - val_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2060 - acc: 0.0000e+00 - val_loss: 5.8978 - val_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2050 - acc: 0.0000e+00 - val_loss: 5.8983 - val_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.2034 - acc: 0.0000e+00 - val_loss: 5.8704 - val_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.0747 - acc: 0.0000e+00 - val_loss: 5.6680 - val_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.0608 - acc: 0.0000e+00 - val_loss: 5.6592 - val_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.0596 - acc: 0.0000e+00 - val_loss: 5.6640 - val_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.0584 - acc: 0.0000e+00 - val_loss: 5.6622 - val_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.0572 - acc: 0.0000e+00 - val_loss: 5.6616 - val_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.0559 - acc: 0.0000e+00 - val_loss: 5.6625 - val_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.0547 - acc: 0.0000e+00 - val_loss: 5.6573 - val_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.0533 - acc: 0.0000e+00 - val_loss: 5.6532 - val_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.0520 - acc: 0.0000e+00 - val_loss: 5.6524 - val_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.0505 - acc: 0.0000e+00 - val_loss: 5.6612 - val_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.0493 - acc: 0.0000e+00 - val_loss: 5.6470 - val_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 14ms/step - loss: 4.0477 - acc: 0.0000e+00 - val_loss: 5.6504 - val_acc: 0.0000e+00\n",
            "With filter = 128, kernel_size = 8, layer_activation = sigmoid, dense_layer = 50, dense_activation = relu, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.1190 - acc: 0.4990 - val_loss: 0.8306 - val_acc: 0.5982\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.9069 - acc: 0.5942 - val_loss: 0.8338 - val_acc: 0.6050\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.8486 - acc: 0.6106 - val_loss: 0.7497 - val_acc: 0.6555\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.7928 - acc: 0.6453 - val_loss: 0.7769 - val_acc: 0.6416\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.7543 - acc: 0.6716 - val_loss: 0.6633 - val_acc: 0.7112\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.7267 - acc: 0.6975 - val_loss: 0.6716 - val_acc: 0.7009\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6891 - acc: 0.7011 - val_loss: 0.6482 - val_acc: 0.7133\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6544 - acc: 0.7081 - val_loss: 0.6064 - val_acc: 0.7365\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6084 - acc: 0.7255 - val_loss: 0.6167 - val_acc: 0.7282\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5864 - acc: 0.7469 - val_loss: 0.5895 - val_acc: 0.7457\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5673 - acc: 0.7642 - val_loss: 0.5795 - val_acc: 0.7586\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5487 - acc: 0.7803 - val_loss: 0.5655 - val_acc: 0.7679\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5315 - acc: 0.7939 - val_loss: 0.5474 - val_acc: 0.7824\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5141 - acc: 0.8043 - val_loss: 0.5417 - val_acc: 0.7886\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4986 - acc: 0.8107 - val_loss: 0.5026 - val_acc: 0.8071\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4828 - acc: 0.8235 - val_loss: 0.5139 - val_acc: 0.8071\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4688 - acc: 0.8295 - val_loss: 0.4754 - val_acc: 0.8247\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4540 - acc: 0.8437 - val_loss: 0.4931 - val_acc: 0.8210\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4363 - acc: 0.8562 - val_loss: 0.4554 - val_acc: 0.8339\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4229 - acc: 0.8592 - val_loss: 0.4365 - val_acc: 0.8453\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4107 - acc: 0.8704 - val_loss: 0.4490 - val_acc: 0.8422\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4193 - acc: 0.8762 - val_loss: 0.4331 - val_acc: 0.8504\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3834 - acc: 0.8811 - val_loss: 0.4222 - val_acc: 0.8479\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3708 - acc: 0.8858 - val_loss: 0.4073 - val_acc: 0.8597\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3571 - acc: 0.8928 - val_loss: 0.4086 - val_acc: 0.8540\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3451 - acc: 0.8931 - val_loss: 0.3947 - val_acc: 0.8654\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3380 - acc: 0.8959 - val_loss: 0.3883 - val_acc: 0.8700\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3312 - acc: 0.9015 - val_loss: 0.3829 - val_acc: 0.8731\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3243 - acc: 0.9052 - val_loss: 0.3736 - val_acc: 0.8757\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3165 - acc: 0.9088 - val_loss: 0.3627 - val_acc: 0.8798\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3106 - acc: 0.9106 - val_loss: 0.3589 - val_acc: 0.8824\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3039 - acc: 0.9173 - val_loss: 0.3534 - val_acc: 0.8845\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2964 - acc: 0.9235 - val_loss: 0.3351 - val_acc: 0.8891\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.2899 - acc: 0.9264 - val_loss: 0.3278 - val_acc: 0.9025\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2840 - acc: 0.9283 - val_loss: 0.3238 - val_acc: 0.9046\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2776 - acc: 0.9327 - val_loss: 0.3245 - val_acc: 0.8938\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2718 - acc: 0.9354 - val_loss: 0.3172 - val_acc: 0.9067\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2657 - acc: 0.9378 - val_loss: 0.3158 - val_acc: 0.9067\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2598 - acc: 0.9397 - val_loss: 0.3112 - val_acc: 0.9082\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2540 - acc: 0.9415 - val_loss: 0.3051 - val_acc: 0.9092\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 1, dense_activation = relu, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 1.8524 - acc: 0.3925 - val_loss: 1.4345 - val_acc: 0.4502\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.2893 - acc: 0.4603 - val_loss: 1.3941 - val_acc: 0.4440\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.1043 - acc: 0.4741 - val_loss: 1.3830 - val_acc: 0.4487\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.0563 - acc: 0.4753 - val_loss: 1.0899 - val_acc: 0.5023\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.0045 - acc: 0.4952 - val_loss: 1.0849 - val_acc: 0.5106\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.9713 - acc: 0.5119 - val_loss: 0.9982 - val_acc: 0.5410\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.9377 - acc: 0.5302 - val_loss: 0.9812 - val_acc: 0.5503\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.9203 - acc: 0.5406 - val_loss: 0.9553 - val_acc: 0.5616\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.8936 - acc: 0.5558 - val_loss: 0.9030 - val_acc: 0.6055\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.8603 - acc: 0.5835 - val_loss: 0.8971 - val_acc: 0.6055\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.8442 - acc: 0.5954 - val_loss: 0.8967 - val_acc: 0.6039\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.8247 - acc: 0.5921 - val_loss: 0.9067 - val_acc: 0.6060\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.8143 - acc: 0.6241 - val_loss: 0.7283 - val_acc: 0.6694\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7977 - acc: 0.6288 - val_loss: 0.8568 - val_acc: 0.6142\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7842 - acc: 0.6221 - val_loss: 0.8018 - val_acc: 0.6426\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7696 - acc: 0.6242 - val_loss: 0.8359 - val_acc: 0.6240\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7617 - acc: 0.6291 - val_loss: 0.7911 - val_acc: 0.6514\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7491 - acc: 0.6360 - val_loss: 0.8045 - val_acc: 0.6457\n",
            "Epoch 18: early stopping\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 1, dense_activation = relu, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 1.0784 - acc: 0.4850 - val_loss: 0.9658 - val_acc: 0.5508\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.8219 - acc: 0.6260 - val_loss: 0.7806 - val_acc: 0.6462\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6555 - acc: 0.6592 - val_loss: 0.6802 - val_acc: 0.6988\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5924 - acc: 0.7019 - val_loss: 0.6051 - val_acc: 0.7437\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5512 - acc: 0.7331 - val_loss: 0.6340 - val_acc: 0.7282\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5094 - acc: 0.7534 - val_loss: 0.5242 - val_acc: 0.7958\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4598 - acc: 0.7854 - val_loss: 0.5328 - val_acc: 0.7829\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4296 - acc: 0.8010 - val_loss: 0.5183 - val_acc: 0.7922\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4016 - acc: 0.8164 - val_loss: 0.5057 - val_acc: 0.7947\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3775 - acc: 0.8377 - val_loss: 0.5226 - val_acc: 0.8004\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3499 - acc: 0.8455 - val_loss: 0.4599 - val_acc: 0.8288\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3287 - acc: 0.8613 - val_loss: 0.4506 - val_acc: 0.8334\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3099 - acc: 0.8703 - val_loss: 0.4285 - val_acc: 0.8468\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2913 - acc: 0.8839 - val_loss: 0.4341 - val_acc: 0.8473\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2749 - acc: 0.8931 - val_loss: 0.3939 - val_acc: 0.8649\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2597 - acc: 0.9012 - val_loss: 0.3880 - val_acc: 0.8654\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2456 - acc: 0.9093 - val_loss: 0.3628 - val_acc: 0.8793\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.2283 - acc: 0.9216 - val_loss: 0.3635 - val_acc: 0.8798\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2116 - acc: 0.9278 - val_loss: 0.3524 - val_acc: 0.8809\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1991 - acc: 0.9349 - val_loss: 0.3266 - val_acc: 0.9020\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1874 - acc: 0.9404 - val_loss: 0.3352 - val_acc: 0.9005\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1759 - acc: 0.9438 - val_loss: 0.3038 - val_acc: 0.9082\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1658 - acc: 0.9480 - val_loss: 0.3032 - val_acc: 0.9113\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1575 - acc: 0.9507 - val_loss: 0.3062 - val_acc: 0.9123\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1488 - acc: 0.9531 - val_loss: 0.3067 - val_acc: 0.9144\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1400 - acc: 0.9554 - val_loss: 0.3103 - val_acc: 0.9159\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1324 - acc: 0.9573 - val_loss: 0.2633 - val_acc: 0.9211\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1253 - acc: 0.9612 - val_loss: 0.2666 - val_acc: 0.9232\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1188 - acc: 0.9638 - val_loss: 0.2728 - val_acc: 0.9226\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1125 - acc: 0.9657 - val_loss: 0.2579 - val_acc: 0.9252\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1064 - acc: 0.9687 - val_loss: 0.2684 - val_acc: 0.9263\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1006 - acc: 0.9718 - val_loss: 0.2579 - val_acc: 0.9288\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0955 - acc: 0.9742 - val_loss: 0.2573 - val_acc: 0.9293\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0908 - acc: 0.9756 - val_loss: 0.2819 - val_acc: 0.9314\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0865 - acc: 0.9768 - val_loss: 0.2582 - val_acc: 0.9319\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0828 - acc: 0.9786 - val_loss: 0.2402 - val_acc: 0.9319\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0790 - acc: 0.9792 - val_loss: 0.2365 - val_acc: 0.9324\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0751 - acc: 0.9801 - val_loss: 0.2481 - val_acc: 0.9340\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0729 - acc: 0.9805 - val_loss: 0.2342 - val_acc: 0.9345\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0684 - acc: 0.9816 - val_loss: 0.2275 - val_acc: 0.9319\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 1, dense_activation = relu, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 3.1256 - acc: 0.3284 - val_loss: 2.0011 - val_acc: 0.3646\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.3428 - acc: 0.4407 - val_loss: 1.1525 - val_acc: 0.4528\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.9768 - acc: 0.5154 - val_loss: 0.9495 - val_acc: 0.5353\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.8998 - acc: 0.5737 - val_loss: 0.9355 - val_acc: 0.5425\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.8376 - acc: 0.5932 - val_loss: 0.9030 - val_acc: 0.5668\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7896 - acc: 0.6153 - val_loss: 0.8336 - val_acc: 0.6029\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7503 - acc: 0.6463 - val_loss: 0.7822 - val_acc: 0.6343\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.8104 - acc: 0.6738 - val_loss: 0.8998 - val_acc: 0.7607\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7455 - acc: 0.6876 - val_loss: 0.7471 - val_acc: 0.6596\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6710 - acc: 0.6945 - val_loss: 0.7210 - val_acc: 0.6756\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6447 - acc: 0.7081 - val_loss: 0.7118 - val_acc: 0.6859\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6251 - acc: 0.7148 - val_loss: 0.6891 - val_acc: 0.6978\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6083 - acc: 0.7304 - val_loss: 0.6618 - val_acc: 0.7138\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5893 - acc: 0.7510 - val_loss: 0.6579 - val_acc: 0.7236\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.5720 - acc: 0.7607 - val_loss: 0.6626 - val_acc: 0.7282\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5717 - acc: 0.7527 - val_loss: 0.5855 - val_acc: 0.7612\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5352 - acc: 0.7776 - val_loss: 0.6175 - val_acc: 0.7390\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5106 - acc: 0.7663 - val_loss: 0.5395 - val_acc: 0.7710\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4748 - acc: 0.7901 - val_loss: 0.5999 - val_acc: 0.7530\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4608 - acc: 0.8012 - val_loss: 0.5358 - val_acc: 0.7777\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4490 - acc: 0.8054 - val_loss: 0.5275 - val_acc: 0.7860\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4381 - acc: 0.8192 - val_loss: 0.5205 - val_acc: 0.7963\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4271 - acc: 0.8223 - val_loss: 0.4909 - val_acc: 0.8045\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4170 - acc: 0.8316 - val_loss: 0.5233 - val_acc: 0.7983\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4064 - acc: 0.8387 - val_loss: 0.4922 - val_acc: 0.8102\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.3955 - acc: 0.8490 - val_loss: 0.4968 - val_acc: 0.8138\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.3864 - acc: 0.8534 - val_loss: 0.4804 - val_acc: 0.8205\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.3767 - acc: 0.8606 - val_loss: 0.4764 - val_acc: 0.8231\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3619 - acc: 0.8576 - val_loss: 0.4505 - val_acc: 0.8334\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3454 - acc: 0.8704 - val_loss: 0.4603 - val_acc: 0.8324\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.3373 - acc: 0.8757 - val_loss: 0.4344 - val_acc: 0.8412\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.3294 - acc: 0.8798 - val_loss: 0.4368 - val_acc: 0.8417\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 19ms/step - loss: 0.3204 - acc: 0.8858 - val_loss: 0.4405 - val_acc: 0.8432\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3127 - acc: 0.8879 - val_loss: 0.4365 - val_acc: 0.8442\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3061 - acc: 0.8953 - val_loss: 0.4073 - val_acc: 0.8623\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2935 - acc: 0.8970 - val_loss: 0.4024 - val_acc: 0.8628\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2863 - acc: 0.9007 - val_loss: 0.4005 - val_acc: 0.8638\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2875 - acc: 0.9086 - val_loss: 0.3875 - val_acc: 0.8773\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2714 - acc: 0.9081 - val_loss: 0.3902 - val_acc: 0.8706\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2635 - acc: 0.9127 - val_loss: 0.3855 - val_acc: 0.8721\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 1, dense_activation = relu, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.0957 - acc: 0.3622 - val_loss: 1.0897 - val_acc: 0.6674\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.9486 - acc: 0.6561 - val_loss: 0.8352 - val_acc: 0.7153\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.7705 - acc: 0.7274 - val_loss: 0.8661 - val_acc: 0.7282\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6305 - acc: 0.7651 - val_loss: 0.6128 - val_acc: 0.7824\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5704 - acc: 0.7936 - val_loss: 0.6743 - val_acc: 0.7906\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5256 - acc: 0.8094 - val_loss: 0.7064 - val_acc: 0.7870\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5443 - acc: 0.8199 - val_loss: 0.6471 - val_acc: 0.8221\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5820 - acc: 0.8205 - val_loss: 0.5472 - val_acc: 0.8231\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4206 - acc: 0.8681 - val_loss: 0.5264 - val_acc: 0.8396\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3823 - acc: 0.8762 - val_loss: 0.5341 - val_acc: 0.8339\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4610 - acc: 0.8582 - val_loss: 0.4621 - val_acc: 0.8685\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.6266 - acc: 0.7973 - val_loss: 2.9409 - val_acc: 0.7731\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 6.6247 - acc: 0.7795 - val_loss: 2.8142 - val_acc: 0.7715\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.6409 - acc: 0.7595 - val_loss: 1.0915 - val_acc: 0.7060\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4413 - acc: 0.8182 - val_loss: 0.6215 - val_acc: 0.8118\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3924 - acc: 0.8387 - val_loss: 0.5653 - val_acc: 0.8319\n",
            "Epoch 16: early stopping\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 1, dense_activation = relu, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 1.7725 - acc: 0.4820 - val_loss: 1.2392 - val_acc: 0.6699\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.2580 - acc: 0.5222 - val_loss: 1.2423 - val_acc: 0.4920\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.0757 - acc: 0.5010 - val_loss: 1.1203 - val_acc: 0.5023\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.9158 - acc: 0.5558 - val_loss: 0.9115 - val_acc: 0.5606\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.8470 - acc: 0.5997 - val_loss: 0.8516 - val_acc: 0.5854\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.8087 - acc: 0.6146 - val_loss: 0.8245 - val_acc: 0.6008\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.7806 - acc: 0.6335 - val_loss: 0.7924 - val_acc: 0.6199\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 22ms/step - loss: 0.7514 - acc: 0.6508 - val_loss: 0.7570 - val_acc: 0.6441\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.7260 - acc: 0.6731 - val_loss: 0.7397 - val_acc: 0.6570\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.7022 - acc: 0.6858 - val_loss: 0.7506 - val_acc: 0.6612\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.6776 - acc: 0.6976 - val_loss: 0.7364 - val_acc: 0.6797\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.6545 - acc: 0.7093 - val_loss: 0.6839 - val_acc: 0.7014\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.6353 - acc: 0.7229 - val_loss: 0.7123 - val_acc: 0.6978\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.6188 - acc: 0.7328 - val_loss: 0.6820 - val_acc: 0.7112\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6030 - acc: 0.7430 - val_loss: 0.6665 - val_acc: 0.7200\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5870 - acc: 0.7522 - val_loss: 0.6489 - val_acc: 0.7375\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5722 - acc: 0.7663 - val_loss: 0.6695 - val_acc: 0.7256\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5555 - acc: 0.7723 - val_loss: 0.6351 - val_acc: 0.7437\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5375 - acc: 0.7910 - val_loss: 0.5742 - val_acc: 0.7803\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5161 - acc: 0.7937 - val_loss: 0.6391 - val_acc: 0.7452\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4999 - acc: 0.7926 - val_loss: 0.5841 - val_acc: 0.7726\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4857 - acc: 0.8059 - val_loss: 0.5359 - val_acc: 0.7958\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4744 - acc: 0.8151 - val_loss: 0.5332 - val_acc: 0.8040\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4642 - acc: 0.8282 - val_loss: 0.5003 - val_acc: 0.8236\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4533 - acc: 0.8298 - val_loss: 0.5300 - val_acc: 0.8061\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4426 - acc: 0.8355 - val_loss: 0.5086 - val_acc: 0.8164\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4331 - acc: 0.8405 - val_loss: 0.5223 - val_acc: 0.8138\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4240 - acc: 0.8486 - val_loss: 0.5007 - val_acc: 0.8205\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4152 - acc: 0.8524 - val_loss: 0.4922 - val_acc: 0.8262\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4068 - acc: 0.8596 - val_loss: 0.4864 - val_acc: 0.8319\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4196 - acc: 0.8464 - val_loss: 1.6577 - val_acc: 0.6354\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4366 - acc: 0.8489 - val_loss: 0.4779 - val_acc: 0.8453\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3866 - acc: 0.8784 - val_loss: 0.5396 - val_acc: 0.8195\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3759 - acc: 0.8789 - val_loss: 0.4701 - val_acc: 0.8535\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.3652 - acc: 0.8850 - val_loss: 0.4555 - val_acc: 0.8628\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3576 - acc: 0.8976 - val_loss: 0.4502 - val_acc: 0.8644\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3511 - acc: 0.9001 - val_loss: 0.4581 - val_acc: 0.8644\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.3445 - acc: 0.9044 - val_loss: 0.4426 - val_acc: 0.8695\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.3374 - acc: 0.9096 - val_loss: 0.4370 - val_acc: 0.8731\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3314 - acc: 0.9128 - val_loss: 0.4266 - val_acc: 0.8767\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 1, dense_activation = relu, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 0.6846 - acc: 0.4264 - val_loss: 0.7177 - val_acc: 0.4626\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.6367 - acc: 0.5956 - val_loss: 0.6463 - val_acc: 0.6560\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.6016 - acc: 0.6818 - val_loss: 0.6130 - val_acc: 0.6973\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.5740 - acc: 0.7208 - val_loss: 0.5859 - val_acc: 0.7169\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.5508 - acc: 0.7440 - val_loss: 0.5623 - val_acc: 0.7323\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.5308 - acc: 0.7645 - val_loss: 0.5565 - val_acc: 0.7323\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.5129 - acc: 0.7752 - val_loss: 0.5197 - val_acc: 0.7741\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.4972 - acc: 0.7981 - val_loss: 0.5173 - val_acc: 0.7705\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.4826 - acc: 0.8057 - val_loss: 0.5022 - val_acc: 0.7808\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4691 - acc: 0.8139 - val_loss: 0.4932 - val_acc: 0.7849\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4568 - acc: 0.8245 - val_loss: 0.4793 - val_acc: 0.7932\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4450 - acc: 0.8342 - val_loss: 0.4759 - val_acc: 0.7953\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4346 - acc: 0.8395 - val_loss: 0.4518 - val_acc: 0.8200\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.4247 - acc: 0.8455 - val_loss: 0.4439 - val_acc: 0.8241\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.4151 - acc: 0.8552 - val_loss: 0.4390 - val_acc: 0.8257\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.4061 - acc: 0.8582 - val_loss: 0.4142 - val_acc: 0.8530\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3979 - acc: 0.8674 - val_loss: 0.4279 - val_acc: 0.8298\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3896 - acc: 0.8652 - val_loss: 0.4005 - val_acc: 0.8582\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3820 - acc: 0.8765 - val_loss: 0.4174 - val_acc: 0.8334\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3747 - acc: 0.8769 - val_loss: 0.4000 - val_acc: 0.8520\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3677 - acc: 0.8814 - val_loss: 0.3975 - val_acc: 0.8510\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3609 - acc: 0.8852 - val_loss: 0.3744 - val_acc: 0.8726\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3542 - acc: 0.8890 - val_loss: 0.3797 - val_acc: 0.8644\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3482 - acc: 0.8945 - val_loss: 0.3765 - val_acc: 0.8638\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3420 - acc: 0.8952 - val_loss: 0.3587 - val_acc: 0.8778\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3361 - acc: 0.8990 - val_loss: 0.3608 - val_acc: 0.8736\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3305 - acc: 0.9030 - val_loss: 0.3557 - val_acc: 0.8788\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3248 - acc: 0.9066 - val_loss: 0.3675 - val_acc: 0.8669\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3197 - acc: 0.9070 - val_loss: 0.3588 - val_acc: 0.8700\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3149 - acc: 0.9095 - val_loss: 0.3519 - val_acc: 0.8742\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3094 - acc: 0.9113 - val_loss: 0.3383 - val_acc: 0.8834\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3046 - acc: 0.9162 - val_loss: 0.3415 - val_acc: 0.8819\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2999 - acc: 0.9184 - val_loss: 0.3336 - val_acc: 0.8850\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2952 - acc: 0.9204 - val_loss: 0.3201 - val_acc: 0.8963\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2910 - acc: 0.9219 - val_loss: 0.3314 - val_acc: 0.8829\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2863 - acc: 0.9237 - val_loss: 0.3179 - val_acc: 0.8953\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2820 - acc: 0.9262 - val_loss: 0.3197 - val_acc: 0.8922\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2777 - acc: 0.9311 - val_loss: 0.3229 - val_acc: 0.8871\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2735 - acc: 0.9293 - val_loss: 0.3034 - val_acc: 0.9025\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2698 - acc: 0.9351 - val_loss: 0.3175 - val_acc: 0.8896\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 1, dense_activation = sigmoid, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 0.6849 - acc: 0.4698 - val_loss: 0.7130 - val_acc: 0.5034\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.6491 - acc: 0.5652 - val_loss: 0.6677 - val_acc: 0.5967\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6223 - acc: 0.6353 - val_loss: 0.6323 - val_acc: 0.6524\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5999 - acc: 0.6765 - val_loss: 0.6137 - val_acc: 0.6787\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5809 - acc: 0.7103 - val_loss: 0.5909 - val_acc: 0.7071\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5641 - acc: 0.7301 - val_loss: 0.5854 - val_acc: 0.7055\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5490 - acc: 0.7469 - val_loss: 0.5602 - val_acc: 0.7329\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5354 - acc: 0.7569 - val_loss: 0.5610 - val_acc: 0.7251\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5228 - acc: 0.7718 - val_loss: 0.5280 - val_acc: 0.7633\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5109 - acc: 0.7759 - val_loss: 0.5215 - val_acc: 0.7638\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5001 - acc: 0.7934 - val_loss: 0.5252 - val_acc: 0.7597\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4897 - acc: 0.8005 - val_loss: 0.5141 - val_acc: 0.7715\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4800 - acc: 0.8052 - val_loss: 0.5001 - val_acc: 0.7808\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4712 - acc: 0.8121 - val_loss: 0.4852 - val_acc: 0.7968\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4622 - acc: 0.8204 - val_loss: 0.4801 - val_acc: 0.8014\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4540 - acc: 0.8211 - val_loss: 0.4751 - val_acc: 0.8061\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4463 - acc: 0.8284 - val_loss: 0.4705 - val_acc: 0.8081\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4386 - acc: 0.8344 - val_loss: 0.4649 - val_acc: 0.8123\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4315 - acc: 0.8349 - val_loss: 0.4356 - val_acc: 0.8427\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4246 - acc: 0.8480 - val_loss: 0.4524 - val_acc: 0.8210\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4183 - acc: 0.8478 - val_loss: 0.4372 - val_acc: 0.8308\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4118 - acc: 0.8468 - val_loss: 0.4344 - val_acc: 0.8324\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4056 - acc: 0.8573 - val_loss: 0.4317 - val_acc: 0.8329\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3998 - acc: 0.8571 - val_loss: 0.4229 - val_acc: 0.8417\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3941 - acc: 0.8625 - val_loss: 0.4118 - val_acc: 0.8515\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3886 - acc: 0.8673 - val_loss: 0.4093 - val_acc: 0.8520\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3833 - acc: 0.8725 - val_loss: 0.4062 - val_acc: 0.8530\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3781 - acc: 0.8722 - val_loss: 0.4001 - val_acc: 0.8587\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3730 - acc: 0.8834 - val_loss: 0.4086 - val_acc: 0.8463\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3679 - acc: 0.8770 - val_loss: 0.3875 - val_acc: 0.8680\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3633 - acc: 0.8847 - val_loss: 0.3925 - val_acc: 0.8577\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3590 - acc: 0.8882 - val_loss: 0.3918 - val_acc: 0.8561\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3541 - acc: 0.8892 - val_loss: 0.3706 - val_acc: 0.8860\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3499 - acc: 0.8968 - val_loss: 0.3777 - val_acc: 0.8685\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3452 - acc: 0.8937 - val_loss: 0.3634 - val_acc: 0.8891\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3412 - acc: 0.8999 - val_loss: 0.3719 - val_acc: 0.8731\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3370 - acc: 0.9007 - val_loss: 0.3676 - val_acc: 0.8767\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3328 - acc: 0.9032 - val_loss: 0.3729 - val_acc: 0.8690\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3288 - acc: 0.9033 - val_loss: 0.3557 - val_acc: 0.8876\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3252 - acc: 0.9061 - val_loss: 0.3562 - val_acc: 0.8850\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 1, dense_activation = sigmoid, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 0.6498 - acc: 0.5660 - val_loss: 0.6518 - val_acc: 0.6359\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.5564 - acc: 0.7355 - val_loss: 0.6230 - val_acc: 0.6555\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.4999 - acc: 0.7921 - val_loss: 0.5014 - val_acc: 0.7916\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.4580 - acc: 0.8264 - val_loss: 0.4762 - val_acc: 0.8025\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.4257 - acc: 0.8459 - val_loss: 0.4422 - val_acc: 0.8236\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3985 - acc: 0.8596 - val_loss: 0.3759 - val_acc: 0.8896\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3766 - acc: 0.8770 - val_loss: 0.3774 - val_acc: 0.8865\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3563 - acc: 0.8859 - val_loss: 0.3724 - val_acc: 0.8793\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3383 - acc: 0.8966 - val_loss: 0.3397 - val_acc: 0.8999\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3224 - acc: 0.9068 - val_loss: 0.3441 - val_acc: 0.8943\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3074 - acc: 0.9146 - val_loss: 0.3728 - val_acc: 0.8587\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2940 - acc: 0.9170 - val_loss: 0.3088 - val_acc: 0.9097\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2810 - acc: 0.9266 - val_loss: 0.3322 - val_acc: 0.8901\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2697 - acc: 0.9304 - val_loss: 0.3192 - val_acc: 0.8984\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2581 - acc: 0.9369 - val_loss: 0.2879 - val_acc: 0.9134\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.2482 - acc: 0.9434 - val_loss: 0.2898 - val_acc: 0.9092\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.2392 - acc: 0.9430 - val_loss: 0.2633 - val_acc: 0.9216\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.2298 - acc: 0.9504 - val_loss: 0.2839 - val_acc: 0.9113\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2211 - acc: 0.9524 - val_loss: 0.2592 - val_acc: 0.9242\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2129 - acc: 0.9577 - val_loss: 0.2687 - val_acc: 0.9180\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2053 - acc: 0.9602 - val_loss: 0.2473 - val_acc: 0.9278\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.1981 - acc: 0.9618 - val_loss: 0.2461 - val_acc: 0.9293\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.1909 - acc: 0.9647 - val_loss: 0.2531 - val_acc: 0.9237\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.1846 - acc: 0.9665 - val_loss: 0.2379 - val_acc: 0.9309\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.1776 - acc: 0.9696 - val_loss: 0.2358 - val_acc: 0.9324\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.1715 - acc: 0.9709 - val_loss: 0.2257 - val_acc: 0.9350\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.1658 - acc: 0.9719 - val_loss: 0.2270 - val_acc: 0.9345\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1598 - acc: 0.9732 - val_loss: 0.2299 - val_acc: 0.9314\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1549 - acc: 0.9750 - val_loss: 0.2058 - val_acc: 0.9355\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.1489 - acc: 0.9769 - val_loss: 0.2048 - val_acc: 0.9350\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.1448 - acc: 0.9772 - val_loss: 0.2027 - val_acc: 0.9355\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.1392 - acc: 0.9791 - val_loss: 0.1997 - val_acc: 0.9360\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.1345 - acc: 0.9796 - val_loss: 0.1907 - val_acc: 0.9433\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.1302 - acc: 0.9813 - val_loss: 0.2017 - val_acc: 0.9376\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.1257 - acc: 0.9813 - val_loss: 0.1840 - val_acc: 0.9458\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.1217 - acc: 0.9830 - val_loss: 0.1820 - val_acc: 0.9458\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.1176 - acc: 0.9831 - val_loss: 0.1821 - val_acc: 0.9433\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.1136 - acc: 0.9853 - val_loss: 0.1794 - val_acc: 0.9469\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.1103 - acc: 0.9857 - val_loss: 0.1857 - val_acc: 0.9397\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.1066 - acc: 0.9861 - val_loss: 0.1800 - val_acc: 0.9453\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 1, dense_activation = sigmoid, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 24ms/step - loss: 0.6683 - acc: 0.4891 - val_loss: 0.6419 - val_acc: 0.6720\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.5845 - acc: 0.7208 - val_loss: 0.6213 - val_acc: 0.6663\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.5352 - acc: 0.7580 - val_loss: 0.5302 - val_acc: 0.7633\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4974 - acc: 0.7925 - val_loss: 0.4978 - val_acc: 0.7916\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4670 - acc: 0.8192 - val_loss: 0.4617 - val_acc: 0.8262\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4419 - acc: 0.8335 - val_loss: 0.4715 - val_acc: 0.7989\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4203 - acc: 0.8473 - val_loss: 0.4312 - val_acc: 0.8432\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4012 - acc: 0.8529 - val_loss: 0.4285 - val_acc: 0.8375\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3840 - acc: 0.8712 - val_loss: 0.4089 - val_acc: 0.8535\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.3680 - acc: 0.8815 - val_loss: 0.3882 - val_acc: 0.8706\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3543 - acc: 0.8868 - val_loss: 0.3761 - val_acc: 0.8783\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3408 - acc: 0.8959 - val_loss: 0.3741 - val_acc: 0.8731\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.3286 - acc: 0.9055 - val_loss: 0.3695 - val_acc: 0.8716\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.3174 - acc: 0.9084 - val_loss: 0.3470 - val_acc: 0.8886\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3073 - acc: 0.9182 - val_loss: 0.3476 - val_acc: 0.8834\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2974 - acc: 0.9224 - val_loss: 0.3416 - val_acc: 0.8850\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.2878 - acc: 0.9242 - val_loss: 0.3199 - val_acc: 0.8979\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2794 - acc: 0.9292 - val_loss: 0.3255 - val_acc: 0.8963\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2707 - acc: 0.9344 - val_loss: 0.3050 - val_acc: 0.8999\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2632 - acc: 0.9348 - val_loss: 0.3059 - val_acc: 0.9005\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2549 - acc: 0.9393 - val_loss: 0.2910 - val_acc: 0.9041\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2478 - acc: 0.9427 - val_loss: 0.2876 - val_acc: 0.9046\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2409 - acc: 0.9465 - val_loss: 0.2870 - val_acc: 0.9046\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2342 - acc: 0.9489 - val_loss: 0.2790 - val_acc: 0.9092\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2278 - acc: 0.9523 - val_loss: 0.2867 - val_acc: 0.9051\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2220 - acc: 0.9546 - val_loss: 0.2778 - val_acc: 0.9087\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2164 - acc: 0.9578 - val_loss: 0.2771 - val_acc: 0.9072\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2102 - acc: 0.9589 - val_loss: 0.2663 - val_acc: 0.9103\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.2053 - acc: 0.9605 - val_loss: 0.2622 - val_acc: 0.9118\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.2002 - acc: 0.9617 - val_loss: 0.2487 - val_acc: 0.9221\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1948 - acc: 0.9649 - val_loss: 0.2540 - val_acc: 0.9154\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1899 - acc: 0.9662 - val_loss: 0.2453 - val_acc: 0.9206\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1852 - acc: 0.9684 - val_loss: 0.2412 - val_acc: 0.9232\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1805 - acc: 0.9693 - val_loss: 0.2379 - val_acc: 0.9263\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1761 - acc: 0.9705 - val_loss: 0.2293 - val_acc: 0.9309\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1721 - acc: 0.9728 - val_loss: 0.2285 - val_acc: 0.9319\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.1679 - acc: 0.9733 - val_loss: 0.2333 - val_acc: 0.9268\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1637 - acc: 0.9737 - val_loss: 0.2198 - val_acc: 0.9355\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.1598 - acc: 0.9755 - val_loss: 0.2214 - val_acc: 0.9350\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.1563 - acc: 0.9767 - val_loss: 0.2148 - val_acc: 0.9360\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 1, dense_activation = sigmoid, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 0.6179 - acc: 0.6349 - val_loss: 0.5726 - val_acc: 0.7086\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5084 - acc: 0.7887 - val_loss: 0.5083 - val_acc: 0.7664\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4453 - acc: 0.8317 - val_loss: 0.3963 - val_acc: 0.8814\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4024 - acc: 0.8610 - val_loss: 0.3911 - val_acc: 0.8731\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3681 - acc: 0.8827 - val_loss: 0.3762 - val_acc: 0.8747\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3380 - acc: 0.8995 - val_loss: 0.3585 - val_acc: 0.8809\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3142 - acc: 0.9100 - val_loss: 0.3557 - val_acc: 0.8767\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2925 - acc: 0.9225 - val_loss: 0.3075 - val_acc: 0.9051\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2733 - acc: 0.9314 - val_loss: 0.3266 - val_acc: 0.8907\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2556 - acc: 0.9384 - val_loss: 0.2929 - val_acc: 0.9097\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2400 - acc: 0.9435 - val_loss: 0.2638 - val_acc: 0.9237\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2251 - acc: 0.9510 - val_loss: 0.2710 - val_acc: 0.9180\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2122 - acc: 0.9583 - val_loss: 0.2686 - val_acc: 0.9180\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.2000 - acc: 0.9603 - val_loss: 0.2401 - val_acc: 0.9319\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.1887 - acc: 0.9674 - val_loss: 0.2375 - val_acc: 0.9324\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.1784 - acc: 0.9698 - val_loss: 0.2398 - val_acc: 0.9314\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.1694 - acc: 0.9719 - val_loss: 0.2107 - val_acc: 0.9386\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.1596 - acc: 0.9759 - val_loss: 0.2197 - val_acc: 0.9381\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.1510 - acc: 0.9772 - val_loss: 0.2004 - val_acc: 0.9433\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.1434 - acc: 0.9805 - val_loss: 0.2018 - val_acc: 0.9428\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.1359 - acc: 0.9810 - val_loss: 0.1854 - val_acc: 0.9474\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.1295 - acc: 0.9831 - val_loss: 0.1868 - val_acc: 0.9479\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.1225 - acc: 0.9836 - val_loss: 0.1932 - val_acc: 0.9453\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.1162 - acc: 0.9852 - val_loss: 0.1891 - val_acc: 0.9453\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.1105 - acc: 0.9859 - val_loss: 0.1681 - val_acc: 0.9500\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.1051 - acc: 0.9875 - val_loss: 0.1752 - val_acc: 0.9489\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.1001 - acc: 0.9874 - val_loss: 0.1641 - val_acc: 0.9500\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.0949 - acc: 0.9887 - val_loss: 0.1736 - val_acc: 0.9479\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.0903 - acc: 0.9894 - val_loss: 0.1578 - val_acc: 0.9489\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.0863 - acc: 0.9901 - val_loss: 0.1556 - val_acc: 0.9489\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.0820 - acc: 0.9903 - val_loss: 0.1537 - val_acc: 0.9520\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.0780 - acc: 0.9911 - val_loss: 0.1504 - val_acc: 0.9510\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.0744 - acc: 0.9914 - val_loss: 0.1476 - val_acc: 0.9526\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.0712 - acc: 0.9928 - val_loss: 0.1474 - val_acc: 0.9520\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.0681 - acc: 0.9939 - val_loss: 0.1414 - val_acc: 0.9546\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.0648 - acc: 0.9945 - val_loss: 0.1455 - val_acc: 0.9526\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.0616 - acc: 0.9947 - val_loss: 0.1416 - val_acc: 0.9515\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.0589 - acc: 0.9952 - val_loss: 0.1386 - val_acc: 0.9562\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.0564 - acc: 0.9959 - val_loss: 0.1361 - val_acc: 0.9556\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.0540 - acc: 0.9959 - val_loss: 0.1349 - val_acc: 0.9556\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 1, dense_activation = sigmoid, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 0.6396 - acc: 0.5838 - val_loss: 0.6525 - val_acc: 0.6343\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5508 - acc: 0.7412 - val_loss: 0.5902 - val_acc: 0.6952\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4973 - acc: 0.7923 - val_loss: 0.4928 - val_acc: 0.7953\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4553 - acc: 0.8208 - val_loss: 0.4486 - val_acc: 0.8262\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4236 - acc: 0.8478 - val_loss: 0.4455 - val_acc: 0.8200\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3973 - acc: 0.8624 - val_loss: 0.4287 - val_acc: 0.8277\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.3737 - acc: 0.8767 - val_loss: 0.3934 - val_acc: 0.8551\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3534 - acc: 0.8905 - val_loss: 0.3799 - val_acc: 0.8623\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3353 - acc: 0.9011 - val_loss: 0.3727 - val_acc: 0.8613\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.3189 - acc: 0.9065 - val_loss: 0.3375 - val_acc: 0.8932\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.3048 - acc: 0.9164 - val_loss: 0.3360 - val_acc: 0.8917\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2898 - acc: 0.9228 - val_loss: 0.3121 - val_acc: 0.9025\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2778 - acc: 0.9297 - val_loss: 0.3106 - val_acc: 0.9036\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2650 - acc: 0.9319 - val_loss: 0.3031 - val_acc: 0.9036\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2542 - acc: 0.9382 - val_loss: 0.3046 - val_acc: 0.8989\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2441 - acc: 0.9422 - val_loss: 0.2970 - val_acc: 0.9041\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2339 - acc: 0.9475 - val_loss: 0.2651 - val_acc: 0.9237\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2252 - acc: 0.9507 - val_loss: 0.2565 - val_acc: 0.9268\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2166 - acc: 0.9571 - val_loss: 0.2800 - val_acc: 0.9113\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2082 - acc: 0.9596 - val_loss: 0.2789 - val_acc: 0.9092\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1999 - acc: 0.9629 - val_loss: 0.2549 - val_acc: 0.9242\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1923 - acc: 0.9661 - val_loss: 0.2548 - val_acc: 0.9232\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1854 - acc: 0.9675 - val_loss: 0.2415 - val_acc: 0.9247\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1787 - acc: 0.9696 - val_loss: 0.2400 - val_acc: 0.9257\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1723 - acc: 0.9709 - val_loss: 0.2336 - val_acc: 0.9304\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1659 - acc: 0.9730 - val_loss: 0.2130 - val_acc: 0.9381\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1604 - acc: 0.9750 - val_loss: 0.2272 - val_acc: 0.9304\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1544 - acc: 0.9768 - val_loss: 0.2028 - val_acc: 0.9438\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1494 - acc: 0.9779 - val_loss: 0.2134 - val_acc: 0.9345\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1439 - acc: 0.9778 - val_loss: 0.2085 - val_acc: 0.9340\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.1389 - acc: 0.9794 - val_loss: 0.1953 - val_acc: 0.9458\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1349 - acc: 0.9807 - val_loss: 0.2068 - val_acc: 0.9340\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1301 - acc: 0.9821 - val_loss: 0.1875 - val_acc: 0.9464\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1254 - acc: 0.9822 - val_loss: 0.1933 - val_acc: 0.9428\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.1214 - acc: 0.9830 - val_loss: 0.1867 - val_acc: 0.9458\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.1172 - acc: 0.9840 - val_loss: 0.1913 - val_acc: 0.9386\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1133 - acc: 0.9847 - val_loss: 0.1863 - val_acc: 0.9438\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1098 - acc: 0.9858 - val_loss: 0.1823 - val_acc: 0.9443\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1064 - acc: 0.9872 - val_loss: 0.1779 - val_acc: 0.9458\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.1030 - acc: 0.9872 - val_loss: 0.1732 - val_acc: 0.9500\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 1, dense_activation = sigmoid, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 4.5509 - acc: 0.0451 - val_loss: 5.2476 - val_acc: 0.1300\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.3177 - acc: 0.1866 - val_loss: 4.4953 - val_acc: 0.1088\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.9868 - acc: 0.1385 - val_loss: 3.8713 - val_acc: 0.1511\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.6961 - acc: 0.1426 - val_loss: 3.6772 - val_acc: 0.1248\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.6115 - acc: 0.1170 - val_loss: 3.5650 - val_acc: 0.1062\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.5345 - acc: 0.1114 - val_loss: 3.4977 - val_acc: 0.1001\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.4957 - acc: 0.1504 - val_loss: 3.4373 - val_acc: 0.1609\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.4653 - acc: 0.1182 - val_loss: 3.4413 - val_acc: 0.0552\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.4990 - acc: 0.1663 - val_loss: 3.4342 - val_acc: 0.4621\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.5454 - acc: 0.3600 - val_loss: 3.3534 - val_acc: 0.2285\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.4040 - acc: 0.2044 - val_loss: 3.3203 - val_acc: 0.1810\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.3680 - acc: 0.1725 - val_loss: 3.2589 - val_acc: 0.1516\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.3311 - acc: 0.1478 - val_loss: 3.1889 - val_acc: 0.1274\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.2451 - acc: 0.1287 - val_loss: 2.9493 - val_acc: 0.1269\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.9583 - acc: 0.1054 - val_loss: 2.3236 - val_acc: 0.0593\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.7341 - acc: 0.0932 - val_loss: 2.2390 - val_acc: 0.0954\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.7127 - acc: 0.1061 - val_loss: 2.2257 - val_acc: 0.0918\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.7054 - acc: 0.1073 - val_loss: 2.2102 - val_acc: 0.1088\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.6836 - acc: 0.1201 - val_loss: 2.1822 - val_acc: 0.1047\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.6706 - acc: 0.1182 - val_loss: 2.1796 - val_acc: 0.1088\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.6556 - acc: 0.1177 - val_loss: 2.1550 - val_acc: 0.1124\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.6416 - acc: 0.1175 - val_loss: 2.1525 - val_acc: 0.1078\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.6325 - acc: 0.1128 - val_loss: 2.1505 - val_acc: 0.1042\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.6212 - acc: 0.1128 - val_loss: 2.1266 - val_acc: 0.1083\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.6115 - acc: 0.1132 - val_loss: 2.1123 - val_acc: 0.1083\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.6002 - acc: 0.1154 - val_loss: 2.1151 - val_acc: 0.1104\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.5924 - acc: 0.1092 - val_loss: 2.0852 - val_acc: 0.1114\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.5797 - acc: 0.1234 - val_loss: 2.0837 - val_acc: 0.1279\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.5772 - acc: 0.1299 - val_loss: 2.0759 - val_acc: 0.1145\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.5631 - acc: 0.1052 - val_loss: 2.0516 - val_acc: 0.0959\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.5624 - acc: 0.1084 - val_loss: 2.0580 - val_acc: 0.1047\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.5421 - acc: 0.1149 - val_loss: 2.0467 - val_acc: 0.1088\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.5345 - acc: 0.1137 - val_loss: 2.0436 - val_acc: 0.1109\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.5281 - acc: 0.1149 - val_loss: 2.0296 - val_acc: 0.1073\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.5740 - acc: 0.0949 - val_loss: 2.0491 - val_acc: 0.0449\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.5522 - acc: 0.0827 - val_loss: 2.0211 - val_acc: 0.0933\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.5131 - acc: 0.0930 - val_loss: 2.0041 - val_acc: 0.0939\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 1.5039 - acc: 0.0989 - val_loss: 2.0060 - val_acc: 0.1016\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 1.4989 - acc: 0.1092 - val_loss: 2.0043 - val_acc: 0.1073\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 1.4940 - acc: 0.1109 - val_loss: 2.0032 - val_acc: 0.1093\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 10, dense_activation = relu, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 5.2954 - acc: 0.0211 - val_loss: 7.7423 - val_acc: 0.0222\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.9271 - acc: 0.0277 - val_loss: 7.4752 - val_acc: 0.0315\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.7930 - acc: 0.0331 - val_loss: 7.3136 - val_acc: 0.0361\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 4.7122 - acc: 0.0356 - val_loss: 7.1750 - val_acc: 0.0392\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.6525 - acc: 0.0379 - val_loss: 7.0656 - val_acc: 0.0402\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.5843 - acc: 0.0391 - val_loss: 6.9401 - val_acc: 0.0464\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 4.4780 - acc: 0.0410 - val_loss: 6.6711 - val_acc: 0.0459\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.3136 - acc: 0.0410 - val_loss: 6.2985 - val_acc: 0.0464\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.0405 - acc: 0.0379 - val_loss: 5.9528 - val_acc: 0.0433\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.9128 - acc: 0.0389 - val_loss: 5.6806 - val_acc: 0.0459\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7373 - acc: 0.0397 - val_loss: 5.4499 - val_acc: 0.0454\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6329 - acc: 0.0393 - val_loss: 5.2974 - val_acc: 0.0464\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.5022 - acc: 0.0441 - val_loss: 5.0264 - val_acc: 0.0531\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.4056 - acc: 0.0446 - val_loss: 4.9384 - val_acc: 0.0346\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.3719 - acc: 0.0271 - val_loss: 4.8913 - val_acc: 0.0335\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.3514 - acc: 0.0281 - val_loss: 4.8685 - val_acc: 0.0351\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.3346 - acc: 0.0295 - val_loss: 4.8453 - val_acc: 0.0361\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.3195 - acc: 0.0293 - val_loss: 4.8137 - val_acc: 0.0361\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.3230 - acc: 0.0270 - val_loss: 4.7939 - val_acc: 0.0335\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.2873 - acc: 0.0294 - val_loss: 4.7774 - val_acc: 0.0366\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.2714 - acc: 0.0300 - val_loss: 4.7530 - val_acc: 0.0351\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.2557 - acc: 0.0298 - val_loss: 4.7387 - val_acc: 0.0351\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.2427 - acc: 0.0276 - val_loss: 4.6866 - val_acc: 0.0273\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.2468 - acc: 0.0246 - val_loss: 4.6404 - val_acc: 0.0304\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.2021 - acc: 0.0253 - val_loss: 4.6189 - val_acc: 0.0335\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.1835 - acc: 0.0277 - val_loss: 4.6190 - val_acc: 0.0340\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.1662 - acc: 0.0284 - val_loss: 4.6079 - val_acc: 0.0361\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.1553 - acc: 0.0289 - val_loss: 4.6047 - val_acc: 0.0356\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.1493 - acc: 0.0290 - val_loss: 4.5966 - val_acc: 0.0351\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.1415 - acc: 0.0291 - val_loss: 4.5827 - val_acc: 0.0340\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.1357 - acc: 0.0291 - val_loss: 4.5861 - val_acc: 0.0346\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.1330 - acc: 0.0293 - val_loss: 4.5767 - val_acc: 0.0340\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.1282 - acc: 0.0294 - val_loss: 4.5695 - val_acc: 0.0351\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.1241 - acc: 0.0297 - val_loss: 4.5606 - val_acc: 0.0346\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.1173 - acc: 0.0294 - val_loss: 4.5516 - val_acc: 0.0346\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.1077 - acc: 0.0291 - val_loss: 4.5230 - val_acc: 0.0330\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.0942 - acc: 0.0280 - val_loss: 4.5185 - val_acc: 0.0330\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.0879 - acc: 0.0275 - val_loss: 4.4966 - val_acc: 0.0309\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.0793 - acc: 0.0284 - val_loss: 4.4861 - val_acc: 0.0330\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.0736 - acc: 0.0294 - val_loss: 4.4734 - val_acc: 0.0325\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 10, dense_activation = relu, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 3.6087 - acc: 0.0307 - val_loss: 3.2898 - val_acc: 0.0423\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.2025 - acc: 0.0843 - val_loss: 2.7742 - val_acc: 0.0665\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.0685 - acc: 0.0780 - val_loss: 2.6031 - val_acc: 0.0748\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.0700 - acc: 0.0741 - val_loss: 2.6086 - val_acc: 0.1119\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.8802 - acc: 0.1108 - val_loss: 2.4291 - val_acc: 0.0737\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.8048 - acc: 0.0778 - val_loss: 2.2974 - val_acc: 0.0789\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.7566 - acc: 0.0865 - val_loss: 2.2817 - val_acc: 0.0794\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.7283 - acc: 0.0895 - val_loss: 2.2172 - val_acc: 0.0846\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.6958 - acc: 0.1315 - val_loss: 2.1931 - val_acc: 0.0923\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.6640 - acc: 0.0977 - val_loss: 2.1658 - val_acc: 0.1186\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.6465 - acc: 0.1132 - val_loss: 2.1326 - val_acc: 0.1160\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.6604 - acc: 0.1231 - val_loss: 2.8350 - val_acc: 0.0268\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.8548 - acc: 0.0347 - val_loss: 2.4760 - val_acc: 0.0021\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.2159 - acc: 0.0023 - val_loss: 2.3166 - val_acc: 0.0021\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 2.1835 - acc: 0.0026 - val_loss: 2.2905 - val_acc: 0.0021\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 2.1641 - acc: 0.0035 - val_loss: 2.2513 - val_acc: 0.0031\n",
            "Epoch 16: early stopping\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 10, dense_activation = relu, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 4.4081 - acc: 0.0157 - val_loss: 5.2856 - val_acc: 0.0294\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.4479 - acc: 0.0311 - val_loss: 4.6606 - val_acc: 0.0407\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.2005 - acc: 0.0324 - val_loss: 4.5612 - val_acc: 0.0330\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.1366 - acc: 0.0295 - val_loss: 4.5132 - val_acc: 0.0361\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.0771 - acc: 0.0259 - val_loss: 4.4080 - val_acc: 0.0361\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.9891 - acc: 0.0316 - val_loss: 4.3422 - val_acc: 0.0351\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.9557 - acc: 0.0221 - val_loss: 4.2772 - val_acc: 0.0253\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.8795 - acc: 0.0254 - val_loss: 4.1145 - val_acc: 0.0340\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.5483 - acc: 0.0254 - val_loss: 3.2240 - val_acc: 0.0284\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.2758 - acc: 0.0257 - val_loss: 3.1768 - val_acc: 0.0263\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.2571 - acc: 0.0213 - val_loss: 3.1644 - val_acc: 0.0263\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.2389 - acc: 0.0237 - val_loss: 3.1458 - val_acc: 0.0278\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.1968 - acc: 0.0246 - val_loss: 3.0936 - val_acc: 0.0299\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.0630 - acc: 0.0282 - val_loss: 2.3125 - val_acc: 0.0376\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.6280 - acc: 0.0190 - val_loss: 2.1366 - val_acc: 0.0191\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.5924 - acc: 0.0195 - val_loss: 2.0772 - val_acc: 0.0289\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.5590 - acc: 0.0188 - val_loss: 2.0466 - val_acc: 0.0232\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.5337 - acc: 0.0175 - val_loss: 2.0347 - val_acc: 0.0227\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.5133 - acc: 0.0178 - val_loss: 2.0124 - val_acc: 0.0217\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.4861 - acc: 0.0181 - val_loss: 2.1483 - val_acc: 0.0253\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.9228 - acc: 0.0134 - val_loss: 2.6738 - val_acc: 0.0155\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.8252 - acc: 0.0172 - val_loss: 2.1985 - val_acc: 0.0160\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.3157 - acc: 0.0548 - val_loss: 1.4400 - val_acc: 0.0995\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.0031 - acc: 0.0784 - val_loss: 0.9096 - val_acc: 0.0598\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.8308 - acc: 0.0607 - val_loss: 0.8903 - val_acc: 0.0743\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.0359 - acc: 0.0705 - val_loss: 1.3702 - val_acc: 0.0676\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.0368 - acc: 0.0696 - val_loss: 1.1176 - val_acc: 0.0686\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.8437 - acc: 0.0695 - val_loss: 0.8553 - val_acc: 0.0784\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7807 - acc: 0.0695 - val_loss: 0.8372 - val_acc: 0.0737\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7713 - acc: 0.0699 - val_loss: 0.8321 - val_acc: 0.0753\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7621 - acc: 0.0743 - val_loss: 0.8150 - val_acc: 0.0768\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7551 - acc: 0.0705 - val_loss: 0.8053 - val_acc: 0.0768\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7473 - acc: 0.0744 - val_loss: 0.7962 - val_acc: 0.0799\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7400 - acc: 0.0711 - val_loss: 0.7885 - val_acc: 0.0774\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7324 - acc: 0.0716 - val_loss: 0.7862 - val_acc: 0.0784\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.7255 - acc: 0.0722 - val_loss: 0.7763 - val_acc: 0.0753\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7182 - acc: 0.0734 - val_loss: 0.7672 - val_acc: 0.0794\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7126 - acc: 0.0729 - val_loss: 0.7610 - val_acc: 0.0784\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7021 - acc: 0.0700 - val_loss: 0.7571 - val_acc: 0.0629\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6917 - acc: 0.0683 - val_loss: 0.7474 - val_acc: 0.0774\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 10, dense_activation = relu, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 3.1762 - acc: 0.0858 - val_loss: 3.4738 - val_acc: 0.0753\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.8886 - acc: 0.1799 - val_loss: 3.1271 - val_acc: 0.0036\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.5727 - acc: 0.0053 - val_loss: 2.7014 - val_acc: 0.0057\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.3233 - acc: 0.0097 - val_loss: 2.3643 - val_acc: 0.0098\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.8766 - acc: 0.0750 - val_loss: 2.0709 - val_acc: 0.1119\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.5128 - acc: 0.1008 - val_loss: 1.9285 - val_acc: 0.0624\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.4521 - acc: 0.0828 - val_loss: 1.8726 - val_acc: 0.1047\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.4026 - acc: 0.0954 - val_loss: 1.7463 - val_acc: 0.1026\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.2660 - acc: 0.0864 - val_loss: 1.5023 - val_acc: 0.0944\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.9715 - acc: 0.0695 - val_loss: 0.8601 - val_acc: 0.0820\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.8039 - acc: 0.0785 - val_loss: 1.1941 - val_acc: 0.0170\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.7936 - acc: 0.0560 - val_loss: 0.8103 - val_acc: 0.0949\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.7335 - acc: 0.0869 - val_loss: 0.7916 - val_acc: 0.0923\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.7227 - acc: 0.1132 - val_loss: 0.8269 - val_acc: 0.1099\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.3281 - acc: 0.0331 - val_loss: 0.9880 - val_acc: 0.0072\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.3290 - acc: 0.0111 - val_loss: 0.9798 - val_acc: 0.0083\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.2998 - acc: 0.0129 - val_loss: 0.9734 - val_acc: 0.0093\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.2653 - acc: 0.0172 - val_loss: 0.9201 - val_acc: 0.0268\n",
            "Epoch 18: early stopping\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 10, dense_activation = relu, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 3.0621 - acc: 0.0374 - val_loss: 3.5788 - val_acc: 0.0196\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.2751 - acc: 0.0378 - val_loss: 2.4372 - val_acc: 0.1480\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.9070 - acc: 0.1060 - val_loss: 1.7278 - val_acc: 0.0376\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.3409 - acc: 0.0360 - val_loss: 1.4301 - val_acc: 0.0031\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.6157 - acc: 0.0022 - val_loss: 1.2827 - val_acc: 0.0046\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.5685 - acc: 0.0039 - val_loss: 1.3028 - val_acc: 0.0057\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.6023 - acc: 0.0058 - val_loss: 1.2845 - val_acc: 0.0155\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.3998 - acc: 0.0214 - val_loss: 1.3557 - val_acc: 0.0062\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.6015 - acc: 0.0044 - val_loss: 1.2484 - val_acc: 0.0083\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.5622 - acc: 0.0071 - val_loss: 1.2504 - val_acc: 0.0098\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.4986 - acc: 0.0162 - val_loss: 1.1830 - val_acc: 0.0227\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.4637 - acc: 0.0137 - val_loss: 1.1421 - val_acc: 0.0181\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.3648 - acc: 0.0197 - val_loss: 1.0387 - val_acc: 0.0480\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.9457 - acc: 0.0867 - val_loss: 0.9474 - val_acc: 0.1124\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.8535 - acc: 0.0956 - val_loss: 0.9383 - val_acc: 0.0970\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.8390 - acc: 0.0827 - val_loss: 0.9169 - val_acc: 0.0903\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.8255 - acc: 0.1006 - val_loss: 0.8999 - val_acc: 0.1795\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.8222 - acc: 0.1545 - val_loss: 0.8994 - val_acc: 0.1078\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.8060 - acc: 0.1122 - val_loss: 0.8809 - val_acc: 0.1171\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.7949 - acc: 0.1072 - val_loss: 0.8764 - val_acc: 0.1109\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.7860 - acc: 0.1054 - val_loss: 0.8527 - val_acc: 0.1145\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.7820 - acc: 0.1001 - val_loss: 0.8604 - val_acc: 0.1088\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.7689 - acc: 0.1046 - val_loss: 0.8404 - val_acc: 0.1083\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.7607 - acc: 0.1043 - val_loss: 0.8450 - val_acc: 0.1166\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.7528 - acc: 0.1097 - val_loss: 0.8393 - val_acc: 0.1145\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.7456 - acc: 0.1078 - val_loss: 0.8213 - val_acc: 0.1176\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.0741 - acc: 0.0913 - val_loss: 1.8589 - val_acc: 0.0949\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.3606 - acc: 0.0994 - val_loss: 1.7542 - val_acc: 0.0897\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.3069 - acc: 0.1026 - val_loss: 1.7254 - val_acc: 0.1150\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.2635 - acc: 0.1101 - val_loss: 1.6909 - val_acc: 0.1150\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.2341 - acc: 0.1112 - val_loss: 1.6562 - val_acc: 0.1145\n",
            "Epoch 31: early stopping\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 10, dense_activation = relu, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 4.5691 - acc: 0.4937 - val_loss: 5.1651 - val_acc: 0.5168\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.0873 - acc: 0.5421 - val_loss: 4.9617 - val_acc: 0.5513\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.8917 - acc: 0.5590 - val_loss: 4.7551 - val_acc: 0.5580\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.7201 - acc: 0.5622 - val_loss: 4.5548 - val_acc: 0.5596\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.5469 - acc: 0.5613 - val_loss: 4.3391 - val_acc: 0.5621\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.3942 - acc: 0.5520 - val_loss: 4.2355 - val_acc: 0.5425\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2792 - acc: 0.5519 - val_loss: 4.0621 - val_acc: 0.5518\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.1675 - acc: 0.5547 - val_loss: 3.9218 - val_acc: 0.5420\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.0388 - acc: 0.5390 - val_loss: 3.7753 - val_acc: 0.5229\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.9234 - acc: 0.5230 - val_loss: 3.6341 - val_acc: 0.5152\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.8503 - acc: 0.5150 - val_loss: 3.5541 - val_acc: 0.5116\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.7899 - acc: 0.5216 - val_loss: 3.4794 - val_acc: 0.5214\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.7324 - acc: 0.5215 - val_loss: 3.4198 - val_acc: 0.5132\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.6812 - acc: 0.5135 - val_loss: 3.3553 - val_acc: 0.5121\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.6452 - acc: 0.5182 - val_loss: 3.3446 - val_acc: 0.5193\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.5967 - acc: 0.5364 - val_loss: 3.2186 - val_acc: 0.5431\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.5449 - acc: 0.5455 - val_loss: 3.1565 - val_acc: 0.5389\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.5080 - acc: 0.5478 - val_loss: 3.0945 - val_acc: 0.5467\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.4692 - acc: 0.5470 - val_loss: 3.0284 - val_acc: 0.5415\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.4154 - acc: 0.5221 - val_loss: 2.9400 - val_acc: 0.5168\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.3446 - acc: 0.5173 - val_loss: 2.8060 - val_acc: 0.5178\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.2854 - acc: 0.5336 - val_loss: 2.7318 - val_acc: 0.5436\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.2290 - acc: 0.5457 - val_loss: 2.6333 - val_acc: 0.5389\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.1885 - acc: 0.5427 - val_loss: 2.6161 - val_acc: 0.5415\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.1586 - acc: 0.5411 - val_loss: 2.5476 - val_acc: 0.5343\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.1221 - acc: 0.5296 - val_loss: 2.4933 - val_acc: 0.5245\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.0837 - acc: 0.5250 - val_loss: 2.4370 - val_acc: 0.5214\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.0630 - acc: 0.5127 - val_loss: 2.4850 - val_acc: 0.4987\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.0844 - acc: 0.5017 - val_loss: 2.4090 - val_acc: 0.5008\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.0427 - acc: 0.5038 - val_loss: 2.3501 - val_acc: 0.5085\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.0046 - acc: 0.5124 - val_loss: 2.2993 - val_acc: 0.5348\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.9742 - acc: 0.5308 - val_loss: 2.2571 - val_acc: 0.5281\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.9577 - acc: 0.5278 - val_loss: 2.2360 - val_acc: 0.5307\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.9358 - acc: 0.5253 - val_loss: 2.2149 - val_acc: 0.5250\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.9183 - acc: 0.5215 - val_loss: 2.1957 - val_acc: 0.5358\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.9012 - acc: 0.5451 - val_loss: 2.1689 - val_acc: 0.6013\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.8810 - acc: 0.5910 - val_loss: 2.1562 - val_acc: 0.5910\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.8603 - acc: 0.5889 - val_loss: 2.1257 - val_acc: 0.5869\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.8331 - acc: 0.5814 - val_loss: 2.0958 - val_acc: 0.5859\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.8201 - acc: 0.5822 - val_loss: 2.0767 - val_acc: 0.5802\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 50, dense_activation = relu, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 4.8616 - acc: 0.0000e+00 - val_loss: 6.1282 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.5432 - acc: 0.0000e+00 - val_loss: 5.8415 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.3633 - acc: 0.0000e+00 - val_loss: 5.6242 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.2408 - acc: 0.0000e+00 - val_loss: 5.4598 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1421 - acc: 0.0000e+00 - val_loss: 5.3318 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 4.0377 - acc: 0.0000e+00 - val_loss: 5.2111 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.9555 - acc: 0.0000e+00 - val_loss: 5.1137 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.8741 - acc: 0.0000e+00 - val_loss: 5.0003 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.7765 - acc: 0.0000e+00 - val_loss: 4.8361 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.6957 - acc: 0.0000e+00 - val_loss: 4.7551 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6427 - acc: 0.0000e+00 - val_loss: 4.6837 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.5953 - acc: 0.0000e+00 - val_loss: 4.6269 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.5462 - acc: 0.0000e+00 - val_loss: 4.5584 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.4992 - acc: 0.0000e+00 - val_loss: 4.4953 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.4556 - acc: 0.0000e+00 - val_loss: 4.4542 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.4252 - acc: 0.0000e+00 - val_loss: 4.4114 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.3974 - acc: 0.0000e+00 - val_loss: 4.3642 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.3604 - acc: 0.0000e+00 - val_loss: 4.3015 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.3205 - acc: 0.0000e+00 - val_loss: 4.2313 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.2793 - acc: 0.0000e+00 - val_loss: 4.1554 - val_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.2356 - acc: 0.0000e+00 - val_loss: 4.0845 - val_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.1970 - acc: 0.0000e+00 - val_loss: 4.0360 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.1704 - acc: 0.0000e+00 - val_loss: 3.9948 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.1461 - acc: 0.0000e+00 - val_loss: 3.9591 - val_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.1173 - acc: 0.0000e+00 - val_loss: 3.9106 - val_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.0916 - acc: 0.0000e+00 - val_loss: 3.8659 - val_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.1018 - acc: 0.0000e+00 - val_loss: 3.8292 - val_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.0705 - acc: 0.0000e+00 - val_loss: 3.7890 - val_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.0353 - acc: 0.0000e+00 - val_loss: 3.7301 - val_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.9920 - acc: 0.0000e+00 - val_loss: 3.6343 - val_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.9429 - acc: 0.0000e+00 - val_loss: 3.5871 - val_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.9087 - acc: 0.0000e+00 - val_loss: 3.5416 - val_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.8686 - acc: 0.0000e+00 - val_loss: 3.4990 - val_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.8414 - acc: 0.0000e+00 - val_loss: 3.4666 - val_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.8143 - acc: 0.0000e+00 - val_loss: 3.4366 - val_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7867 - acc: 0.0000e+00 - val_loss: 3.4004 - val_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7584 - acc: 0.0000e+00 - val_loss: 3.3645 - val_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.6971 - acc: 0.0000e+00 - val_loss: 3.2586 - val_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.6510 - acc: 0.0000e+00 - val_loss: 3.2246 - val_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.6331 - acc: 0.0000e+00 - val_loss: 3.2063 - val_acc: 0.0000e+00\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 50, dense_activation = relu, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 4.7400 - acc: 0.0080 - val_loss: 5.6767 - val_acc: 0.0036\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.8084 - acc: 0.0028 - val_loss: 4.5390 - val_acc: 0.0041\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2987 - acc: 0.0050 - val_loss: 4.1937 - val_acc: 0.0067\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.1907 - acc: 0.0045 - val_loss: 4.0735 - val_acc: 0.0026\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.1734 - acc: 0.0043 - val_loss: 3.9863 - val_acc: 0.0026\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.0165 - acc: 0.0053 - val_loss: 3.7532 - val_acc: 0.0036\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.8335 - acc: 0.0066 - val_loss: 3.5507 - val_acc: 0.0046\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.7028 - acc: 0.0075 - val_loss: 3.3320 - val_acc: 0.0077\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.4147 - acc: 0.0104 - val_loss: 2.8991 - val_acc: 0.0150\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.1625 - acc: 0.0139 - val_loss: 2.7017 - val_acc: 0.0144\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.0843 - acc: 0.0123 - val_loss: 2.6067 - val_acc: 0.0108\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.0177 - acc: 0.0092 - val_loss: 2.5833 - val_acc: 0.0083\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.9686 - acc: 0.0121 - val_loss: 2.5043 - val_acc: 0.0093\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.9205 - acc: 0.0104 - val_loss: 2.3040 - val_acc: 0.0423\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.7798 - acc: 0.0338 - val_loss: 2.1530 - val_acc: 0.0356\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.6516 - acc: 0.0312 - val_loss: 1.9427 - val_acc: 0.0351\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.4490 - acc: 0.0320 - val_loss: 1.7036 - val_acc: 0.0304\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.4455 - acc: 0.0275 - val_loss: 1.8928 - val_acc: 0.0253\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.4545 - acc: 0.0241 - val_loss: 1.8000 - val_acc: 0.0284\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.4092 - acc: 0.0272 - val_loss: 1.7482 - val_acc: 0.0273\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.3999 - acc: 0.0260 - val_loss: 1.7840 - val_acc: 0.0299\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.3745 - acc: 0.0273 - val_loss: 1.6884 - val_acc: 0.0248\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.3522 - acc: 0.0271 - val_loss: 1.6785 - val_acc: 0.0304\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.3252 - acc: 0.0290 - val_loss: 1.6152 - val_acc: 0.0289\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.3561 - acc: 0.0162 - val_loss: 1.6618 - val_acc: 0.0150\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.3031 - acc: 0.0159 - val_loss: 1.5633 - val_acc: 0.0196\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.2429 - acc: 0.0197 - val_loss: 1.5043 - val_acc: 0.0206\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.2099 - acc: 0.0227 - val_loss: 1.4755 - val_acc: 0.0273\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.1902 - acc: 0.0264 - val_loss: 1.4408 - val_acc: 0.0268\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.2857 - acc: 0.0104 - val_loss: 1.4910 - val_acc: 0.0046\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.2815 - acc: 0.0071 - val_loss: 1.4591 - val_acc: 0.0057\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.2665 - acc: 0.0081 - val_loss: 1.4316 - val_acc: 0.0057\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.2342 - acc: 0.0113 - val_loss: 1.3938 - val_acc: 0.0144\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.1721 - acc: 0.0141 - val_loss: 1.3756 - val_acc: 0.0175\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.2514 - acc: 0.0093 - val_loss: 1.5371 - val_acc: 0.0010\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.3086 - acc: 0.0014 - val_loss: 1.4245 - val_acc: 0.0010\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.2561 - acc: 0.0022 - val_loss: 1.4102 - val_acc: 0.0015\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.2566 - acc: 0.0023 - val_loss: 1.3967 - val_acc: 0.0015\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.2341 - acc: 0.0025 - val_loss: 1.3921 - val_acc: 0.0015\n",
            "Epoch 39: early stopping\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 50, dense_activation = relu, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 4.3008 - acc: 0.0945 - val_loss: 4.9933 - val_acc: 0.0882\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6781 - acc: 0.0985 - val_loss: 4.3680 - val_acc: 0.1068\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.3476 - acc: 0.1201 - val_loss: 3.9076 - val_acc: 0.1284\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.0270 - acc: 0.1418 - val_loss: 3.5192 - val_acc: 0.1465\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.8564 - acc: 0.1547 - val_loss: 3.3573 - val_acc: 0.1470\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.6965 - acc: 0.1761 - val_loss: 3.0710 - val_acc: 0.2078\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.5235 - acc: 0.2040 - val_loss: 2.8688 - val_acc: 0.2084\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.3705 - acc: 0.2141 - val_loss: 2.6991 - val_acc: 0.1826\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.2858 - acc: 0.2139 - val_loss: 2.7183 - val_acc: 0.2682\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.2667 - acc: 0.2623 - val_loss: 2.5724 - val_acc: 0.2785\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.1514 - acc: 0.2673 - val_loss: 2.4111 - val_acc: 0.2692\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.0783 - acc: 0.2794 - val_loss: 2.3415 - val_acc: 0.3002\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.0637 - acc: 0.3003 - val_loss: 2.2717 - val_acc: 0.2950\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.9780 - acc: 0.2743 - val_loss: 2.2052 - val_acc: 0.2589\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.9079 - acc: 0.2524 - val_loss: 2.1742 - val_acc: 0.2249\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.8574 - acc: 0.2279 - val_loss: 2.1697 - val_acc: 0.2156\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.8458 - acc: 0.2284 - val_loss: 2.1458 - val_acc: 0.2114\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.8220 - acc: 0.1964 - val_loss: 2.1169 - val_acc: 0.1821\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.8042 - acc: 0.1679 - val_loss: 2.0939 - val_acc: 0.1454\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.7836 - acc: 0.1217 - val_loss: 2.0814 - val_acc: 0.0964\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.7613 - acc: 0.0756 - val_loss: 2.0532 - val_acc: 0.0268\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.6827 - acc: 0.0204 - val_loss: 2.0343 - val_acc: 0.0139\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.6556 - acc: 0.0193 - val_loss: 2.0378 - val_acc: 0.0201\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.6488 - acc: 0.0184 - val_loss: 2.0271 - val_acc: 0.0170\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.6967 - acc: 0.0174 - val_loss: 2.0999 - val_acc: 0.0113\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.7302 - acc: 0.0116 - val_loss: 2.0615 - val_acc: 0.0098\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.6809 - acc: 0.0124 - val_loss: 1.9994 - val_acc: 0.0129\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.6395 - acc: 0.0148 - val_loss: 1.9767 - val_acc: 0.0150\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.6139 - acc: 0.0143 - val_loss: 1.9667 - val_acc: 0.0134\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.5991 - acc: 0.0135 - val_loss: 1.9657 - val_acc: 0.0134\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.5890 - acc: 0.0133 - val_loss: 1.9555 - val_acc: 0.0139\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.5803 - acc: 0.0152 - val_loss: 1.9394 - val_acc: 0.0165\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.5630 - acc: 0.0172 - val_loss: 1.9263 - val_acc: 0.0139\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.5588 - acc: 0.0162 - val_loss: 1.9166 - val_acc: 0.0119\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.5504 - acc: 0.0160 - val_loss: 1.9237 - val_acc: 0.0108\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.5527 - acc: 0.0126 - val_loss: 1.8901 - val_acc: 0.0098\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.4859 - acc: 0.0124 - val_loss: 1.8024 - val_acc: 0.0108\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.4265 - acc: 0.0135 - val_loss: 1.7469 - val_acc: 0.0113\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.3794 - acc: 0.0182 - val_loss: 1.7267 - val_acc: 0.0170\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.3608 - acc: 0.0188 - val_loss: 1.6995 - val_acc: 0.0170\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 50, dense_activation = relu, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 4.1030 - acc: 0.0000e+00 - val_loss: 4.2191 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.0268 - acc: 0.0000e+00 - val_loss: 3.1518 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.4932 - acc: 0.0000e+00 - val_loss: 2.6500 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.2521 - acc: 0.0000e+00 - val_loss: 2.4323 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.1582 - acc: 0.0000e+00 - val_loss: 2.4833 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 2.0770 - acc: 0.0000e+00 - val_loss: 2.2380 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 2.0463 - acc: 0.0000e+00 - val_loss: 2.1908 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.9515 - acc: 0.0000e+00 - val_loss: 1.9818 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.6589 - acc: 0.0000e+00 - val_loss: 1.7501 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.5252 - acc: 0.0000e+00 - val_loss: 1.6260 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.4879 - acc: 0.0000e+00 - val_loss: 1.5759 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.4478 - acc: 0.0000e+00 - val_loss: 1.5389 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.4225 - acc: 0.0000e+00 - val_loss: 1.5201 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.3969 - acc: 0.0000e+00 - val_loss: 1.4682 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.3888 - acc: 0.0000e+00 - val_loss: 1.6110 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.4387 - acc: 0.0000e+00 - val_loss: 1.6208 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.4088 - acc: 0.0000e+00 - val_loss: 1.4541 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.4299 - acc: 0.0000e+00 - val_loss: 1.3697 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.2825 - acc: 0.0000e+00 - val_loss: 1.1568 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.1536 - acc: 3.8685e-04 - val_loss: 1.1925 - val_acc: 0.0015\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.0938 - acc: 9.0264e-04 - val_loss: 1.0855 - val_acc: 0.0015\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.2071 - acc: 2.5790e-04 - val_loss: 1.0568 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 1.0642 - acc: 2.5790e-04 - val_loss: 0.9733 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.9835 - acc: 3.8685e-04 - val_loss: 0.9260 - val_acc: 5.1573e-04\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.9556 - acc: 3.8685e-04 - val_loss: 0.9200 - val_acc: 5.1573e-04\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.9412 - acc: 5.1580e-04 - val_loss: 0.9049 - val_acc: 0.0010\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 1.0028 - acc: 0.0012 - val_loss: 1.0569 - val_acc: 0.0015\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.9909 - acc: 0.0010 - val_loss: 0.9925 - val_acc: 0.0010\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.9568 - acc: 5.1580e-04 - val_loss: 0.9233 - val_acc: 0.0010\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.9220 - acc: 5.1580e-04 - val_loss: 0.8825 - val_acc: 0.0010\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.9167 - acc: 5.1580e-04 - val_loss: 0.9017 - val_acc: 0.0010\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.9021 - acc: 5.1580e-04 - val_loss: 0.8661 - val_acc: 0.0010\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.8867 - acc: 5.1580e-04 - val_loss: 0.8600 - val_acc: 0.0010\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.8804 - acc: 9.0264e-04 - val_loss: 0.8867 - val_acc: 0.0010\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.8785 - acc: 5.1580e-04 - val_loss: 0.8470 - val_acc: 0.0010\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.8686 - acc: 6.4475e-04 - val_loss: 0.8410 - val_acc: 0.0010\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.8581 - acc: 0.0014 - val_loss: 0.8276 - val_acc: 0.0015\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.9294 - acc: 0.0015 - val_loss: 0.9951 - val_acc: 0.0015\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.9243 - acc: 0.0023 - val_loss: 0.8859 - val_acc: 0.0021\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.8586 - acc: 0.0027 - val_loss: 0.8125 - val_acc: 0.0026\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 50, dense_activation = relu, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 25ms/step - loss: 4.4173 - acc: 0.0000e+00 - val_loss: 4.8417 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.3451 - acc: 0.0000e+00 - val_loss: 4.1734 - val_acc: 5.1573e-04\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 22ms/step - loss: 2.8867 - acc: 7.7369e-04 - val_loss: 3.5544 - val_acc: 0.0010\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.5147 - acc: 0.0014 - val_loss: 3.1986 - val_acc: 0.0036\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.2814 - acc: 0.0129 - val_loss: 2.9125 - val_acc: 0.0284\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.3069 - acc: 0.0113 - val_loss: 3.0292 - val_acc: 0.0041\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.3458 - acc: 0.0025 - val_loss: 2.9891 - val_acc: 0.0015\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.2041 - acc: 0.0071 - val_loss: 2.8150 - val_acc: 0.0098\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.1171 - acc: 0.0117 - val_loss: 2.7605 - val_acc: 0.0103\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.0810 - acc: 0.0046 - val_loss: 2.7081 - val_acc: 5.1573e-04\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.0436 - acc: 0.0079 - val_loss: 2.5633 - val_acc: 0.0103\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.8933 - acc: 0.0160 - val_loss: 2.3531 - val_acc: 0.0134\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.7793 - acc: 0.0166 - val_loss: 2.2681 - val_acc: 0.0155\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.7373 - acc: 0.0165 - val_loss: 2.2126 - val_acc: 0.0155\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.6853 - acc: 0.0173 - val_loss: 2.0689 - val_acc: 0.0165\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.5855 - acc: 0.0182 - val_loss: 1.9889 - val_acc: 0.0186\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 1.5536 - acc: 0.0188 - val_loss: 1.9641 - val_acc: 0.0217\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.5365 - acc: 0.0190 - val_loss: 1.9445 - val_acc: 0.0201\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.5151 - acc: 0.0196 - val_loss: 1.9047 - val_acc: 0.0206\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.4956 - acc: 0.0191 - val_loss: 1.8840 - val_acc: 0.0196\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.4720 - acc: 0.0178 - val_loss: 1.8394 - val_acc: 0.0191\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.4461 - acc: 0.0173 - val_loss: 1.8098 - val_acc: 0.0211\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.4263 - acc: 0.0183 - val_loss: 1.7815 - val_acc: 0.0201\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.4112 - acc: 0.0192 - val_loss: 1.7515 - val_acc: 0.0222\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.3936 - acc: 0.0193 - val_loss: 1.7326 - val_acc: 0.0258\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.3819 - acc: 0.0172 - val_loss: 1.7115 - val_acc: 0.0119\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.3932 - acc: 0.0083 - val_loss: 1.7016 - val_acc: 0.0098\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.3653 - acc: 0.0209 - val_loss: 1.6941 - val_acc: 0.0206\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.3530 - acc: 0.0218 - val_loss: 1.7018 - val_acc: 0.0206\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.3481 - acc: 0.0116 - val_loss: 1.6612 - val_acc: 0.0067\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.3438 - acc: 0.0179 - val_loss: 1.6590 - val_acc: 0.0181\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.3305 - acc: 0.0179 - val_loss: 1.6627 - val_acc: 0.0186\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.3227 - acc: 0.0186 - val_loss: 1.6498 - val_acc: 0.0181\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.3152 - acc: 0.0177 - val_loss: 1.6426 - val_acc: 0.0175\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.3076 - acc: 0.0181 - val_loss: 1.6336 - val_acc: 0.0186\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.3005 - acc: 0.0183 - val_loss: 1.6240 - val_acc: 0.0201\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.2966 - acc: 0.0184 - val_loss: 1.6119 - val_acc: 0.0237\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.2894 - acc: 0.0191 - val_loss: 1.6055 - val_acc: 0.0211\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.2956 - acc: 0.0195 - val_loss: 1.6428 - val_acc: 0.0181\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 1.2888 - acc: 0.0157 - val_loss: 1.6027 - val_acc: 0.0088\n",
            "With filter = 128, kernel_size = 16, layer_activation = relu, dense_layer = 50, dense_activation = relu, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2701 - acc: 0.2049 - val_loss: 1.7176 - val_acc: 0.2114\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 1.0130 - acc: 0.2049 - val_loss: 1.2865 - val_acc: 0.2114\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.9141 - acc: 0.2059 - val_loss: 1.1519 - val_acc: 0.2130\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.8676 - acc: 0.2141 - val_loss: 1.0601 - val_acc: 0.2305\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.8385 - acc: 0.2420 - val_loss: 1.0008 - val_acc: 0.2666\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.8198 - acc: 0.2766 - val_loss: 0.9576 - val_acc: 0.3002\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.8051 - acc: 0.3109 - val_loss: 0.9262 - val_acc: 0.3337\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.7922 - acc: 0.3404 - val_loss: 0.9038 - val_acc: 0.3533\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.7800 - acc: 0.3599 - val_loss: 0.8825 - val_acc: 0.3749\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.7682 - acc: 0.3807 - val_loss: 0.8654 - val_acc: 0.3925\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.7567 - acc: 0.3982 - val_loss: 0.8492 - val_acc: 0.4105\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.7456 - acc: 0.4099 - val_loss: 0.8347 - val_acc: 0.4255\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.7346 - acc: 0.4286 - val_loss: 0.8203 - val_acc: 0.4409\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.7240 - acc: 0.4502 - val_loss: 0.8074 - val_acc: 0.4621\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.7135 - acc: 0.4647 - val_loss: 0.7956 - val_acc: 0.4724\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.7033 - acc: 0.4694 - val_loss: 0.7817 - val_acc: 0.4925\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6933 - acc: 0.4976 - val_loss: 0.7703 - val_acc: 0.5059\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6835 - acc: 0.5023 - val_loss: 0.7602 - val_acc: 0.5034\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6739 - acc: 0.5078 - val_loss: 0.7463 - val_acc: 0.5209\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6644 - acc: 0.5186 - val_loss: 0.7328 - val_acc: 0.5369\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6550 - acc: 0.5427 - val_loss: 0.7206 - val_acc: 0.5498\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6458 - acc: 0.5470 - val_loss: 0.7107 - val_acc: 0.5565\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6367 - acc: 0.5678 - val_loss: 0.7007 - val_acc: 0.5585\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6277 - acc: 0.5612 - val_loss: 0.6846 - val_acc: 0.5854\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6188 - acc: 0.5925 - val_loss: 0.6761 - val_acc: 0.5936\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6099 - acc: 0.5955 - val_loss: 0.6654 - val_acc: 0.6044\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6011 - acc: 0.6035 - val_loss: 0.6538 - val_acc: 0.6111\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5924 - acc: 0.6270 - val_loss: 0.6458 - val_acc: 0.6163\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5838 - acc: 0.6362 - val_loss: 0.6395 - val_acc: 0.6173\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5752 - acc: 0.6273 - val_loss: 0.6200 - val_acc: 0.6318\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5667 - acc: 0.6531 - val_loss: 0.6109 - val_acc: 0.6421\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5580 - acc: 0.6558 - val_loss: 0.6028 - val_acc: 0.6478\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5495 - acc: 0.6674 - val_loss: 0.5979 - val_acc: 0.6514\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.5409 - acc: 0.6712 - val_loss: 0.5828 - val_acc: 0.6720\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.5325 - acc: 0.6836 - val_loss: 0.5784 - val_acc: 0.6684\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5239 - acc: 0.6882 - val_loss: 0.5628 - val_acc: 0.6797\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5157 - acc: 0.7043 - val_loss: 0.5591 - val_acc: 0.6777\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.5074 - acc: 0.7109 - val_loss: 0.5470 - val_acc: 0.6921\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4992 - acc: 0.7185 - val_loss: 0.5330 - val_acc: 0.7096\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4912 - acc: 0.7283 - val_loss: 0.5327 - val_acc: 0.7081\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 1, dense_activation = relu, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 22ms/step - loss: 0.7760 - acc: 0.2520 - val_loss: 0.8086 - val_acc: 0.3476\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7097 - acc: 0.3924 - val_loss: 0.7724 - val_acc: 0.3909\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6760 - acc: 0.4622 - val_loss: 0.7354 - val_acc: 0.4642\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6476 - acc: 0.5115 - val_loss: 0.6889 - val_acc: 0.5472\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6230 - acc: 0.5845 - val_loss: 0.6630 - val_acc: 0.5890\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6018 - acc: 0.6179 - val_loss: 0.6344 - val_acc: 0.6240\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5828 - acc: 0.6525 - val_loss: 0.6118 - val_acc: 0.6560\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5657 - acc: 0.6732 - val_loss: 0.5836 - val_acc: 0.6911\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5500 - acc: 0.7065 - val_loss: 0.5808 - val_acc: 0.6844\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5353 - acc: 0.7050 - val_loss: 0.5622 - val_acc: 0.7004\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5217 - acc: 0.7211 - val_loss: 0.5522 - val_acc: 0.7122\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5089 - acc: 0.7341 - val_loss: 0.5301 - val_acc: 0.7308\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4975 - acc: 0.7460 - val_loss: 0.5107 - val_acc: 0.7478\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4859 - acc: 0.7536 - val_loss: 0.5139 - val_acc: 0.7437\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4753 - acc: 0.7634 - val_loss: 0.5035 - val_acc: 0.7509\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4653 - acc: 0.7752 - val_loss: 0.4910 - val_acc: 0.7555\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4561 - acc: 0.7709 - val_loss: 0.4873 - val_acc: 0.7597\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4467 - acc: 0.7930 - val_loss: 0.4802 - val_acc: 0.7638\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4380 - acc: 0.7902 - val_loss: 0.4739 - val_acc: 0.7715\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4299 - acc: 0.7956 - val_loss: 0.4555 - val_acc: 0.7886\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4221 - acc: 0.8032 - val_loss: 0.4557 - val_acc: 0.7829\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4146 - acc: 0.8108 - val_loss: 0.4510 - val_acc: 0.7844\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4077 - acc: 0.8080 - val_loss: 0.4425 - val_acc: 0.7947\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4007 - acc: 0.8179 - val_loss: 0.4374 - val_acc: 0.7989\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3944 - acc: 0.8188 - val_loss: 0.4255 - val_acc: 0.8076\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3881 - acc: 0.8249 - val_loss: 0.4153 - val_acc: 0.8138\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3820 - acc: 0.8347 - val_loss: 0.4208 - val_acc: 0.8066\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3765 - acc: 0.8309 - val_loss: 0.4236 - val_acc: 0.7978\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3708 - acc: 0.8356 - val_loss: 0.4246 - val_acc: 0.7932\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3655 - acc: 0.8353 - val_loss: 0.4011 - val_acc: 0.8154\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3602 - acc: 0.8417 - val_loss: 0.3946 - val_acc: 0.8236\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3555 - acc: 0.8418 - val_loss: 0.4017 - val_acc: 0.8133\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3503 - acc: 0.8480 - val_loss: 0.3829 - val_acc: 0.8303\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3456 - acc: 0.8517 - val_loss: 0.3892 - val_acc: 0.8241\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3413 - acc: 0.8552 - val_loss: 0.3791 - val_acc: 0.8339\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3367 - acc: 0.8551 - val_loss: 0.3740 - val_acc: 0.8391\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3323 - acc: 0.8598 - val_loss: 0.3763 - val_acc: 0.8324\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3286 - acc: 0.8622 - val_loss: 0.3634 - val_acc: 0.8427\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3242 - acc: 0.8611 - val_loss: 0.3690 - val_acc: 0.8412\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3200 - acc: 0.8681 - val_loss: 0.3620 - val_acc: 0.8437\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 1, dense_activation = relu, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 7.7266 - acc: 0.2049 - val_loss: 12.1634 - val_acc: 0.2114\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 7.7266 - acc: 0.2049 - val_loss: 12.1634 - val_acc: 0.2114\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 7.7266 - acc: 0.2049 - val_loss: 12.1634 - val_acc: 0.2114\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 7.7266 - acc: 0.2049 - val_loss: 12.1634 - val_acc: 0.2114\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 7.7266 - acc: 0.2049 - val_loss: 12.1634 - val_acc: 0.2114\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 7.7266 - acc: 0.2049 - val_loss: 12.1634 - val_acc: 0.2114\n",
            "Epoch 6: early stopping\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 1, dense_activation = relu, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 22ms/step - loss: 0.9845 - acc: 0.2454 - val_loss: 0.8954 - val_acc: 0.3337\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7706 - acc: 0.3488 - val_loss: 0.8325 - val_acc: 0.3791\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7324 - acc: 0.3711 - val_loss: 0.7930 - val_acc: 0.4064\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6979 - acc: 0.4275 - val_loss: 0.7570 - val_acc: 0.4502\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6674 - acc: 0.4797 - val_loss: 0.7095 - val_acc: 0.5621\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6405 - acc: 0.5537 - val_loss: 0.6814 - val_acc: 0.6008\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6162 - acc: 0.5910 - val_loss: 0.6487 - val_acc: 0.6421\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5941 - acc: 0.6407 - val_loss: 0.6319 - val_acc: 0.6478\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5741 - acc: 0.6498 - val_loss: 0.6056 - val_acc: 0.6756\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5553 - acc: 0.6912 - val_loss: 0.5935 - val_acc: 0.6828\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5373 - acc: 0.6980 - val_loss: 0.5575 - val_acc: 0.7163\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5207 - acc: 0.7226 - val_loss: 0.5477 - val_acc: 0.7200\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5049 - acc: 0.7376 - val_loss: 0.5357 - val_acc: 0.7292\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4896 - acc: 0.7582 - val_loss: 0.5249 - val_acc: 0.7468\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4753 - acc: 0.7623 - val_loss: 0.5089 - val_acc: 0.7540\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4617 - acc: 0.7736 - val_loss: 0.4901 - val_acc: 0.7715\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4489 - acc: 0.7796 - val_loss: 0.4849 - val_acc: 0.7746\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4364 - acc: 0.7903 - val_loss: 0.4685 - val_acc: 0.7875\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4245 - acc: 0.8026 - val_loss: 0.4554 - val_acc: 0.7947\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4137 - acc: 0.8063 - val_loss: 0.4485 - val_acc: 0.7999\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4028 - acc: 0.8152 - val_loss: 0.4262 - val_acc: 0.8185\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3926 - acc: 0.8166 - val_loss: 0.4159 - val_acc: 0.8247\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3833 - acc: 0.8280 - val_loss: 0.4091 - val_acc: 0.8288\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3740 - acc: 0.8282 - val_loss: 0.4137 - val_acc: 0.8241\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3650 - acc: 0.8366 - val_loss: 0.4031 - val_acc: 0.8293\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3567 - acc: 0.8358 - val_loss: 0.3912 - val_acc: 0.8339\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3486 - acc: 0.8432 - val_loss: 0.3828 - val_acc: 0.8370\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3408 - acc: 0.8446 - val_loss: 0.3820 - val_acc: 0.8350\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3329 - acc: 0.8557 - val_loss: 0.3868 - val_acc: 0.8319\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3259 - acc: 0.8531 - val_loss: 0.3718 - val_acc: 0.8412\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3185 - acc: 0.8602 - val_loss: 0.3585 - val_acc: 0.8468\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3113 - acc: 0.8669 - val_loss: 0.3730 - val_acc: 0.8396\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3049 - acc: 0.8658 - val_loss: 0.3441 - val_acc: 0.8592\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2984 - acc: 0.8743 - val_loss: 0.3331 - val_acc: 0.8654\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2919 - acc: 0.8832 - val_loss: 0.3509 - val_acc: 0.8484\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2860 - acc: 0.8783 - val_loss: 0.3204 - val_acc: 0.8736\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2797 - acc: 0.8891 - val_loss: 0.3530 - val_acc: 0.8463\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2746 - acc: 0.8855 - val_loss: 0.3352 - val_acc: 0.8587\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2685 - acc: 0.8941 - val_loss: 0.3225 - val_acc: 0.8680\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.2630 - acc: 0.8958 - val_loss: 0.3176 - val_acc: 0.8736\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 1, dense_activation = relu, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.6169 - acc: 0.6362 - val_loss: 0.5988 - val_acc: 0.6570\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5069 - acc: 0.7525 - val_loss: 0.5114 - val_acc: 0.7514\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4449 - acc: 0.8036 - val_loss: 0.4181 - val_acc: 0.8236\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3951 - acc: 0.8288 - val_loss: 0.3876 - val_acc: 0.8623\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3592 - acc: 0.8567 - val_loss: 0.4287 - val_acc: 0.8092\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3329 - acc: 0.8664 - val_loss: 0.3477 - val_acc: 0.8804\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3087 - acc: 0.8870 - val_loss: 0.3187 - val_acc: 0.8953\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2885 - acc: 0.8975 - val_loss: 0.3230 - val_acc: 0.8891\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2702 - acc: 0.9093 - val_loss: 0.2964 - val_acc: 0.9030\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2548 - acc: 0.9191 - val_loss: 0.3635 - val_acc: 0.8695\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2404 - acc: 0.9237 - val_loss: 0.3216 - val_acc: 0.8943\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2269 - acc: 0.9297 - val_loss: 0.3071 - val_acc: 0.9025\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.2149 - acc: 0.9369 - val_loss: 0.2917 - val_acc: 0.9077\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.2040 - acc: 0.9434 - val_loss: 0.2793 - val_acc: 0.9149\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1932 - acc: 0.9506 - val_loss: 0.2487 - val_acc: 0.9257\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1838 - acc: 0.9547 - val_loss: 0.2431 - val_acc: 0.9299\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1736 - acc: 0.9618 - val_loss: 0.2752 - val_acc: 0.9165\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1648 - acc: 0.9653 - val_loss: 0.2616 - val_acc: 0.9268\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.1582 - acc: 0.9674 - val_loss: 0.2370 - val_acc: 0.9304\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1499 - acc: 0.9694 - val_loss: 0.2289 - val_acc: 0.9355\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1428 - acc: 0.9718 - val_loss: 0.2195 - val_acc: 0.9428\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1366 - acc: 0.9743 - val_loss: 0.2474 - val_acc: 0.9324\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1308 - acc: 0.9759 - val_loss: 0.2257 - val_acc: 0.9386\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1245 - acc: 0.9778 - val_loss: 0.2123 - val_acc: 0.9433\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.1183 - acc: 0.9795 - val_loss: 0.2144 - val_acc: 0.9422\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1133 - acc: 0.9809 - val_loss: 0.2060 - val_acc: 0.9448\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1087 - acc: 0.9822 - val_loss: 0.2021 - val_acc: 0.9443\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.1045 - acc: 0.9827 - val_loss: 0.2020 - val_acc: 0.9428\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0990 - acc: 0.9832 - val_loss: 0.1916 - val_acc: 0.9484\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0950 - acc: 0.9848 - val_loss: 0.1943 - val_acc: 0.9458\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0906 - acc: 0.9861 - val_loss: 0.1918 - val_acc: 0.9474\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0869 - acc: 0.9866 - val_loss: 0.1890 - val_acc: 0.9489\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0833 - acc: 0.9876 - val_loss: 0.1862 - val_acc: 0.9474\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0799 - acc: 0.9883 - val_loss: 0.1826 - val_acc: 0.9484\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0773 - acc: 0.9887 - val_loss: 0.1769 - val_acc: 0.9531\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0735 - acc: 0.9892 - val_loss: 0.1738 - val_acc: 0.9531\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0703 - acc: 0.9896 - val_loss: 0.1715 - val_acc: 0.9536\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0673 - acc: 0.9903 - val_loss: 0.1754 - val_acc: 0.9520\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0648 - acc: 0.9908 - val_loss: 0.1697 - val_acc: 0.9546\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0616 - acc: 0.9912 - val_loss: 0.1708 - val_acc: 0.9526\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 1, dense_activation = relu, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 2.5786 - acc: 0.2490 - val_loss: 1.1691 - val_acc: 0.3703\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.9546 - acc: 0.3963 - val_loss: 1.0355 - val_acc: 0.4214\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.8913 - acc: 0.4226 - val_loss: 0.9807 - val_acc: 0.4265\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.8323 - acc: 0.4251 - val_loss: 0.8200 - val_acc: 0.4662\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7439 - acc: 0.4475 - val_loss: 0.8040 - val_acc: 0.4590\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7198 - acc: 0.4597 - val_loss: 0.7859 - val_acc: 0.4636\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6992 - acc: 0.4654 - val_loss: 0.7639 - val_acc: 0.4925\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6805 - acc: 0.5119 - val_loss: 0.7432 - val_acc: 0.5178\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6634 - acc: 0.5287 - val_loss: 0.7209 - val_acc: 0.5503\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6475 - acc: 0.5558 - val_loss: 0.7007 - val_acc: 0.5735\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6328 - acc: 0.5831 - val_loss: 0.6850 - val_acc: 0.5833\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6188 - acc: 0.5973 - val_loss: 0.6704 - val_acc: 0.5936\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6053 - acc: 0.6084 - val_loss: 0.6503 - val_acc: 0.6163\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5924 - acc: 0.6330 - val_loss: 0.6306 - val_acc: 0.6364\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5801 - acc: 0.6596 - val_loss: 0.6246 - val_acc: 0.6374\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5682 - acc: 0.6587 - val_loss: 0.6042 - val_acc: 0.6565\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5563 - acc: 0.6772 - val_loss: 0.5946 - val_acc: 0.6622\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5449 - acc: 0.6948 - val_loss: 0.5827 - val_acc: 0.6761\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5340 - acc: 0.7095 - val_loss: 0.5795 - val_acc: 0.6782\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5233 - acc: 0.7081 - val_loss: 0.5641 - val_acc: 0.6998\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5124 - acc: 0.7262 - val_loss: 0.5470 - val_acc: 0.7138\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5021 - acc: 0.7329 - val_loss: 0.5273 - val_acc: 0.7339\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4923 - acc: 0.7502 - val_loss: 0.5311 - val_acc: 0.7267\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4825 - acc: 0.7558 - val_loss: 0.5233 - val_acc: 0.7298\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4729 - acc: 0.7618 - val_loss: 0.5099 - val_acc: 0.7442\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4639 - acc: 0.7672 - val_loss: 0.5006 - val_acc: 0.7499\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4546 - acc: 0.7769 - val_loss: 0.4961 - val_acc: 0.7519\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4459 - acc: 0.7759 - val_loss: 0.4770 - val_acc: 0.7741\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4373 - acc: 0.7923 - val_loss: 0.4789 - val_acc: 0.7710\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4291 - acc: 0.7835 - val_loss: 0.4540 - val_acc: 0.7916\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4210 - acc: 0.8041 - val_loss: 0.4585 - val_acc: 0.7922\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4132 - acc: 0.8094 - val_loss: 0.4537 - val_acc: 0.7932\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4056 - acc: 0.8141 - val_loss: 0.4489 - val_acc: 0.7932\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.3984 - acc: 0.8168 - val_loss: 0.4275 - val_acc: 0.8118\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.3912 - acc: 0.8224 - val_loss: 0.4220 - val_acc: 0.8159\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.3841 - acc: 0.8300 - val_loss: 0.4201 - val_acc: 0.8143\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3772 - acc: 0.8348 - val_loss: 0.4149 - val_acc: 0.8190\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3705 - acc: 0.8388 - val_loss: 0.4172 - val_acc: 0.8107\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3641 - acc: 0.8369 - val_loss: 0.3981 - val_acc: 0.8288\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3578 - acc: 0.8445 - val_loss: 0.3888 - val_acc: 0.8386\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 1, dense_activation = relu, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 0.6987 - acc: 0.2063 - val_loss: 0.7429 - val_acc: 0.2135\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6825 - acc: 0.2505 - val_loss: 0.7135 - val_acc: 0.3564\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6689 - acc: 0.4218 - val_loss: 0.7011 - val_acc: 0.4812\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.6571 - acc: 0.5101 - val_loss: 0.6805 - val_acc: 0.5673\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6465 - acc: 0.5732 - val_loss: 0.6734 - val_acc: 0.5828\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6372 - acc: 0.5973 - val_loss: 0.6613 - val_acc: 0.6132\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6287 - acc: 0.6218 - val_loss: 0.6529 - val_acc: 0.6215\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6207 - acc: 0.6365 - val_loss: 0.6416 - val_acc: 0.6333\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6133 - acc: 0.6576 - val_loss: 0.6316 - val_acc: 0.6483\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6065 - acc: 0.6562 - val_loss: 0.6253 - val_acc: 0.6581\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6000 - acc: 0.6890 - val_loss: 0.6221 - val_acc: 0.6565\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.5940 - acc: 0.6827 - val_loss: 0.6134 - val_acc: 0.6725\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.5880 - acc: 0.6888 - val_loss: 0.6033 - val_acc: 0.6885\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5824 - acc: 0.7064 - val_loss: 0.5991 - val_acc: 0.6931\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.5772 - acc: 0.7044 - val_loss: 0.5871 - val_acc: 0.7050\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5720 - acc: 0.7225 - val_loss: 0.5839 - val_acc: 0.7065\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5669 - acc: 0.7289 - val_loss: 0.5834 - val_acc: 0.7040\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5620 - acc: 0.7359 - val_loss: 0.5802 - val_acc: 0.7071\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5575 - acc: 0.7373 - val_loss: 0.5710 - val_acc: 0.7215\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5531 - acc: 0.7560 - val_loss: 0.5714 - val_acc: 0.7303\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5484 - acc: 0.7617 - val_loss: 0.5637 - val_acc: 0.7447\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5441 - acc: 0.7667 - val_loss: 0.5629 - val_acc: 0.7411\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5399 - acc: 0.7616 - val_loss: 0.5508 - val_acc: 0.7643\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.5359 - acc: 0.7729 - val_loss: 0.5500 - val_acc: 0.7638\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.5319 - acc: 0.7786 - val_loss: 0.5498 - val_acc: 0.7597\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5281 - acc: 0.7794 - val_loss: 0.5431 - val_acc: 0.7669\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.5244 - acc: 0.7849 - val_loss: 0.5320 - val_acc: 0.7875\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5206 - acc: 0.7899 - val_loss: 0.5346 - val_acc: 0.7788\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5170 - acc: 0.7857 - val_loss: 0.5285 - val_acc: 0.7865\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5135 - acc: 0.7942 - val_loss: 0.5258 - val_acc: 0.7875\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5101 - acc: 0.7996 - val_loss: 0.5254 - val_acc: 0.7844\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5069 - acc: 0.8068 - val_loss: 0.5244 - val_acc: 0.7855\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5034 - acc: 0.8089 - val_loss: 0.5272 - val_acc: 0.7803\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5003 - acc: 0.8050 - val_loss: 0.5150 - val_acc: 0.7947\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4971 - acc: 0.8108 - val_loss: 0.5135 - val_acc: 0.7953\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4940 - acc: 0.8123 - val_loss: 0.5093 - val_acc: 0.7994\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4911 - acc: 0.8170 - val_loss: 0.5056 - val_acc: 0.8040\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4880 - acc: 0.8155 - val_loss: 0.5005 - val_acc: 0.8087\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4852 - acc: 0.8197 - val_loss: 0.5000 - val_acc: 0.8076\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4822 - acc: 0.8205 - val_loss: 0.4926 - val_acc: 0.8164\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 1, dense_activation = sigmoid, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 0.7365 - acc: 0.2049 - val_loss: 0.8444 - val_acc: 0.2114\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7131 - acc: 0.2049 - val_loss: 0.7891 - val_acc: 0.2114\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.7011 - acc: 0.2074 - val_loss: 0.7652 - val_acc: 0.2202\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6913 - acc: 0.2417 - val_loss: 0.7475 - val_acc: 0.2584\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6823 - acc: 0.2872 - val_loss: 0.7325 - val_acc: 0.3347\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6738 - acc: 0.3500 - val_loss: 0.7205 - val_acc: 0.3909\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6660 - acc: 0.4026 - val_loss: 0.7108 - val_acc: 0.4337\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6587 - acc: 0.4558 - val_loss: 0.6991 - val_acc: 0.4807\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6519 - acc: 0.4953 - val_loss: 0.6916 - val_acc: 0.5090\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6455 - acc: 0.5243 - val_loss: 0.6806 - val_acc: 0.5456\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6395 - acc: 0.5505 - val_loss: 0.6752 - val_acc: 0.5565\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6339 - acc: 0.5644 - val_loss: 0.6683 - val_acc: 0.5714\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6285 - acc: 0.5849 - val_loss: 0.6602 - val_acc: 0.5869\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6234 - acc: 0.6054 - val_loss: 0.6560 - val_acc: 0.5910\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6186 - acc: 0.6173 - val_loss: 0.6463 - val_acc: 0.6240\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6139 - acc: 0.6328 - val_loss: 0.6433 - val_acc: 0.6261\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6095 - acc: 0.6355 - val_loss: 0.6384 - val_acc: 0.6395\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6051 - acc: 0.6585 - val_loss: 0.6294 - val_acc: 0.6493\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6009 - acc: 0.6651 - val_loss: 0.6263 - val_acc: 0.6498\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5969 - acc: 0.6700 - val_loss: 0.6252 - val_acc: 0.6550\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5929 - acc: 0.6713 - val_loss: 0.6177 - val_acc: 0.6674\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5892 - acc: 0.6907 - val_loss: 0.6126 - val_acc: 0.6787\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.5854 - acc: 0.6928 - val_loss: 0.6097 - val_acc: 0.6813\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5817 - acc: 0.7048 - val_loss: 0.6056 - val_acc: 0.6875\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5783 - acc: 0.6993 - val_loss: 0.5999 - val_acc: 0.6962\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5748 - acc: 0.7144 - val_loss: 0.5951 - val_acc: 0.6983\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5715 - acc: 0.7230 - val_loss: 0.5930 - val_acc: 0.7004\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5681 - acc: 0.7257 - val_loss: 0.5887 - val_acc: 0.7060\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.5651 - acc: 0.7250 - val_loss: 0.5852 - val_acc: 0.7091\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.5618 - acc: 0.7349 - val_loss: 0.5806 - val_acc: 0.7184\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5587 - acc: 0.7394 - val_loss: 0.5795 - val_acc: 0.7169\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5558 - acc: 0.7406 - val_loss: 0.5763 - val_acc: 0.7215\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5528 - acc: 0.7546 - val_loss: 0.5720 - val_acc: 0.7298\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5498 - acc: 0.7431 - val_loss: 0.5707 - val_acc: 0.7323\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5469 - acc: 0.7600 - val_loss: 0.5673 - val_acc: 0.7370\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5441 - acc: 0.7544 - val_loss: 0.5645 - val_acc: 0.7432\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5413 - acc: 0.7623 - val_loss: 0.5608 - val_acc: 0.7494\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5387 - acc: 0.7703 - val_loss: 0.5580 - val_acc: 0.7514\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5359 - acc: 0.7652 - val_loss: 0.5559 - val_acc: 0.7530\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5333 - acc: 0.7725 - val_loss: 0.5533 - val_acc: 0.7592\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 1, dense_activation = sigmoid, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 0.6703 - acc: 0.5233 - val_loss: 0.6844 - val_acc: 0.5425\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.6378 - acc: 0.5832 - val_loss: 0.6410 - val_acc: 0.6178\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.6135 - acc: 0.6534 - val_loss: 0.6321 - val_acc: 0.6313\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.5934 - acc: 0.6778 - val_loss: 0.5924 - val_acc: 0.6895\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.5759 - acc: 0.7168 - val_loss: 0.5902 - val_acc: 0.6864\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5602 - acc: 0.7434 - val_loss: 0.5668 - val_acc: 0.7215\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.5461 - acc: 0.7536 - val_loss: 0.5465 - val_acc: 0.7530\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5328 - acc: 0.7674 - val_loss: 0.5291 - val_acc: 0.7777\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.5213 - acc: 0.7889 - val_loss: 0.5215 - val_acc: 0.7782\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.5100 - acc: 0.7898 - val_loss: 0.5100 - val_acc: 0.7922\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4998 - acc: 0.8090 - val_loss: 0.5145 - val_acc: 0.7798\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4902 - acc: 0.8081 - val_loss: 0.4968 - val_acc: 0.8066\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4816 - acc: 0.8219 - val_loss: 0.4923 - val_acc: 0.8071\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4729 - acc: 0.8250 - val_loss: 0.4911 - val_acc: 0.8040\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4648 - acc: 0.8294 - val_loss: 0.4785 - val_acc: 0.8107\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.4572 - acc: 0.8293 - val_loss: 0.4774 - val_acc: 0.8092\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4502 - acc: 0.8361 - val_loss: 0.4564 - val_acc: 0.8303\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4432 - acc: 0.8429 - val_loss: 0.4588 - val_acc: 0.8226\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4365 - acc: 0.8365 - val_loss: 0.4427 - val_acc: 0.8396\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4302 - acc: 0.8486 - val_loss: 0.4430 - val_acc: 0.8381\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4239 - acc: 0.8524 - val_loss: 0.4434 - val_acc: 0.8360\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4180 - acc: 0.8554 - val_loss: 0.4370 - val_acc: 0.8396\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4124 - acc: 0.8578 - val_loss: 0.4311 - val_acc: 0.8427\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.4068 - acc: 0.8611 - val_loss: 0.4222 - val_acc: 0.8520\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.4013 - acc: 0.8632 - val_loss: 0.4081 - val_acc: 0.8602\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3960 - acc: 0.8683 - val_loss: 0.4097 - val_acc: 0.8577\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3909 - acc: 0.8704 - val_loss: 0.4071 - val_acc: 0.8577\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3859 - acc: 0.8743 - val_loss: 0.4017 - val_acc: 0.8597\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3810 - acc: 0.8747 - val_loss: 0.3961 - val_acc: 0.8613\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3764 - acc: 0.8780 - val_loss: 0.3909 - val_acc: 0.8649\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3718 - acc: 0.8811 - val_loss: 0.3916 - val_acc: 0.8638\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3674 - acc: 0.8825 - val_loss: 0.3894 - val_acc: 0.8638\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3629 - acc: 0.8842 - val_loss: 0.3811 - val_acc: 0.8711\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3587 - acc: 0.8887 - val_loss: 0.3758 - val_acc: 0.8747\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3543 - acc: 0.8918 - val_loss: 0.3750 - val_acc: 0.8742\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3501 - acc: 0.8939 - val_loss: 0.3801 - val_acc: 0.8675\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3462 - acc: 0.8934 - val_loss: 0.3725 - val_acc: 0.8711\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3422 - acc: 0.8970 - val_loss: 0.3678 - val_acc: 0.8742\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3382 - acc: 0.8988 - val_loss: 0.3566 - val_acc: 0.8840\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3343 - acc: 0.9008 - val_loss: 0.3486 - val_acc: 0.8891\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 1, dense_activation = sigmoid, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 0.7484 - acc: 0.7828 - val_loss: 0.6211 - val_acc: 0.6998\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6610 - acc: 0.5921 - val_loss: 0.6602 - val_acc: 0.5420\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6474 - acc: 0.5638 - val_loss: 0.6468 - val_acc: 0.5797\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6356 - acc: 0.6019 - val_loss: 0.6425 - val_acc: 0.5817\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6243 - acc: 0.6080 - val_loss: 0.6273 - val_acc: 0.6008\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6132 - acc: 0.6387 - val_loss: 0.6088 - val_acc: 0.6405\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.6026 - acc: 0.6673 - val_loss: 0.6021 - val_acc: 0.6591\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5925 - acc: 0.6921 - val_loss: 0.5941 - val_acc: 0.6704\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5827 - acc: 0.7028 - val_loss: 0.5805 - val_acc: 0.6998\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5733 - acc: 0.7198 - val_loss: 0.5660 - val_acc: 0.7251\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5645 - acc: 0.7381 - val_loss: 0.5634 - val_acc: 0.7236\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5558 - acc: 0.7493 - val_loss: 0.5553 - val_acc: 0.7334\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5478 - acc: 0.7599 - val_loss: 0.5474 - val_acc: 0.7452\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5397 - acc: 0.7789 - val_loss: 0.5457 - val_acc: 0.7442\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5323 - acc: 0.7709 - val_loss: 0.5328 - val_acc: 0.7617\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5250 - acc: 0.7799 - val_loss: 0.5235 - val_acc: 0.7757\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5181 - acc: 0.7952 - val_loss: 0.5177 - val_acc: 0.7813\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5113 - acc: 0.7951 - val_loss: 0.5119 - val_acc: 0.7875\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5051 - acc: 0.8074 - val_loss: 0.5012 - val_acc: 0.7942\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4989 - acc: 0.8068 - val_loss: 0.5029 - val_acc: 0.7911\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4930 - acc: 0.8095 - val_loss: 0.4981 - val_acc: 0.7932\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4873 - acc: 0.8113 - val_loss: 0.4830 - val_acc: 0.8164\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4819 - acc: 0.8237 - val_loss: 0.4855 - val_acc: 0.8040\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4765 - acc: 0.8202 - val_loss: 0.4742 - val_acc: 0.8205\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4714 - acc: 0.8184 - val_loss: 0.4698 - val_acc: 0.8226\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4666 - acc: 0.8338 - val_loss: 0.4803 - val_acc: 0.8035\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4615 - acc: 0.8289 - val_loss: 0.4638 - val_acc: 0.8231\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4572 - acc: 0.8316 - val_loss: 0.4655 - val_acc: 0.8231\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4523 - acc: 0.8337 - val_loss: 0.4606 - val_acc: 0.8226\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4479 - acc: 0.8407 - val_loss: 0.4662 - val_acc: 0.8179\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4436 - acc: 0.8377 - val_loss: 0.4570 - val_acc: 0.8241\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4394 - acc: 0.8368 - val_loss: 0.4448 - val_acc: 0.8334\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4353 - acc: 0.8410 - val_loss: 0.4406 - val_acc: 0.8375\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4312 - acc: 0.8481 - val_loss: 0.4424 - val_acc: 0.8308\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4274 - acc: 0.8456 - val_loss: 0.4373 - val_acc: 0.8339\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4236 - acc: 0.8469 - val_loss: 0.4273 - val_acc: 0.8453\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4196 - acc: 0.8477 - val_loss: 0.4286 - val_acc: 0.8412\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4159 - acc: 0.8526 - val_loss: 0.4239 - val_acc: 0.8453\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4123 - acc: 0.8529 - val_loss: 0.4257 - val_acc: 0.8401\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4087 - acc: 0.8591 - val_loss: 0.4256 - val_acc: 0.8391\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 1, dense_activation = sigmoid, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 0.7059 - acc: 0.6798 - val_loss: 0.6566 - val_acc: 0.5333\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.6378 - acc: 0.5841 - val_loss: 0.6338 - val_acc: 0.5797\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.6147 - acc: 0.6355 - val_loss: 0.6020 - val_acc: 0.6441\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.5923 - acc: 0.6921 - val_loss: 0.5843 - val_acc: 0.6859\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.5713 - acc: 0.7345 - val_loss: 0.5575 - val_acc: 0.7231\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.5521 - acc: 0.7630 - val_loss: 0.5496 - val_acc: 0.7292\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.5346 - acc: 0.7786 - val_loss: 0.5199 - val_acc: 0.7793\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.5191 - acc: 0.7942 - val_loss: 0.5063 - val_acc: 0.7891\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.5043 - acc: 0.8036 - val_loss: 0.4943 - val_acc: 0.8025\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4907 - acc: 0.8166 - val_loss: 0.4761 - val_acc: 0.8174\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4782 - acc: 0.8231 - val_loss: 0.4774 - val_acc: 0.8118\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4666 - acc: 0.8244 - val_loss: 0.4553 - val_acc: 0.8303\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4559 - acc: 0.8338 - val_loss: 0.4568 - val_acc: 0.8252\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4458 - acc: 0.8383 - val_loss: 0.4547 - val_acc: 0.8236\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.4362 - acc: 0.8437 - val_loss: 0.4368 - val_acc: 0.8406\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.4274 - acc: 0.8455 - val_loss: 0.4311 - val_acc: 0.8427\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4186 - acc: 0.8529 - val_loss: 0.4332 - val_acc: 0.8319\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.4103 - acc: 0.8561 - val_loss: 0.4112 - val_acc: 0.8577\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.4021 - acc: 0.8642 - val_loss: 0.4060 - val_acc: 0.8602\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3945 - acc: 0.8667 - val_loss: 0.3914 - val_acc: 0.8669\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3872 - acc: 0.8725 - val_loss: 0.3909 - val_acc: 0.8654\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3799 - acc: 0.8747 - val_loss: 0.4002 - val_acc: 0.8597\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3732 - acc: 0.8767 - val_loss: 0.3745 - val_acc: 0.8726\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3661 - acc: 0.8843 - val_loss: 0.3872 - val_acc: 0.8669\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3595 - acc: 0.8829 - val_loss: 0.3597 - val_acc: 0.8860\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3533 - acc: 0.8923 - val_loss: 0.3781 - val_acc: 0.8685\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3470 - acc: 0.8907 - val_loss: 0.3717 - val_acc: 0.8711\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3410 - acc: 0.8950 - val_loss: 0.3546 - val_acc: 0.8829\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3350 - acc: 0.8972 - val_loss: 0.3543 - val_acc: 0.8788\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3292 - acc: 0.9023 - val_loss: 0.3454 - val_acc: 0.8876\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3235 - acc: 0.9056 - val_loss: 0.3420 - val_acc: 0.8891\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.3182 - acc: 0.9064 - val_loss: 0.3385 - val_acc: 0.8917\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.3129 - acc: 0.9095 - val_loss: 0.3315 - val_acc: 0.8979\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3075 - acc: 0.9128 - val_loss: 0.3339 - val_acc: 0.8912\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.3024 - acc: 0.9131 - val_loss: 0.3281 - val_acc: 0.8963\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2970 - acc: 0.9181 - val_loss: 0.3246 - val_acc: 0.8994\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.2920 - acc: 0.9195 - val_loss: 0.3300 - val_acc: 0.8896\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2873 - acc: 0.9237 - val_loss: 0.3241 - val_acc: 0.8917\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.2828 - acc: 0.9234 - val_loss: 0.3009 - val_acc: 0.9149\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 0.2778 - acc: 0.9275 - val_loss: 0.2971 - val_acc: 0.9149\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 1, dense_activation = sigmoid, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 0.6724 - acc: 0.4948 - val_loss: 0.6971 - val_acc: 0.5358\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6390 - acc: 0.5999 - val_loss: 0.6518 - val_acc: 0.5998\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.6146 - acc: 0.6437 - val_loss: 0.6158 - val_acc: 0.6519\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.5934 - acc: 0.6927 - val_loss: 0.6046 - val_acc: 0.6674\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.5753 - acc: 0.7211 - val_loss: 0.5905 - val_acc: 0.6864\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.5595 - acc: 0.7404 - val_loss: 0.5649 - val_acc: 0.7313\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.5450 - acc: 0.7577 - val_loss: 0.5508 - val_acc: 0.7504\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.5317 - acc: 0.7732 - val_loss: 0.5309 - val_acc: 0.7793\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.5196 - acc: 0.7968 - val_loss: 0.5372 - val_acc: 0.7607\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.5085 - acc: 0.7942 - val_loss: 0.5172 - val_acc: 0.7870\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4982 - acc: 0.8110 - val_loss: 0.5093 - val_acc: 0.7916\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4882 - acc: 0.8152 - val_loss: 0.4997 - val_acc: 0.8004\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4792 - acc: 0.8213 - val_loss: 0.4927 - val_acc: 0.8051\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4703 - acc: 0.8306 - val_loss: 0.4870 - val_acc: 0.8102\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4624 - acc: 0.8259 - val_loss: 0.4668 - val_acc: 0.8288\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.4546 - acc: 0.8419 - val_loss: 0.4727 - val_acc: 0.8185\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4470 - acc: 0.8370 - val_loss: 0.4532 - val_acc: 0.8355\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4398 - acc: 0.8484 - val_loss: 0.4639 - val_acc: 0.8185\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4332 - acc: 0.8436 - val_loss: 0.4439 - val_acc: 0.8401\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4263 - acc: 0.8509 - val_loss: 0.4322 - val_acc: 0.8479\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4202 - acc: 0.8582 - val_loss: 0.4414 - val_acc: 0.8345\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4138 - acc: 0.8601 - val_loss: 0.4314 - val_acc: 0.8427\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4077 - acc: 0.8611 - val_loss: 0.4204 - val_acc: 0.8510\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.4021 - acc: 0.8667 - val_loss: 0.4171 - val_acc: 0.8515\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3963 - acc: 0.8656 - val_loss: 0.4152 - val_acc: 0.8510\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3909 - acc: 0.8714 - val_loss: 0.3984 - val_acc: 0.8669\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3856 - acc: 0.8789 - val_loss: 0.4065 - val_acc: 0.8540\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3803 - acc: 0.8761 - val_loss: 0.3920 - val_acc: 0.8675\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3756 - acc: 0.8823 - val_loss: 0.3926 - val_acc: 0.8669\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3703 - acc: 0.8854 - val_loss: 0.3883 - val_acc: 0.8695\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3655 - acc: 0.8918 - val_loss: 0.3956 - val_acc: 0.8551\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3610 - acc: 0.8867 - val_loss: 0.3812 - val_acc: 0.8716\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3563 - acc: 0.8914 - val_loss: 0.3744 - val_acc: 0.8773\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.3519 - acc: 0.8934 - val_loss: 0.3725 - val_acc: 0.8783\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3474 - acc: 0.8974 - val_loss: 0.3603 - val_acc: 0.8855\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3432 - acc: 0.8992 - val_loss: 0.3631 - val_acc: 0.8829\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3387 - acc: 0.9026 - val_loss: 0.3625 - val_acc: 0.8819\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3345 - acc: 0.9033 - val_loss: 0.3621 - val_acc: 0.8804\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3304 - acc: 0.9028 - val_loss: 0.3369 - val_acc: 0.8994\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.3266 - acc: 0.9063 - val_loss: 0.3346 - val_acc: 0.8994\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 1, dense_activation = sigmoid, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 4.4793 - acc: 0.0000e+00 - val_loss: 6.5819 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.2750 - acc: 0.0080 - val_loss: 6.5246 - val_acc: 0.0170\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.2515 - acc: 0.0357 - val_loss: 6.5013 - val_acc: 0.0423\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.2401 - acc: 0.0502 - val_loss: 6.4876 - val_acc: 0.0449\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.2327 - acc: 0.0468 - val_loss: 6.4788 - val_acc: 0.0392\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.2266 - acc: 0.0396 - val_loss: 6.4698 - val_acc: 0.0356\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.2211 - acc: 0.0344 - val_loss: 6.4634 - val_acc: 0.0315\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.2160 - acc: 0.0317 - val_loss: 6.4577 - val_acc: 0.0284\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.2111 - acc: 0.0276 - val_loss: 6.4504 - val_acc: 0.0294\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.2063 - acc: 0.0290 - val_loss: 6.4442 - val_acc: 0.0284\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.2019 - acc: 0.0285 - val_loss: 6.4393 - val_acc: 0.0304\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.1976 - acc: 0.0288 - val_loss: 6.4320 - val_acc: 0.0330\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.1935 - acc: 0.0285 - val_loss: 6.4278 - val_acc: 0.0330\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.1896 - acc: 0.0291 - val_loss: 6.4245 - val_acc: 0.0268\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.1858 - acc: 0.0264 - val_loss: 6.4195 - val_acc: 0.0340\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.1820 - acc: 0.0266 - val_loss: 6.4159 - val_acc: 0.0309\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.1784 - acc: 0.0263 - val_loss: 6.4105 - val_acc: 0.0330\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.1750 - acc: 0.0289 - val_loss: 6.4038 - val_acc: 0.0320\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.1715 - acc: 0.0268 - val_loss: 6.4027 - val_acc: 0.0315\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.1681 - acc: 0.0262 - val_loss: 6.3991 - val_acc: 0.0309\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.1648 - acc: 0.0262 - val_loss: 6.3969 - val_acc: 0.0304\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.1615 - acc: 0.0271 - val_loss: 6.3898 - val_acc: 0.0315\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.1583 - acc: 0.0266 - val_loss: 6.3912 - val_acc: 0.0268\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.1551 - acc: 0.0250 - val_loss: 6.3833 - val_acc: 0.0304\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.1520 - acc: 0.0250 - val_loss: 6.3786 - val_acc: 0.0304\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.1489 - acc: 0.0250 - val_loss: 6.3766 - val_acc: 0.0294\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.1458 - acc: 0.0235 - val_loss: 6.3732 - val_acc: 0.0299\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.1428 - acc: 0.0235 - val_loss: 6.3724 - val_acc: 0.0284\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.1397 - acc: 0.0224 - val_loss: 6.3688 - val_acc: 0.0273\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.1367 - acc: 0.0205 - val_loss: 6.3650 - val_acc: 0.0304\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.1338 - acc: 0.0223 - val_loss: 6.3628 - val_acc: 0.0237\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.1308 - acc: 0.0197 - val_loss: 6.3558 - val_acc: 0.0309\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.1279 - acc: 0.0201 - val_loss: 6.3539 - val_acc: 0.0294\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.1250 - acc: 0.0201 - val_loss: 6.3540 - val_acc: 0.0268\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.1220 - acc: 0.0191 - val_loss: 6.3525 - val_acc: 0.0278\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.1192 - acc: 0.0195 - val_loss: 6.3454 - val_acc: 0.0304\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.1164 - acc: 0.0193 - val_loss: 6.3429 - val_acc: 0.0268\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.1135 - acc: 0.0184 - val_loss: 6.3418 - val_acc: 0.0284\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.1107 - acc: 0.0184 - val_loss: 6.3417 - val_acc: 0.0253\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.1080 - acc: 0.0174 - val_loss: 6.3352 - val_acc: 0.0284\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 10, dense_activation = relu, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 4.6048 - acc: 0.2049 - val_loss: 6.4903 - val_acc: 0.2114\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.2631 - acc: 0.2049 - val_loss: 6.4696 - val_acc: 0.2114\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.2459 - acc: 0.2049 - val_loss: 6.4589 - val_acc: 0.2099\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 4.2362 - acc: 0.2031 - val_loss: 6.4519 - val_acc: 0.2099\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.2296 - acc: 0.1978 - val_loss: 6.4477 - val_acc: 0.2032\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.2246 - acc: 0.1847 - val_loss: 6.4441 - val_acc: 0.1898\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.2207 - acc: 0.1687 - val_loss: 6.4410 - val_acc: 0.1769\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.2175 - acc: 0.1585 - val_loss: 6.4399 - val_acc: 0.1640\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.2147 - acc: 0.1513 - val_loss: 6.4392 - val_acc: 0.1712\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.2122 - acc: 0.1537 - val_loss: 6.4378 - val_acc: 0.1635\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.2099 - acc: 0.1583 - val_loss: 6.4373 - val_acc: 0.1671\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.2077 - acc: 0.1600 - val_loss: 6.4344 - val_acc: 0.1738\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 4.2056 - acc: 0.1697 - val_loss: 6.4337 - val_acc: 0.1795\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.2036 - acc: 0.1720 - val_loss: 6.4322 - val_acc: 0.1877\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.2016 - acc: 0.1777 - val_loss: 6.4300 - val_acc: 0.1908\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1997 - acc: 0.1799 - val_loss: 6.4273 - val_acc: 0.1965\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1978 - acc: 0.1850 - val_loss: 6.4262 - val_acc: 0.1970\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1959 - acc: 0.1854 - val_loss: 6.4251 - val_acc: 0.1970\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1941 - acc: 0.1881 - val_loss: 6.4222 - val_acc: 0.2017\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1923 - acc: 0.1926 - val_loss: 6.4201 - val_acc: 0.2053\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1906 - acc: 0.1952 - val_loss: 6.4191 - val_acc: 0.2058\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1888 - acc: 0.1943 - val_loss: 6.4168 - val_acc: 0.2176\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1871 - acc: 0.2059 - val_loss: 6.4126 - val_acc: 0.2218\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1854 - acc: 0.1986 - val_loss: 6.4130 - val_acc: 0.2233\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1836 - acc: 0.2081 - val_loss: 6.4115 - val_acc: 0.2202\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1819 - acc: 0.2055 - val_loss: 6.4095 - val_acc: 0.2264\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1803 - acc: 0.2106 - val_loss: 6.4071 - val_acc: 0.2336\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1786 - acc: 0.2121 - val_loss: 6.4042 - val_acc: 0.2403\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1770 - acc: 0.2193 - val_loss: 6.4035 - val_acc: 0.2352\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1753 - acc: 0.2147 - val_loss: 6.4007 - val_acc: 0.2398\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1737 - acc: 0.2210 - val_loss: 6.4000 - val_acc: 0.2388\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1721 - acc: 0.2231 - val_loss: 6.3988 - val_acc: 0.2414\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1704 - acc: 0.2262 - val_loss: 6.3965 - val_acc: 0.2414\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1688 - acc: 0.2259 - val_loss: 6.3948 - val_acc: 0.2429\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1671 - acc: 0.2260 - val_loss: 6.3937 - val_acc: 0.2445\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1655 - acc: 0.2352 - val_loss: 6.3907 - val_acc: 0.2496\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1639 - acc: 0.2384 - val_loss: 6.3887 - val_acc: 0.2512\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1623 - acc: 0.2398 - val_loss: 6.3876 - val_acc: 0.2537\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1606 - acc: 0.2397 - val_loss: 6.3860 - val_acc: 0.2548\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1591 - acc: 0.2463 - val_loss: 6.3840 - val_acc: 0.2548\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 10, dense_activation = relu, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 4.9807 - acc: 0.0085 - val_loss: 7.6040 - val_acc: 0.0593\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.9242 - acc: 0.0686 - val_loss: 7.5970 - val_acc: 0.0676\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.9143 - acc: 0.0589 - val_loss: 7.5853 - val_acc: 0.0609\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.9057 - acc: 0.0524 - val_loss: 7.5802 - val_acc: 0.0572\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.8981 - acc: 0.0527 - val_loss: 7.5680 - val_acc: 0.0598\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.8911 - acc: 0.0507 - val_loss: 7.5605 - val_acc: 0.0547\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.8844 - acc: 0.0486 - val_loss: 7.5521 - val_acc: 0.0536\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.8781 - acc: 0.0460 - val_loss: 7.5505 - val_acc: 0.0480\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.8721 - acc: 0.0487 - val_loss: 7.5358 - val_acc: 0.0526\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.8661 - acc: 0.0459 - val_loss: 7.5389 - val_acc: 0.0444\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.8605 - acc: 0.0485 - val_loss: 7.5251 - val_acc: 0.0562\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.8549 - acc: 0.0471 - val_loss: 7.5186 - val_acc: 0.0469\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.8494 - acc: 0.0437 - val_loss: 7.5136 - val_acc: 0.0490\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.8440 - acc: 0.0418 - val_loss: 7.5105 - val_acc: 0.0449\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.8388 - acc: 0.0411 - val_loss: 7.5146 - val_acc: 0.0356\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.8336 - acc: 0.0413 - val_loss: 7.5022 - val_acc: 0.0351\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.8286 - acc: 0.0347 - val_loss: 7.4936 - val_acc: 0.0474\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.8237 - acc: 0.0325 - val_loss: 7.4895 - val_acc: 0.0433\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.8191 - acc: 0.0315 - val_loss: 7.4879 - val_acc: 0.0402\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.8147 - acc: 0.0322 - val_loss: 7.4791 - val_acc: 0.0382\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.8102 - acc: 0.0275 - val_loss: 7.4841 - val_acc: 0.0428\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.8061 - acc: 0.0302 - val_loss: 7.4730 - val_acc: 0.0474\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.8020 - acc: 0.0308 - val_loss: 7.4758 - val_acc: 0.0361\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.7982 - acc: 0.0322 - val_loss: 7.4630 - val_acc: 0.0459\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.7946 - acc: 0.0325 - val_loss: 7.4728 - val_acc: 0.0444\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.7910 - acc: 0.0322 - val_loss: 7.4609 - val_acc: 0.0454\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.7875 - acc: 0.0319 - val_loss: 7.4587 - val_acc: 0.0407\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.7839 - acc: 0.0333 - val_loss: 7.4474 - val_acc: 0.0330\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.7809 - acc: 0.0288 - val_loss: 7.4570 - val_acc: 0.0438\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.7777 - acc: 0.0344 - val_loss: 7.4480 - val_acc: 0.0438\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.7747 - acc: 0.0334 - val_loss: 7.4495 - val_acc: 0.0428\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.7717 - acc: 0.0355 - val_loss: 7.4467 - val_acc: 0.0542\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.7690 - acc: 0.0365 - val_loss: 7.4379 - val_acc: 0.0521\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.7661 - acc: 0.0369 - val_loss: 7.4430 - val_acc: 0.0552\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.7633 - acc: 0.0387 - val_loss: 7.4400 - val_acc: 0.0516\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.7605 - acc: 0.0409 - val_loss: 7.4343 - val_acc: 0.0578\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.7580 - acc: 0.0464 - val_loss: 7.4306 - val_acc: 0.0552\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.7556 - acc: 0.0436 - val_loss: 7.4304 - val_acc: 0.0609\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.7530 - acc: 0.0456 - val_loss: 7.4317 - val_acc: 0.0557\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.7506 - acc: 0.0494 - val_loss: 7.4303 - val_acc: 0.0614\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 10, dense_activation = relu, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 3.7616 - acc: 0.0000e+00 - val_loss: 4.4030 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.9434 - acc: 0.0000e+00 - val_loss: 4.2901 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.8990 - acc: 0.0000e+00 - val_loss: 4.2483 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.8778 - acc: 0.0000e+00 - val_loss: 4.2243 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.8634 - acc: 0.0000e+00 - val_loss: 4.2070 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.8527 - acc: 2.5790e-04 - val_loss: 4.1966 - val_acc: 0.0010\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.8441 - acc: 0.0015 - val_loss: 4.1882 - val_acc: 0.0026\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.8371 - acc: 0.0018 - val_loss: 4.1812 - val_acc: 0.0026\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.8314 - acc: 0.0019 - val_loss: 4.1760 - val_acc: 0.0026\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.8267 - acc: 0.0035 - val_loss: 4.1715 - val_acc: 0.0036\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.8227 - acc: 0.0068 - val_loss: 4.1668 - val_acc: 0.0046\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.8192 - acc: 0.0083 - val_loss: 4.1640 - val_acc: 0.0077\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.8161 - acc: 0.0139 - val_loss: 4.1589 - val_acc: 0.0119\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.8134 - acc: 0.0164 - val_loss: 4.1578 - val_acc: 0.0129\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 2.8109 - acc: 0.0177 - val_loss: 4.1566 - val_acc: 0.0134\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.8086 - acc: 0.0183 - val_loss: 4.1541 - val_acc: 0.0181\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.8066 - acc: 0.0190 - val_loss: 4.1515 - val_acc: 0.0181\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.8044 - acc: 0.0181 - val_loss: 4.1486 - val_acc: 0.0196\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.8025 - acc: 0.0188 - val_loss: 4.1495 - val_acc: 0.0181\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.8005 - acc: 0.0170 - val_loss: 4.1456 - val_acc: 0.0186\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7987 - acc: 0.0183 - val_loss: 4.1431 - val_acc: 0.0191\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7968 - acc: 0.0170 - val_loss: 4.1431 - val_acc: 0.0186\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7950 - acc: 0.0166 - val_loss: 4.1404 - val_acc: 0.0196\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7932 - acc: 0.0172 - val_loss: 4.1388 - val_acc: 0.0186\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7915 - acc: 0.0165 - val_loss: 4.1363 - val_acc: 0.0196\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7897 - acc: 0.0168 - val_loss: 4.1315 - val_acc: 0.0186\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7878 - acc: 0.0168 - val_loss: 4.1334 - val_acc: 0.0181\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7861 - acc: 0.0161 - val_loss: 4.1304 - val_acc: 0.0175\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7843 - acc: 0.0166 - val_loss: 4.1302 - val_acc: 0.0165\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7825 - acc: 0.0148 - val_loss: 4.1266 - val_acc: 0.0175\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7806 - acc: 0.0165 - val_loss: 4.1231 - val_acc: 0.0181\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7789 - acc: 0.0152 - val_loss: 4.1210 - val_acc: 0.0186\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7770 - acc: 0.0166 - val_loss: 4.1189 - val_acc: 0.0186\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7751 - acc: 0.0164 - val_loss: 4.1196 - val_acc: 0.0139\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7733 - acc: 0.0155 - val_loss: 4.1138 - val_acc: 0.0201\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7714 - acc: 0.0162 - val_loss: 4.1134 - val_acc: 0.0175\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7696 - acc: 0.0148 - val_loss: 4.1105 - val_acc: 0.0181\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7678 - acc: 0.0157 - val_loss: 4.1099 - val_acc: 0.0165\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7658 - acc: 0.0165 - val_loss: 4.1078 - val_acc: 0.0134\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 2.7639 - acc: 0.0123 - val_loss: 4.1067 - val_acc: 0.0160\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 10, dense_activation = relu, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 3.8016 - acc: 0.0000e+00 - val_loss: 4.4503 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.5094 - acc: 0.0000e+00 - val_loss: 4.4153 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.4856 - acc: 0.0000e+00 - val_loss: 4.3935 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.4666 - acc: 0.0000e+00 - val_loss: 4.3720 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.4504 - acc: 0.0000e+00 - val_loss: 4.3530 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.4352 - acc: 0.0000e+00 - val_loss: 4.3300 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.4214 - acc: 0.0000e+00 - val_loss: 4.3219 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.4083 - acc: 0.0000e+00 - val_loss: 4.3047 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.3959 - acc: 0.0000e+00 - val_loss: 4.3011 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.3839 - acc: 0.0000e+00 - val_loss: 4.2802 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.3721 - acc: 0.0000e+00 - val_loss: 4.2722 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.3613 - acc: 0.0000e+00 - val_loss: 4.2496 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.3514 - acc: 0.0000e+00 - val_loss: 4.2504 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.3416 - acc: 0.0000e+00 - val_loss: 4.2274 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.3331 - acc: 0.0000e+00 - val_loss: 4.2258 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.3253 - acc: 0.0000e+00 - val_loss: 4.2369 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.3174 - acc: 0.0000e+00 - val_loss: 4.2140 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.3102 - acc: 0.0000e+00 - val_loss: 4.2009 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.3033 - acc: 0.0000e+00 - val_loss: 4.2108 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.2971 - acc: 0.0000e+00 - val_loss: 4.1988 - val_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.2907 - acc: 0.0000e+00 - val_loss: 4.1913 - val_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.2849 - acc: 0.0000e+00 - val_loss: 4.2014 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.2790 - acc: 0.0000e+00 - val_loss: 4.1944 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.2736 - acc: 0.0000e+00 - val_loss: 4.1815 - val_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.2682 - acc: 0.0000e+00 - val_loss: 4.1949 - val_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.2632 - acc: 0.0000e+00 - val_loss: 4.1694 - val_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.2582 - acc: 0.0000e+00 - val_loss: 4.1863 - val_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.2534 - acc: 0.0000e+00 - val_loss: 4.1644 - val_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2486 - acc: 0.0000e+00 - val_loss: 4.1620 - val_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2444 - acc: 1.2895e-04 - val_loss: 4.1590 - val_acc: 5.1573e-04\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2397 - acc: 0.0000e+00 - val_loss: 4.1657 - val_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2355 - acc: 1.2895e-04 - val_loss: 4.1596 - val_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2311 - acc: 1.2895e-04 - val_loss: 4.1523 - val_acc: 5.1573e-04\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2276 - acc: 2.5790e-04 - val_loss: 4.1614 - val_acc: 0.0010\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2232 - acc: 2.5790e-04 - val_loss: 4.1514 - val_acc: 5.1573e-04\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2193 - acc: 0.0000e+00 - val_loss: 4.1521 - val_acc: 0.0010\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2157 - acc: 3.8685e-04 - val_loss: 4.1499 - val_acc: 0.0010\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2120 - acc: 1.2895e-04 - val_loss: 4.1485 - val_acc: 0.0010\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2083 - acc: 5.1580e-04 - val_loss: 4.1448 - val_acc: 0.0010\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.2048 - acc: 9.0264e-04 - val_loss: 4.1371 - val_acc: 0.0010\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 10, dense_activation = relu, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 5.5979 - acc: 0.7948 - val_loss: 6.9205 - val_acc: 0.7886\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.5777 - acc: 0.7951 - val_loss: 6.9010 - val_acc: 0.7886\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.5649 - acc: 0.7951 - val_loss: 6.8932 - val_acc: 0.7886\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.5540 - acc: 0.7950 - val_loss: 6.8833 - val_acc: 0.7886\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.5448 - acc: 0.7950 - val_loss: 6.8764 - val_acc: 0.7886\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.5361 - acc: 0.7950 - val_loss: 6.8758 - val_acc: 0.7886\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.5287 - acc: 0.7948 - val_loss: 6.8716 - val_acc: 0.7886\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.5227 - acc: 0.7948 - val_loss: 6.8659 - val_acc: 0.7886\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.5169 - acc: 0.7948 - val_loss: 6.8544 - val_acc: 0.7886\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.5117 - acc: 0.7948 - val_loss: 6.8414 - val_acc: 0.7886\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.5071 - acc: 0.7850 - val_loss: 6.8373 - val_acc: 0.7818\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.5031 - acc: 0.7852 - val_loss: 6.8445 - val_acc: 0.7777\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4994 - acc: 0.7838 - val_loss: 6.8365 - val_acc: 0.7782\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4956 - acc: 0.7841 - val_loss: 6.8367 - val_acc: 0.7767\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4926 - acc: 0.7836 - val_loss: 6.8389 - val_acc: 0.7751\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4894 - acc: 0.7822 - val_loss: 6.8305 - val_acc: 0.7726\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4864 - acc: 0.7817 - val_loss: 6.8246 - val_acc: 0.7726\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4838 - acc: 0.7807 - val_loss: 6.8276 - val_acc: 0.7705\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4808 - acc: 0.7801 - val_loss: 6.8226 - val_acc: 0.7684\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4784 - acc: 0.7776 - val_loss: 6.8236 - val_acc: 0.7684\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 5.4762 - acc: 0.7776 - val_loss: 6.8266 - val_acc: 0.7669\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 5.4735 - acc: 0.7769 - val_loss: 6.8213 - val_acc: 0.7664\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4717 - acc: 0.7737 - val_loss: 6.8184 - val_acc: 0.7653\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4694 - acc: 0.7721 - val_loss: 6.8164 - val_acc: 0.7643\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4671 - acc: 0.7694 - val_loss: 6.8146 - val_acc: 0.7659\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4652 - acc: 0.7692 - val_loss: 6.8147 - val_acc: 0.7628\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4634 - acc: 0.7269 - val_loss: 6.8144 - val_acc: 0.6493\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4614 - acc: 0.6649 - val_loss: 6.8130 - val_acc: 0.6405\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4596 - acc: 0.6594 - val_loss: 6.8081 - val_acc: 0.6441\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4579 - acc: 0.6571 - val_loss: 6.8104 - val_acc: 0.6359\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4563 - acc: 0.6603 - val_loss: 6.8066 - val_acc: 0.6374\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4546 - acc: 0.6570 - val_loss: 6.8075 - val_acc: 0.6354\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4530 - acc: 0.6593 - val_loss: 6.8084 - val_acc: 0.6405\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4514 - acc: 0.6547 - val_loss: 6.8032 - val_acc: 0.6385\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4499 - acc: 0.6585 - val_loss: 6.8051 - val_acc: 0.6349\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4484 - acc: 0.6625 - val_loss: 6.8027 - val_acc: 0.6405\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4470 - acc: 0.6585 - val_loss: 6.8030 - val_acc: 0.6349\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4457 - acc: 0.6554 - val_loss: 6.8011 - val_acc: 0.6431\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4443 - acc: 0.6638 - val_loss: 6.8054 - val_acc: 0.6323\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 5.4431 - acc: 0.6584 - val_loss: 6.7994 - val_acc: 0.6380\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 10, dense_activation = relu, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 4.9382 - acc: 0.0000e+00 - val_loss: 5.9373 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.6196 - acc: 0.0000e+00 - val_loss: 5.7970 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.4754 - acc: 0.0000e+00 - val_loss: 5.7034 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.4001 - acc: 0.0000e+00 - val_loss: 5.6720 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.3175 - acc: 0.0000e+00 - val_loss: 5.6034 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.2423 - acc: 0.0000e+00 - val_loss: 5.5912 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.2156 - acc: 0.0000e+00 - val_loss: 5.5602 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.1212 - acc: 0.0000e+00 - val_loss: 5.5348 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.1068 - acc: 0.0000e+00 - val_loss: 5.5305 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.1017 - acc: 0.0000e+00 - val_loss: 5.5280 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.0976 - acc: 0.0000e+00 - val_loss: 5.5239 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0942 - acc: 0.0000e+00 - val_loss: 5.5214 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0912 - acc: 0.0000e+00 - val_loss: 5.5176 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.0885 - acc: 0.0000e+00 - val_loss: 5.5172 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0860 - acc: 0.0000e+00 - val_loss: 5.5146 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.0838 - acc: 0.0000e+00 - val_loss: 5.5116 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.0819 - acc: 0.0000e+00 - val_loss: 5.5109 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0801 - acc: 0.0000e+00 - val_loss: 5.5096 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0785 - acc: 0.0000e+00 - val_loss: 5.5068 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.0770 - acc: 0.0000e+00 - val_loss: 5.5045 - val_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.0756 - acc: 0.0000e+00 - val_loss: 5.5043 - val_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0742 - acc: 0.0000e+00 - val_loss: 5.5030 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0730 - acc: 0.0000e+00 - val_loss: 5.5024 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.0717 - acc: 0.0000e+00 - val_loss: 5.5008 - val_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.0705 - acc: 0.0000e+00 - val_loss: 5.4993 - val_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 4.0694 - acc: 0.0000e+00 - val_loss: 5.4984 - val_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.0683 - acc: 0.0000e+00 - val_loss: 5.4966 - val_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0671 - acc: 0.0000e+00 - val_loss: 5.4964 - val_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0660 - acc: 0.0000e+00 - val_loss: 5.4941 - val_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0649 - acc: 0.0000e+00 - val_loss: 5.4941 - val_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0638 - acc: 0.0000e+00 - val_loss: 5.4920 - val_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0627 - acc: 0.0000e+00 - val_loss: 5.4921 - val_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0616 - acc: 0.0000e+00 - val_loss: 5.4906 - val_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0604 - acc: 0.0000e+00 - val_loss: 5.4883 - val_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0593 - acc: 0.0000e+00 - val_loss: 5.4868 - val_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0581 - acc: 0.0000e+00 - val_loss: 5.4860 - val_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0569 - acc: 0.0000e+00 - val_loss: 5.4844 - val_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0558 - acc: 0.0000e+00 - val_loss: 5.4831 - val_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0545 - acc: 0.0000e+00 - val_loss: 5.4830 - val_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 4.0533 - acc: 0.0000e+00 - val_loss: 5.4806 - val_acc: 0.0000e+00\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 50, dense_activation = relu, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 5.0438 - acc: 0.0000e+00 - val_loss: 6.7399 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.8758 - acc: 0.0000e+00 - val_loss: 6.6182 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.8327 - acc: 0.0000e+00 - val_loss: 6.5552 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 4.7446 - acc: 0.0000e+00 - val_loss: 6.3844 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.6914 - acc: 0.0000e+00 - val_loss: 6.3373 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.6740 - acc: 0.0000e+00 - val_loss: 6.3199 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.6674 - acc: 0.0000e+00 - val_loss: 6.3093 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.6628 - acc: 0.0000e+00 - val_loss: 6.3019 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.6594 - acc: 0.0000e+00 - val_loss: 6.2950 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.6567 - acc: 0.0000e+00 - val_loss: 6.2899 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.6543 - acc: 0.0000e+00 - val_loss: 6.2850 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.6523 - acc: 0.0000e+00 - val_loss: 6.2813 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.6499 - acc: 0.0000e+00 - val_loss: 6.2721 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.6151 - acc: 0.0000e+00 - val_loss: 6.0988 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.5268 - acc: 0.0000e+00 - val_loss: 6.0740 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.5180 - acc: 0.0000e+00 - val_loss: 6.0616 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.5145 - acc: 0.0000e+00 - val_loss: 6.0570 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.5128 - acc: 0.0000e+00 - val_loss: 6.0544 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.5114 - acc: 0.0000e+00 - val_loss: 6.0509 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.5100 - acc: 0.0000e+00 - val_loss: 6.0482 - val_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.5087 - acc: 0.0000e+00 - val_loss: 6.0462 - val_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.5076 - acc: 0.0000e+00 - val_loss: 6.0440 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.5065 - acc: 0.0000e+00 - val_loss: 6.0422 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.5054 - acc: 0.0000e+00 - val_loss: 6.0401 - val_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.5044 - acc: 0.0000e+00 - val_loss: 6.0386 - val_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.5021 - acc: 0.0000e+00 - val_loss: 6.0327 - val_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.4995 - acc: 0.0000e+00 - val_loss: 6.0313 - val_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.4985 - acc: 0.0000e+00 - val_loss: 6.0300 - val_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.4976 - acc: 0.0000e+00 - val_loss: 6.0275 - val_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 4.4966 - acc: 0.0000e+00 - val_loss: 6.0257 - val_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.4957 - acc: 0.0000e+00 - val_loss: 6.0251 - val_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.4948 - acc: 0.0000e+00 - val_loss: 6.0233 - val_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.4939 - acc: 0.0000e+00 - val_loss: 6.0215 - val_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.4930 - acc: 0.0000e+00 - val_loss: 6.0205 - val_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.4922 - acc: 0.0000e+00 - val_loss: 6.0191 - val_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.4913 - acc: 0.0000e+00 - val_loss: 6.0186 - val_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.4905 - acc: 0.0000e+00 - val_loss: 6.0178 - val_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.4896 - acc: 0.0000e+00 - val_loss: 6.0145 - val_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.4481 - acc: 0.0000e+00 - val_loss: 5.8135 - val_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.3588 - acc: 0.0000e+00 - val_loss: 5.8006 - val_acc: 0.0000e+00\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 50, dense_activation = relu, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 3s 18ms/step - loss: 4.2140 - acc: 0.0000e+00 - val_loss: 5.3839 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 4.0506 - acc: 0.0000e+00 - val_loss: 5.1311 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.9435 - acc: 0.0000e+00 - val_loss: 5.1179 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.9362 - acc: 0.0000e+00 - val_loss: 5.1096 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.9311 - acc: 0.0000e+00 - val_loss: 5.0953 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.9268 - acc: 0.0000e+00 - val_loss: 5.0929 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.9231 - acc: 0.0000e+00 - val_loss: 5.0856 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.9197 - acc: 0.0000e+00 - val_loss: 5.0858 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.9162 - acc: 0.0000e+00 - val_loss: 5.0816 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.9129 - acc: 0.0000e+00 - val_loss: 5.0773 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.9097 - acc: 0.0000e+00 - val_loss: 5.0736 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.9066 - acc: 0.0000e+00 - val_loss: 5.0665 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.9035 - acc: 0.0000e+00 - val_loss: 5.0686 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.9006 - acc: 0.0000e+00 - val_loss: 5.0606 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.8975 - acc: 0.0000e+00 - val_loss: 5.0588 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.8944 - acc: 0.0000e+00 - val_loss: 5.0499 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.8910 - acc: 0.0000e+00 - val_loss: 5.0528 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.8877 - acc: 0.0000e+00 - val_loss: 5.0446 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.8842 - acc: 0.0000e+00 - val_loss: 5.0427 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.7543 - acc: 0.0000e+00 - val_loss: 4.8096 - val_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.7364 - acc: 0.0000e+00 - val_loss: 4.8090 - val_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.7322 - acc: 0.0000e+00 - val_loss: 4.8007 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.7278 - acc: 0.0000e+00 - val_loss: 4.7989 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.7235 - acc: 0.0000e+00 - val_loss: 4.7973 - val_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.7189 - acc: 0.0000e+00 - val_loss: 4.7894 - val_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.7142 - acc: 0.0000e+00 - val_loss: 4.7821 - val_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.7094 - acc: 0.0000e+00 - val_loss: 4.7765 - val_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.7044 - acc: 0.0000e+00 - val_loss: 4.7709 - val_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.6993 - acc: 0.0000e+00 - val_loss: 4.7690 - val_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.6941 - acc: 0.0000e+00 - val_loss: 4.7653 - val_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.6887 - acc: 0.0000e+00 - val_loss: 4.7550 - val_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.6834 - acc: 0.0000e+00 - val_loss: 4.7563 - val_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.6778 - acc: 0.0000e+00 - val_loss: 4.7467 - val_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.6725 - acc: 0.0000e+00 - val_loss: 4.7434 - val_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.6667 - acc: 0.0000e+00 - val_loss: 4.7304 - val_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.6613 - acc: 0.0000e+00 - val_loss: 4.7288 - val_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.6557 - acc: 0.0000e+00 - val_loss: 4.7245 - val_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.6504 - acc: 0.0000e+00 - val_loss: 4.7157 - val_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.6449 - acc: 0.0000e+00 - val_loss: 4.7118 - val_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.6398 - acc: 0.0000e+00 - val_loss: 4.7183 - val_acc: 0.0000e+00\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 50, dense_activation = relu, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 4.5919 - acc: 0.0000e+00 - val_loss: 5.7752 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1243 - acc: 0.0000e+00 - val_loss: 5.0805 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.8289 - acc: 0.0000e+00 - val_loss: 4.9330 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7145 - acc: 0.0000e+00 - val_loss: 4.8959 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6972 - acc: 0.0000e+00 - val_loss: 4.8838 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6892 - acc: 0.0000e+00 - val_loss: 4.8730 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6833 - acc: 0.0000e+00 - val_loss: 4.8674 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6787 - acc: 0.0000e+00 - val_loss: 4.8583 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6750 - acc: 0.0000e+00 - val_loss: 4.8549 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6716 - acc: 0.0000e+00 - val_loss: 4.8484 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6678 - acc: 0.0000e+00 - val_loss: 4.8419 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6654 - acc: 0.0000e+00 - val_loss: 4.8387 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6634 - acc: 0.0000e+00 - val_loss: 4.8347 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6615 - acc: 0.0000e+00 - val_loss: 4.8304 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.6598 - acc: 0.0000e+00 - val_loss: 4.8297 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6582 - acc: 0.0000e+00 - val_loss: 4.8274 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6567 - acc: 0.0000e+00 - val_loss: 4.8252 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6552 - acc: 0.0000e+00 - val_loss: 4.8230 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6539 - acc: 0.0000e+00 - val_loss: 4.8210 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6525 - acc: 0.0000e+00 - val_loss: 4.8194 - val_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6511 - acc: 0.0000e+00 - val_loss: 4.8184 - val_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6498 - acc: 0.0000e+00 - val_loss: 4.8146 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6486 - acc: 0.0000e+00 - val_loss: 4.8143 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6473 - acc: 0.0000e+00 - val_loss: 4.8119 - val_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6460 - acc: 0.0000e+00 - val_loss: 4.8106 - val_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6446 - acc: 0.0000e+00 - val_loss: 4.8108 - val_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.6434 - acc: 0.0000e+00 - val_loss: 4.8088 - val_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.6421 - acc: 0.0000e+00 - val_loss: 4.8089 - val_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6409 - acc: 0.0000e+00 - val_loss: 4.8046 - val_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6396 - acc: 0.0000e+00 - val_loss: 4.8042 - val_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6383 - acc: 0.0000e+00 - val_loss: 4.8026 - val_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6371 - acc: 0.0000e+00 - val_loss: 4.8028 - val_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6358 - acc: 0.0000e+00 - val_loss: 4.7985 - val_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6345 - acc: 0.0000e+00 - val_loss: 4.8001 - val_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6332 - acc: 0.0000e+00 - val_loss: 4.7956 - val_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6319 - acc: 0.0000e+00 - val_loss: 4.7977 - val_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.6306 - acc: 0.0000e+00 - val_loss: 4.7956 - val_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.6293 - acc: 0.0000e+00 - val_loss: 4.7918 - val_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.6280 - acc: 0.0000e+00 - val_loss: 4.7898 - val_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.6267 - acc: 0.0000e+00 - val_loss: 4.7886 - val_acc: 0.0000e+00\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 50, dense_activation = relu, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "122/122 [==============================] - 2s 14ms/step - loss: 4.2946 - acc: 0.0000e+00 - val_loss: 5.9090 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.9726 - acc: 0.0000e+00 - val_loss: 5.8629 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.9560 - acc: 0.0000e+00 - val_loss: 5.8390 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.9481 - acc: 0.0000e+00 - val_loss: 5.8304 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 3.9426 - acc: 0.0000e+00 - val_loss: 5.8210 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.9383 - acc: 0.0000e+00 - val_loss: 5.8128 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.9340 - acc: 0.0000e+00 - val_loss: 5.8146 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.8842 - acc: 0.0000e+00 - val_loss: 5.5824 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.7883 - acc: 0.0000e+00 - val_loss: 5.5677 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.7844 - acc: 0.0000e+00 - val_loss: 5.5780 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.7807 - acc: 0.0000e+00 - val_loss: 5.5738 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.7770 - acc: 0.0000e+00 - val_loss: 5.5629 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.7732 - acc: 0.0000e+00 - val_loss: 5.5586 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.7696 - acc: 0.0000e+00 - val_loss: 5.5500 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.6973 - acc: 0.0000e+00 - val_loss: 5.3172 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.6236 - acc: 0.0000e+00 - val_loss: 5.3165 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.6194 - acc: 0.0000e+00 - val_loss: 5.3108 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.6151 - acc: 0.0000e+00 - val_loss: 5.3047 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.6109 - acc: 0.0000e+00 - val_loss: 5.3047 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.6063 - acc: 0.0000e+00 - val_loss: 5.3028 - val_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.6017 - acc: 0.0000e+00 - val_loss: 5.2917 - val_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.5340 - acc: 0.0000e+00 - val_loss: 5.0560 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.4496 - acc: 0.0000e+00 - val_loss: 5.0491 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.4436 - acc: 0.0000e+00 - val_loss: 5.0445 - val_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.4376 - acc: 0.0000e+00 - val_loss: 5.0474 - val_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.4314 - acc: 0.0000e+00 - val_loss: 5.0366 - val_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.4247 - acc: 0.0000e+00 - val_loss: 5.0149 - val_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.4180 - acc: 0.0000e+00 - val_loss: 5.0227 - val_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.4110 - acc: 0.0000e+00 - val_loss: 5.0064 - val_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.4040 - acc: 0.0000e+00 - val_loss: 5.0049 - val_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.3966 - acc: 0.0000e+00 - val_loss: 5.0076 - val_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.3340 - acc: 0.0000e+00 - val_loss: 4.7578 - val_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.2431 - acc: 0.0000e+00 - val_loss: 4.7537 - val_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2349 - acc: 0.0000e+00 - val_loss: 4.7587 - val_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2271 - acc: 0.0000e+00 - val_loss: 4.7369 - val_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2193 - acc: 0.0000e+00 - val_loss: 4.7287 - val_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2118 - acc: 0.0000e+00 - val_loss: 4.7289 - val_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.2047 - acc: 0.0000e+00 - val_loss: 4.7162 - val_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 3.1971 - acc: 0.0000e+00 - val_loss: 4.7319 - val_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "122/122 [==============================] - 2s 12ms/step - loss: 3.1907 - acc: 0.0000e+00 - val_loss: 4.7090 - val_acc: 0.0000e+00\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 50, dense_activation = relu, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 2s 23ms/step - loss: 4.9800 - acc: 0.0000e+00 - val_loss: 6.0673 - val_acc: 0.0000e+00\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.3143 - acc: 0.0000e+00 - val_loss: 5.9418 - val_acc: 0.0000e+00\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 4.1331 - acc: 0.0000e+00 - val_loss: 5.5445 - val_acc: 0.0000e+00\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.9698 - acc: 0.0000e+00 - val_loss: 5.4938 - val_acc: 0.0000e+00\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.9577 - acc: 0.0000e+00 - val_loss: 5.4801 - val_acc: 0.0000e+00\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.9501 - acc: 0.0000e+00 - val_loss: 5.4774 - val_acc: 0.0000e+00\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.9449 - acc: 0.0000e+00 - val_loss: 5.4716 - val_acc: 0.0000e+00\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.9373 - acc: 0.0000e+00 - val_loss: 5.4577 - val_acc: 0.0000e+00\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.9338 - acc: 0.0000e+00 - val_loss: 5.4609 - val_acc: 0.0000e+00\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.9311 - acc: 0.0000e+00 - val_loss: 5.4548 - val_acc: 0.0000e+00\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.9287 - acc: 0.0000e+00 - val_loss: 5.4548 - val_acc: 0.0000e+00\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.9265 - acc: 0.0000e+00 - val_loss: 5.4444 - val_acc: 0.0000e+00\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.9242 - acc: 0.0000e+00 - val_loss: 5.4478 - val_acc: 0.0000e+00\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.9221 - acc: 0.0000e+00 - val_loss: 5.4478 - val_acc: 0.0000e+00\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.9200 - acc: 0.0000e+00 - val_loss: 5.4409 - val_acc: 0.0000e+00\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.8256 - acc: 0.0000e+00 - val_loss: 5.2175 - val_acc: 0.0000e+00\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7789 - acc: 0.0000e+00 - val_loss: 5.2095 - val_acc: 0.0000e+00\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7765 - acc: 0.0000e+00 - val_loss: 5.2105 - val_acc: 0.0000e+00\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7742 - acc: 0.0000e+00 - val_loss: 5.2060 - val_acc: 0.0000e+00\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7720 - acc: 0.0000e+00 - val_loss: 5.2026 - val_acc: 0.0000e+00\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7698 - acc: 0.0000e+00 - val_loss: 5.2029 - val_acc: 0.0000e+00\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7676 - acc: 0.0000e+00 - val_loss: 5.2023 - val_acc: 0.0000e+00\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7655 - acc: 0.0000e+00 - val_loss: 5.2010 - val_acc: 0.0000e+00\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7634 - acc: 0.0000e+00 - val_loss: 5.1957 - val_acc: 0.0000e+00\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7610 - acc: 0.0000e+00 - val_loss: 5.1924 - val_acc: 0.0000e+00\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7589 - acc: 0.0000e+00 - val_loss: 5.1848 - val_acc: 0.0000e+00\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7568 - acc: 0.0000e+00 - val_loss: 5.1903 - val_acc: 0.0000e+00\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7545 - acc: 0.0000e+00 - val_loss: 5.1855 - val_acc: 0.0000e+00\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7521 - acc: 0.0000e+00 - val_loss: 5.1836 - val_acc: 0.0000e+00\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7499 - acc: 0.0000e+00 - val_loss: 5.1781 - val_acc: 0.0000e+00\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7476 - acc: 0.0000e+00 - val_loss: 5.1754 - val_acc: 0.0000e+00\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7450 - acc: 0.0000e+00 - val_loss: 5.1773 - val_acc: 0.0000e+00\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 3.7426 - acc: 0.0000e+00 - val_loss: 5.1734 - val_acc: 0.0000e+00\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7401 - acc: 0.0000e+00 - val_loss: 5.1660 - val_acc: 0.0000e+00\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7376 - acc: 0.0000e+00 - val_loss: 5.1651 - val_acc: 0.0000e+00\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7350 - acc: 0.0000e+00 - val_loss: 5.1598 - val_acc: 0.0000e+00\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7322 - acc: 0.0000e+00 - val_loss: 5.1637 - val_acc: 0.0000e+00\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7296 - acc: 0.0000e+00 - val_loss: 5.1595 - val_acc: 0.0000e+00\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7267 - acc: 0.0000e+00 - val_loss: 5.1569 - val_acc: 0.0000e+00\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 3.7238 - acc: 0.0000e+00 - val_loss: 5.1492 - val_acc: 0.0000e+00\n",
            "With filter = 128, kernel_size = 16, layer_activation = sigmoid, dense_layer = 50, dense_activation = relu, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n",
            "Epoch 1/40\n"
          ]
        }
      ],
      "source": [
        "# Hyper parameter tunng ~ 3 hrs\n",
        "# Neural Network architecture\n",
        "#lr = 5e-5\n",
        "#optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "# Class weights\n",
        "class_weights = { # Newly added \n",
        "    0: 2.45, # Class 0 has the fewest samples, so we weight it higher\n",
        "    1: 0.63   # Class 1 has the most samples, so we weight it lower}\n",
        "}\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "\n",
        "ls = []\n",
        "cnn_result_dict = {}\n",
        "cnn_iteration_dict = {}\n",
        "best_valid_acc = float()\n",
        "best_valid_loss = float()\n",
        "iteration = 1\n",
        "\n",
        "for filter in (16,64, 128):\n",
        "  for kernel_size in (8,16):\n",
        "    for layer_activation in ('relu','sigmoid'):  \n",
        "      for dense_layer in (1,10, 50):\n",
        "        for dense_activation in ('relu','sigmoid'):\n",
        "          for lr in (1e-5,3e-5,5e-5):\n",
        "            for batch in (64, 128):\n",
        "              try:\n",
        "                cnn_model = Sequential()\n",
        "                embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "                cnn_model.add(embedding_layer)\n",
        "                cnn_model.add(Conv1D(filter, kernel_size, activation=layer_activation))\n",
        "                cnn_model.add(GlobalMaxPooling1D())\n",
        "                cnn_model.add(Dense(dense_layer, activation=dense_activation))\n",
        "                cnn_model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['acc'])\n",
        "                cnn_model_history = cnn_model.fit(X_train, y_train, batch_size=batch, epochs=40, verbose=1, validation_split=0.2,class_weight=class_weights, callbacks=[early_stop])\n",
        "                for acc,loss in zip(cnn_model_history.history['val_acc'],cnn_model_history.history['val_loss']):\n",
        "                  if acc > best_valid_acc or loss < best_valid_loss:\n",
        "                    best_valid_acc = acc\n",
        "                    best_valid_loss = loss\n",
        "                cnn_result_dict[iteration] = {'filter': filter, 'kernel_size': kernel_size, 'layer_activation': layer_activation, 'dense_layer': dense_layer, 'dense_activation': dense_activation, 'lr': lr, 'batch_size': batch, 'Validation_acc': best_valid_acc, 'Validation_lss': best_valid_loss} \n",
        "                print(f\"With filter = {filter}, kernel_size = {kernel_size}, layer_activation = {layer_activation}, dense_layer = {dense_layer}, dense_activation = {dense_activation}, lr = {lr}, batch_size = {batch} done!!!\")\n",
        "                keras.backend.clear_session()\n",
        "                iteration += 1\n",
        "              except:\n",
        "                continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RA0Ho9M0WKW"
      },
      "outputs": [],
      "source": [
        "#Create json file and move to drive\n",
        "import json\n",
        "\n",
        "file_path = \"cnn_result_dict.json\"\n",
        "\n",
        "with open(file_path, \"w\") as json_file:\n",
        "    json.dump(cnn_result_dict, json_file)\n",
        "\n",
        "!cp '/content/cnn_result_dict.json' '/content/drive/MyDrive/cnn_result_dict.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6sJLtPp2EUn",
        "outputId": "3a160d5a-094b-4686-9ab1-c6f40a604191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.4631253182888031, 'Validation_lss': 3.281038284301758}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.4631253182888031, 'Validation_lss': 3.281038284301758}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.6328004002571106, 'Validation_lss': 1.6841351985931396}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.4775657653808594, 'Validation_lss': 1.9736348390579224}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.615781307220459, 'Validation_lss': 0.8327248692512512}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.6219701170921326, 'Validation_lss': 1.2392511367797852}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.7534811496734619, 'Validation_lss': 0.56940758228302}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.7534811496734619, 'Validation_lss': 0.56940758228302}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.8550799489021301, 'Validation_lss': 0.37817713618278503}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.8550799489021301, 'Validation_lss': 0.37817713618278503}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.8932439684867859, 'Validation_lss': 0.3020108938217163}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9133573770523071, 'Validation_lss': 0.2892255187034607}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9133573770523071, 'Validation_lss': 0.2892255187034607}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 16, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9190304279327393, 'Validation_lss': 0.25183066725730896}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9453326463699341, 'Validation_lss': 0.19259104132652283}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9463641047477722, 'Validation_lss': 0.21610647439956665}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9463641047477722, 'Validation_lss': 0.21610647439956665}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 64, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.952552855014801, 'Validation_lss': 0.16272665560245514}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 8, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9551315307617188, 'Validation_lss': 0.1517765372991562}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'relu', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 1, 'dense_activation': 'sigmoid', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 10, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 1e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 3e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 64, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n",
            "{'filter': 128, 'kernel_size': 16, 'layer_activation': 'sigmoid', 'dense_layer': 50, 'dense_activation': 'relu', 'lr': 5e-05, 'batch_size': 128, 'Validation_acc': 0.9556472301483154, 'Validation_lss': 0.13493070006370544}\n"
          ]
        }
      ],
      "source": [
        "for k,v in cnn_result_dict.items():\n",
        "  print(v)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAo4BZM-meou"
      },
      "outputs": [],
      "source": [
        "lr = 5e-5\n",
        "optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "# Class weights\n",
        "class_weights = {   \n",
        "    0: 2.45, # Class 0 has the fewest samples, so we weight it higher\n",
        "    1: 0.63   # Class 1 has the most samples, so we weight it lower}\n",
        "}\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGqxwMvGQfcT"
      },
      "outputs": [],
      "source": [
        "# Neural Network architecture\n",
        "\n",
        "cnn_model = Sequential()\n",
        "\n",
        "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "cnn_model.add(embedding_layer)\n",
        "\n",
        "cnn_model.add(Conv1D(128, 5, activation='relu'))\n",
        "cnn_model.add(GlobalMaxPooling1D())\n",
        "cnn_model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13dPDEfxQg2A",
        "outputId": "450f0714-4067-42ac-8bfa-ce3addd95668"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 100)          928100    \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 992,357\n",
            "Trainable params: 64,257\n",
            "Non-trainable params: 928,100\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Model compiling\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(cnn_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oao7K2xAQiVA",
        "outputId": "47e8a3a7-7543-492a-f2bd-c4f8952836b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "61/61 [==============================] - 6s 82ms/step - loss: 0.4880 - acc: 0.7542 - val_loss: 0.3830 - val_acc: 0.8350\n",
            "Epoch 2/50\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.2997 - acc: 0.8852 - val_loss: 0.2896 - val_acc: 0.8871\n",
            "Epoch 3/50\n",
            "61/61 [==============================] - 4s 72ms/step - loss: 0.2170 - acc: 0.9297 - val_loss: 0.2110 - val_acc: 0.9324\n",
            "Epoch 4/50\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.1637 - acc: 0.9572 - val_loss: 0.1605 - val_acc: 0.9556\n",
            "Epoch 5/50\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.1280 - acc: 0.9697 - val_loss: 0.1721 - val_acc: 0.9438\n",
            "Epoch 6/50\n",
            "61/61 [==============================] - 4s 74ms/step - loss: 0.0977 - acc: 0.9819 - val_loss: 0.1693 - val_acc: 0.9495\n",
            "Epoch 7/50\n",
            "61/61 [==============================] - 6s 92ms/step - loss: 0.0768 - acc: 0.9870 - val_loss: 0.1343 - val_acc: 0.9587\n",
            "Epoch 8/50\n",
            "61/61 [==============================] - 4s 72ms/step - loss: 0.0622 - acc: 0.9908 - val_loss: 0.1307 - val_acc: 0.9613\n",
            "Epoch 9/50\n",
            "61/61 [==============================] - 4s 72ms/step - loss: 0.0506 - acc: 0.9933 - val_loss: 0.1217 - val_acc: 0.9613\n",
            "Epoch 10/50\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.0417 - acc: 0.9947 - val_loss: 0.1233 - val_acc: 0.9593\n",
            "Epoch 11/50\n",
            "61/61 [==============================] - 4s 72ms/step - loss: 0.0349 - acc: 0.9964 - val_loss: 0.1174 - val_acc: 0.9603\n",
            "Epoch 12/50\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.0303 - acc: 0.9974 - val_loss: 0.1162 - val_acc: 0.9598\n",
            "Epoch 13/50\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.0266 - acc: 0.9974 - val_loss: 0.1154 - val_acc: 0.9613\n",
            "Epoch 14/50\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.0229 - acc: 0.9982 - val_loss: 0.1142 - val_acc: 0.9618\n",
            "Epoch 15/50\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.0201 - acc: 0.9986 - val_loss: 0.1154 - val_acc: 0.9629\n",
            "Epoch 16/50\n",
            "61/61 [==============================] - 5s 76ms/step - loss: 0.0181 - acc: 0.9986 - val_loss: 0.1143 - val_acc: 0.9613\n",
            "Epoch 17/50\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.0168 - acc: 0.9986 - val_loss: 0.1162 - val_acc: 0.9608\n",
            "Epoch 18/50\n",
            "61/61 [==============================] - 6s 101ms/step - loss: 0.0152 - acc: 0.9986 - val_loss: 0.1157 - val_acc: 0.9613\n",
            "Epoch 19/50\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.0142 - acc: 0.9986 - val_loss: 0.1192 - val_acc: 0.9613\n",
            "Epoch 19: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Model training\n",
        "\n",
        "cnn_model_history = cnn_model.fit(X_train, y_train, batch_size=128, epochs=50, verbose=1, validation_split=0.2,class_weight=class_weights, callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hPVjTdqQkRm",
        "outputId": "8a779c04-eb4c-48c2-cd09-c13a47195f45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "76/76 [==============================] - 1s 8ms/step - loss: 0.0918 - acc: 0.9699\n"
          ]
        }
      ],
      "source": [
        "# Predictions on the Test Set\n",
        "\n",
        "score = cnn_model.evaluate(X_test, y_test, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttdjsyxNRavh",
        "outputId": "7092eb45-6b7d-4141-81e3-479dee565e17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Score: 0.0917508453130722\n",
            "Test Accuracy: 0.9698845148086548\n"
          ]
        }
      ],
      "source": [
        "# Model Performance\n",
        "\n",
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcaGg7xXMr3x",
        "outputId": "2ca794f6-382a-473b-f42b-dec84c235976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "76/76 [==============================] - 1s 12ms/step\n"
          ]
        }
      ],
      "source": [
        "Y_pred_prob = cnn_model.predict(X_test)\n",
        "\n",
        "y_pred = (Y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "C_M = confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "x--D5cjeenkf",
        "outputId": "7b7e23e5-9db5-471d-c8e9-2e268429117e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "76/76 [==============================] - 1s 14ms/step\n",
            "test_accuracy: 0.972\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Y_pred_prob = cnn_model.predict(X_test)\n",
        "\n",
        "y_pred = (Y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "C_M = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Define labels\n",
        "labels = {0: \"Negative\", 1: \"Positive\"}\n",
        "\n",
        "# Plot confusion matrix\n",
        "sns.set(font_scale=1.5)\n",
        "ax = sns.heatmap(C_M, annot=True, fmt=\"d\", xticklabels=labels.values(), yticklabels=labels.values())\n",
        "ax.set_title(\"Confusion Matrix Sentiments\")\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('test_accuracy: %.3f' % (acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuJQwSa3kgDt"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score,balanced_accuracy_score,confusion_matrix\n",
        "\n",
        "Accuracy_CNN = accuracy_score(y_test, y_pred)\n",
        "Balanced_accuracy_cnn = balanced_accuracy_score(y_test, y_pred)\n",
        "Precision_CNN = precision_score(y_test, y_pred,average = 'weighted')\n",
        "Recall_CNN = recall_score(y_test, y_pred,average = 'weighted')\n",
        "F1_score_CNN = f1_score(y_test, y_pred,average = 'weighted') #, average='macro'\n",
        "sensitivity_CNN = Recall_CNN\n",
        "specificity_CNN =  C_M[0][0] / (C_M[0][0] + C_M[0][1])\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRoW5xqukrVD",
        "outputId": "60559d09-d9c6-4035-edc7-57edf2ba4c8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9698844884488449\n",
            "0.9453521583901331\n",
            "0.9696152399506387\n",
            "0.9698844884488449\n",
            "0.9696748863045991\n",
            "0.9698844884488449\n",
            "0.9050632911392406\n"
          ]
        }
      ],
      "source": [
        "print(Accuracy_CNN)\n",
        "print(Balanced_accuracy_cnn)\n",
        "print(Precision_CNN)\n",
        "print(Recall_CNN)\n",
        "print(F1_score_CNN)\n",
        "print(sensitivity_CNN)\n",
        "print(specificity_CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "ZcM6cQtJReje",
        "outputId": "d88210cb-d629-46b6-bd59-6919b410840a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Model Performance Charts\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(cnn_model_history.history['acc'])\n",
        "plt.plot(cnn_model_history.history['val_acc'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(cnn_model_history.history['loss'])\n",
        "plt.plot(cnn_model_history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc = 'upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHxKNhNyNxdK"
      },
      "outputs": [],
      "source": [
        "# Saving the model as a h5 file for possible use later\n",
        "cnn_model.save(f\"./drive/MyDrive/c1_cnn_model_acc_{round(score[1], 3)}_optimizer.h5\", save_format='h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eraoiqFFVQzp"
      },
      "outputs": [],
      "source": [
        "#Loading cnn_model with best weights \n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "cnn_model = load_model('/content/drive/MyDrive/c1_cnn_model_acc_0.97.h5')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mXu4qB7sRmWG"
      },
      "source": [
        "# Recurrent Neural Network (LSTM)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quoh5fAJRgzy"
      },
      "outputs": [],
      "source": [
        "from keras.layers import LSTM\n",
        "import numpy as np\n",
        "np.random.seed(121)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tv_6aZo8EOd",
        "outputId": "7b13b063-3f3c-45f9-a7f3-ea207196f29b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 47ms/step - loss: 0.6984 - acc: 0.2729 - val_loss: 0.6872 - val_acc: 0.2733\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6980 - acc: 0.2651 - val_loss: 0.6876 - val_acc: 0.2713\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6976 - acc: 0.2620 - val_loss: 0.6880 - val_acc: 0.2641\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6972 - acc: 0.2557 - val_loss: 0.6883 - val_acc: 0.2610\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6969 - acc: 0.2545 - val_loss: 0.6886 - val_acc: 0.2635\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6966 - acc: 0.2522 - val_loss: 0.6890 - val_acc: 0.2579\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 1, dense_activation = relu, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 4s 42ms/step - loss: 0.6949 - acc: 0.6730 - val_loss: 0.7004 - val_acc: 0.7267\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6948 - acc: 0.7415 - val_loss: 0.7002 - val_acc: 0.7323\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6947 - acc: 0.7455 - val_loss: 0.6999 - val_acc: 0.7380\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.6946 - acc: 0.7474 - val_loss: 0.6997 - val_acc: 0.7385\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.6945 - acc: 0.7485 - val_loss: 0.6995 - val_acc: 0.7396\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6945 - acc: 0.7482 - val_loss: 0.6993 - val_acc: 0.7396\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6944 - acc: 0.7488 - val_loss: 0.6990 - val_acc: 0.7416\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6943 - acc: 0.7488 - val_loss: 0.6988 - val_acc: 0.7416\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.6942 - acc: 0.7496 - val_loss: 0.6987 - val_acc: 0.7416\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6942 - acc: 0.7495 - val_loss: 0.6984 - val_acc: 0.7442\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6941 - acc: 0.7488 - val_loss: 0.6983 - val_acc: 0.7432\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6940 - acc: 0.7504 - val_loss: 0.6980 - val_acc: 0.7437\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6939 - acc: 0.7500 - val_loss: 0.6979 - val_acc: 0.7437\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6938 - acc: 0.7505 - val_loss: 0.6977 - val_acc: 0.7442\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6938 - acc: 0.7506 - val_loss: 0.6975 - val_acc: 0.7442\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6937 - acc: 0.7511 - val_loss: 0.6973 - val_acc: 0.7437\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6936 - acc: 0.7510 - val_loss: 0.6972 - val_acc: 0.7432\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6935 - acc: 0.7507 - val_loss: 0.6970 - val_acc: 0.7432\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6935 - acc: 0.7509 - val_loss: 0.6969 - val_acc: 0.7427\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6934 - acc: 0.7511 - val_loss: 0.6967 - val_acc: 0.7432\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6933 - acc: 0.7510 - val_loss: 0.6965 - val_acc: 0.7432\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6932 - acc: 0.7511 - val_loss: 0.6963 - val_acc: 0.7432\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6931 - acc: 0.7511 - val_loss: 0.6962 - val_acc: 0.7421\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6931 - acc: 0.7510 - val_loss: 0.6961 - val_acc: 0.7421\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6930 - acc: 0.7510 - val_loss: 0.6959 - val_acc: 0.7421\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6929 - acc: 0.7506 - val_loss: 0.6958 - val_acc: 0.7421\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6928 - acc: 0.7504 - val_loss: 0.6957 - val_acc: 0.7416\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6927 - acc: 0.7505 - val_loss: 0.6956 - val_acc: 0.7406\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6927 - acc: 0.7505 - val_loss: 0.6955 - val_acc: 0.7416\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6926 - acc: 0.7505 - val_loss: 0.6953 - val_acc: 0.7416\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6925 - acc: 0.7502 - val_loss: 0.6952 - val_acc: 0.7416\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6924 - acc: 0.7488 - val_loss: 0.6951 - val_acc: 0.7401\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6923 - acc: 0.7489 - val_loss: 0.6949 - val_acc: 0.7401\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6923 - acc: 0.7489 - val_loss: 0.6948 - val_acc: 0.7401\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6922 - acc: 0.7488 - val_loss: 0.6946 - val_acc: 0.7406\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6921 - acc: 0.7488 - val_loss: 0.6945 - val_acc: 0.7401\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6920 - acc: 0.7479 - val_loss: 0.6944 - val_acc: 0.7406\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6919 - acc: 0.7496 - val_loss: 0.6942 - val_acc: 0.7416\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6918 - acc: 0.7497 - val_loss: 0.6941 - val_acc: 0.7411\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6918 - acc: 0.7489 - val_loss: 0.6940 - val_acc: 0.7401\n",
            "With LSTM_units = 16, dense_layer = 1, dense_activation = relu, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 4s 43ms/step - loss: 0.6968 - acc: 0.7319 - val_loss: 0.6943 - val_acc: 0.7617\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6965 - acc: 0.6882 - val_loss: 0.6949 - val_acc: 0.7602\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6961 - acc: 0.4151 - val_loss: 0.6953 - val_acc: 0.7622\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6959 - acc: 0.7616 - val_loss: 0.6957 - val_acc: 0.7581\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6956 - acc: 0.7586 - val_loss: 0.6959 - val_acc: 0.7571\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6954 - acc: 0.7572 - val_loss: 0.6961 - val_acc: 0.7535\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 1, dense_activation = relu, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 4s 41ms/step - loss: 0.6947 - acc: 0.7750 - val_loss: 0.6924 - val_acc: 0.7715\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6944 - acc: 0.7809 - val_loss: 0.6927 - val_acc: 0.7726\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6942 - acc: 0.7798 - val_loss: 0.6927 - val_acc: 0.7720\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6939 - acc: 0.7786 - val_loss: 0.6929 - val_acc: 0.7715\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6937 - acc: 0.7770 - val_loss: 0.6929 - val_acc: 0.7726\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6935 - acc: 0.7767 - val_loss: 0.6927 - val_acc: 0.7726\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 1, dense_activation = relu, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 49ms/step - loss: 0.6957 - acc: 0.7577 - val_loss: 0.6970 - val_acc: 0.7571\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6954 - acc: 0.7662 - val_loss: 0.6967 - val_acc: 0.7550\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6950 - acc: 0.7671 - val_loss: 0.6968 - val_acc: 0.7561\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6947 - acc: 0.7680 - val_loss: 0.6963 - val_acc: 0.7571\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6944 - acc: 0.7666 - val_loss: 0.6962 - val_acc: 0.7571\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6940 - acc: 0.7670 - val_loss: 0.6957 - val_acc: 0.7581\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6937 - acc: 0.7676 - val_loss: 0.6953 - val_acc: 0.7597\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6934 - acc: 0.7680 - val_loss: 0.6950 - val_acc: 0.7597\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6931 - acc: 0.7696 - val_loss: 0.6948 - val_acc: 0.7617\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6928 - acc: 0.7701 - val_loss: 0.6945 - val_acc: 0.7622\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6925 - acc: 0.7698 - val_loss: 0.6941 - val_acc: 0.7628\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6922 - acc: 0.7700 - val_loss: 0.6943 - val_acc: 0.7628\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6918 - acc: 0.7683 - val_loss: 0.6938 - val_acc: 0.7617\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6915 - acc: 0.7694 - val_loss: 0.6932 - val_acc: 0.7617\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6911 - acc: 0.7703 - val_loss: 0.6927 - val_acc: 0.7633\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6908 - acc: 0.7710 - val_loss: 0.6922 - val_acc: 0.7643\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6904 - acc: 0.7734 - val_loss: 0.6919 - val_acc: 0.7648\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6899 - acc: 0.7723 - val_loss: 0.6915 - val_acc: 0.7653\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6894 - acc: 0.7754 - val_loss: 0.6909 - val_acc: 0.7648\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6888 - acc: 0.7705 - val_loss: 0.6910 - val_acc: 0.7597\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6881 - acc: 0.7718 - val_loss: 0.6897 - val_acc: 0.7617\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6869 - acc: 0.7689 - val_loss: 0.6897 - val_acc: 0.7545\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6844 - acc: 0.7621 - val_loss: 0.6884 - val_acc: 0.7468\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6702 - acc: 0.6957 - val_loss: 0.6718 - val_acc: 0.7086\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.5972 - acc: 0.7602 - val_loss: 0.6101 - val_acc: 0.8149\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.5548 - acc: 0.8067 - val_loss: 0.5635 - val_acc: 0.8515\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.5402 - acc: 0.8232 - val_loss: 0.6314 - val_acc: 0.7829\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.5376 - acc: 0.8309 - val_loss: 0.5786 - val_acc: 0.8226\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.5271 - acc: 0.8169 - val_loss: 0.5610 - val_acc: 0.8339\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.5180 - acc: 0.8422 - val_loss: 0.5418 - val_acc: 0.8432\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.5149 - acc: 0.8246 - val_loss: 0.5351 - val_acc: 0.8453\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.5066 - acc: 0.8378 - val_loss: 0.5322 - val_acc: 0.8437\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.5055 - acc: 0.8406 - val_loss: 0.5673 - val_acc: 0.8185\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.5137 - acc: 0.8084 - val_loss: 0.5159 - val_acc: 0.8479\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.4968 - acc: 0.8446 - val_loss: 0.5085 - val_acc: 0.8530\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.5012 - acc: 0.8293 - val_loss: 0.4856 - val_acc: 0.8659\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.4925 - acc: 0.8484 - val_loss: 0.5060 - val_acc: 0.8515\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.4922 - acc: 0.8462 - val_loss: 0.5037 - val_acc: 0.8510\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.4885 - acc: 0.8503 - val_loss: 0.5143 - val_acc: 0.8386\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.4868 - acc: 0.8454 - val_loss: 0.4798 - val_acc: 0.8628\n",
            "With LSTM_units = 16, dense_layer = 1, dense_activation = relu, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 4s 41ms/step - loss: 0.6969 - acc: 0.4126 - val_loss: 0.6893 - val_acc: 0.2537\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6957 - acc: 0.2489 - val_loss: 0.6905 - val_acc: 0.2573\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6948 - acc: 0.2436 - val_loss: 0.6918 - val_acc: 0.2486\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6941 - acc: 0.2379 - val_loss: 0.6927 - val_acc: 0.2434\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.6936 - acc: 0.4357 - val_loss: 0.6931 - val_acc: 0.7545\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6932 - acc: 0.7714 - val_loss: 0.6934 - val_acc: 0.7545\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 1, dense_activation = relu, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 43ms/step - loss: 0.6959 - acc: 0.7761 - val_loss: 0.6908 - val_acc: 0.7736\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6958 - acc: 0.5299 - val_loss: 0.6910 - val_acc: 0.7695\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6956 - acc: 0.5973 - val_loss: 0.6912 - val_acc: 0.7690\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6955 - acc: 0.3678 - val_loss: 0.6914 - val_acc: 0.2821\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6954 - acc: 0.7446 - val_loss: 0.6915 - val_acc: 0.7648\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6952 - acc: 0.7734 - val_loss: 0.6917 - val_acc: 0.7664\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 1, dense_activation = sigmoid, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 4s 42ms/step - loss: 0.7082 - acc: 0.2896 - val_loss: 0.6835 - val_acc: 0.2496\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.7073 - acc: 0.2449 - val_loss: 0.6839 - val_acc: 0.2506\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.7064 - acc: 0.2437 - val_loss: 0.6842 - val_acc: 0.2517\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.7056 - acc: 0.2438 - val_loss: 0.6845 - val_acc: 0.2491\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.7048 - acc: 0.2435 - val_loss: 0.6848 - val_acc: 0.2491\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.7041 - acc: 0.2428 - val_loss: 0.6852 - val_acc: 0.2491\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 1, dense_activation = sigmoid, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 4s 43ms/step - loss: 0.6960 - acc: 0.7556 - val_loss: 0.6989 - val_acc: 0.7494\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.6957 - acc: 0.7563 - val_loss: 0.6984 - val_acc: 0.7499\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.6954 - acc: 0.7555 - val_loss: 0.6979 - val_acc: 0.7488\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6952 - acc: 0.7538 - val_loss: 0.6976 - val_acc: 0.7499\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6949 - acc: 0.7542 - val_loss: 0.6971 - val_acc: 0.7499\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6947 - acc: 0.7544 - val_loss: 0.6970 - val_acc: 0.7478\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6945 - acc: 0.7541 - val_loss: 0.6965 - val_acc: 0.7463\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6943 - acc: 0.7540 - val_loss: 0.6960 - val_acc: 0.7468\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6940 - acc: 0.7542 - val_loss: 0.6957 - val_acc: 0.7452\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6939 - acc: 0.7541 - val_loss: 0.6955 - val_acc: 0.7432\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6937 - acc: 0.7538 - val_loss: 0.6952 - val_acc: 0.7421\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6935 - acc: 0.7532 - val_loss: 0.6950 - val_acc: 0.7427\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6933 - acc: 0.7536 - val_loss: 0.6949 - val_acc: 0.7432\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6931 - acc: 0.7534 - val_loss: 0.6944 - val_acc: 0.7437\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6929 - acc: 0.7533 - val_loss: 0.6942 - val_acc: 0.7416\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6927 - acc: 0.7529 - val_loss: 0.6940 - val_acc: 0.7406\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6925 - acc: 0.7534 - val_loss: 0.6936 - val_acc: 0.7385\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6923 - acc: 0.7525 - val_loss: 0.6934 - val_acc: 0.7396\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6921 - acc: 0.7528 - val_loss: 0.6931 - val_acc: 0.7390\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6919 - acc: 0.7509 - val_loss: 0.6929 - val_acc: 0.7375\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6917 - acc: 0.7513 - val_loss: 0.6925 - val_acc: 0.7380\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6915 - acc: 0.7510 - val_loss: 0.6922 - val_acc: 0.7354\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6912 - acc: 0.7484 - val_loss: 0.6918 - val_acc: 0.7334\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6910 - acc: 0.7456 - val_loss: 0.6916 - val_acc: 0.7298\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6907 - acc: 0.7446 - val_loss: 0.6913 - val_acc: 0.7282\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6904 - acc: 0.7438 - val_loss: 0.6908 - val_acc: 0.7313\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6900 - acc: 0.7433 - val_loss: 0.6901 - val_acc: 0.7329\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6896 - acc: 0.7403 - val_loss: 0.6896 - val_acc: 0.7256\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.6890 - acc: 0.7387 - val_loss: 0.6886 - val_acc: 0.7261\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 2s 33ms/step - loss: 0.6883 - acc: 0.7309 - val_loss: 0.6880 - val_acc: 0.7215\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6873 - acc: 0.7259 - val_loss: 0.6867 - val_acc: 0.7117\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6857 - acc: 0.7158 - val_loss: 0.6864 - val_acc: 0.6890\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6833 - acc: 0.6870 - val_loss: 0.6876 - val_acc: 0.6514\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6801 - acc: 0.6306 - val_loss: 0.6898 - val_acc: 0.5988\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6766 - acc: 0.6023 - val_loss: 0.6895 - val_acc: 0.5730\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6727 - acc: 0.5785 - val_loss: 0.6853 - val_acc: 0.5709\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6665 - acc: 0.5525 - val_loss: 0.6713 - val_acc: 0.5952\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6469 - acc: 0.6214 - val_loss: 0.6393 - val_acc: 0.6674\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6138 - acc: 0.6859 - val_loss: 0.6063 - val_acc: 0.7463\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.5923 - acc: 0.7184 - val_loss: 0.6198 - val_acc: 0.7205\n",
            "With LSTM_units = 16, dense_layer = 1, dense_activation = sigmoid, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 45ms/step - loss: 0.6951 - acc: 0.6108 - val_loss: 0.7014 - val_acc: 0.7488\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6948 - acc: 0.7506 - val_loss: 0.7004 - val_acc: 0.7514\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6945 - acc: 0.7523 - val_loss: 0.6995 - val_acc: 0.7530\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6943 - acc: 0.7519 - val_loss: 0.6986 - val_acc: 0.7524\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6940 - acc: 0.7534 - val_loss: 0.6980 - val_acc: 0.7540\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6938 - acc: 0.7541 - val_loss: 0.6973 - val_acc: 0.7540\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6936 - acc: 0.7549 - val_loss: 0.6966 - val_acc: 0.7545\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6933 - acc: 0.7569 - val_loss: 0.6960 - val_acc: 0.7555\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6931 - acc: 0.7573 - val_loss: 0.6957 - val_acc: 0.7555\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6929 - acc: 0.7574 - val_loss: 0.6954 - val_acc: 0.7555\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6927 - acc: 0.7590 - val_loss: 0.6949 - val_acc: 0.7561\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6925 - acc: 0.7611 - val_loss: 0.6942 - val_acc: 0.7592\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6923 - acc: 0.7611 - val_loss: 0.6940 - val_acc: 0.7592\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.6921 - acc: 0.7618 - val_loss: 0.6939 - val_acc: 0.7597\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6919 - acc: 0.7630 - val_loss: 0.6935 - val_acc: 0.7612\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6916 - acc: 0.7661 - val_loss: 0.6933 - val_acc: 0.7612\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6914 - acc: 0.7667 - val_loss: 0.6931 - val_acc: 0.7622\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6912 - acc: 0.7654 - val_loss: 0.6927 - val_acc: 0.7633\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6910 - acc: 0.7679 - val_loss: 0.6921 - val_acc: 0.7633\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6908 - acc: 0.7675 - val_loss: 0.6922 - val_acc: 0.7633\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6905 - acc: 0.7678 - val_loss: 0.6923 - val_acc: 0.7643\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6903 - acc: 0.7671 - val_loss: 0.6922 - val_acc: 0.7638\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6901 - acc: 0.7684 - val_loss: 0.6915 - val_acc: 0.7648\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6899 - acc: 0.7681 - val_loss: 0.6912 - val_acc: 0.7653\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6897 - acc: 0.7688 - val_loss: 0.6909 - val_acc: 0.7659\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6894 - acc: 0.7692 - val_loss: 0.6904 - val_acc: 0.7664\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6892 - acc: 0.7712 - val_loss: 0.6900 - val_acc: 0.7679\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6890 - acc: 0.7712 - val_loss: 0.6901 - val_acc: 0.7679\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6887 - acc: 0.7720 - val_loss: 0.6900 - val_acc: 0.7684\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6885 - acc: 0.7720 - val_loss: 0.6895 - val_acc: 0.7720\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6882 - acc: 0.7723 - val_loss: 0.6896 - val_acc: 0.7695\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6880 - acc: 0.7721 - val_loss: 0.6890 - val_acc: 0.7710\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6877 - acc: 0.7725 - val_loss: 0.6889 - val_acc: 0.7705\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6874 - acc: 0.7728 - val_loss: 0.6885 - val_acc: 0.7710\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6872 - acc: 0.7732 - val_loss: 0.6878 - val_acc: 0.7720\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6869 - acc: 0.7750 - val_loss: 0.6878 - val_acc: 0.7715\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6866 - acc: 0.7720 - val_loss: 0.6880 - val_acc: 0.7705\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6863 - acc: 0.7723 - val_loss: 0.6879 - val_acc: 0.7695\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6860 - acc: 0.7740 - val_loss: 0.6870 - val_acc: 0.7700\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6857 - acc: 0.7752 - val_loss: 0.6869 - val_acc: 0.7700\n",
            "With LSTM_units = 16, dense_layer = 1, dense_activation = sigmoid, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 46ms/step - loss: 0.6953 - acc: 0.3253 - val_loss: 0.7002 - val_acc: 0.7179\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6948 - acc: 0.7264 - val_loss: 0.6992 - val_acc: 0.7251\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6944 - acc: 0.7397 - val_loss: 0.6982 - val_acc: 0.7334\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6940 - acc: 0.7384 - val_loss: 0.6976 - val_acc: 0.7318\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6935 - acc: 0.7426 - val_loss: 0.6964 - val_acc: 0.7334\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6930 - acc: 0.7415 - val_loss: 0.6962 - val_acc: 0.7313\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6925 - acc: 0.7390 - val_loss: 0.6958 - val_acc: 0.7256\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6919 - acc: 0.7369 - val_loss: 0.6952 - val_acc: 0.7246\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6912 - acc: 0.7368 - val_loss: 0.6949 - val_acc: 0.7282\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6904 - acc: 0.7381 - val_loss: 0.6942 - val_acc: 0.7236\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6892 - acc: 0.7304 - val_loss: 0.6940 - val_acc: 0.7179\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6875 - acc: 0.7191 - val_loss: 0.6944 - val_acc: 0.7024\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6846 - acc: 0.7010 - val_loss: 0.6968 - val_acc: 0.6704\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6777 - acc: 0.6254 - val_loss: 0.7099 - val_acc: 0.5487\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6543 - acc: 0.5901 - val_loss: 0.6684 - val_acc: 0.6632\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.5896 - acc: 0.7327 - val_loss: 0.6542 - val_acc: 0.7107\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.5462 - acc: 0.7803 - val_loss: 0.5583 - val_acc: 0.8143\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.5227 - acc: 0.7994 - val_loss: 0.5663 - val_acc: 0.7927\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.5088 - acc: 0.8092 - val_loss: 0.5629 - val_acc: 0.7891\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.5043 - acc: 0.7956 - val_loss: 0.5259 - val_acc: 0.8097\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4952 - acc: 0.8099 - val_loss: 0.4994 - val_acc: 0.8293\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.4936 - acc: 0.7880 - val_loss: 0.5477 - val_acc: 0.7834\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.4819 - acc: 0.8113 - val_loss: 0.5156 - val_acc: 0.8061\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4779 - acc: 0.8039 - val_loss: 0.4793 - val_acc: 0.8308\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4706 - acc: 0.8147 - val_loss: 0.4813 - val_acc: 0.8267\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4677 - acc: 0.8204 - val_loss: 0.4793 - val_acc: 0.8257\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4673 - acc: 0.8112 - val_loss: 0.4600 - val_acc: 0.8391\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4620 - acc: 0.8237 - val_loss: 0.4662 - val_acc: 0.8319\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4569 - acc: 0.8263 - val_loss: 0.4525 - val_acc: 0.8427\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4552 - acc: 0.8284 - val_loss: 0.4507 - val_acc: 0.8422\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4535 - acc: 0.8233 - val_loss: 0.4476 - val_acc: 0.8391\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4529 - acc: 0.8280 - val_loss: 0.4646 - val_acc: 0.8267\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4479 - acc: 0.8313 - val_loss: 0.4485 - val_acc: 0.8370\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4459 - acc: 0.8299 - val_loss: 0.4598 - val_acc: 0.8293\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.4460 - acc: 0.8286 - val_loss: 0.4306 - val_acc: 0.8463\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4420 - acc: 0.8386 - val_loss: 0.4370 - val_acc: 0.8412\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4399 - acc: 0.8331 - val_loss: 0.4233 - val_acc: 0.8535\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.4410 - acc: 0.8328 - val_loss: 0.4234 - val_acc: 0.8530\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.4351 - acc: 0.8432 - val_loss: 0.4186 - val_acc: 0.8571\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4368 - acc: 0.8371 - val_loss: 0.4169 - val_acc: 0.8561\n",
            "With LSTM_units = 16, dense_layer = 1, dense_activation = sigmoid, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 45ms/step - loss: 0.6977 - acc: 0.7791 - val_loss: 0.6928 - val_acc: 0.7741\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6970 - acc: 0.7750 - val_loss: 0.6934 - val_acc: 0.7674\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6965 - acc: 0.7687 - val_loss: 0.6940 - val_acc: 0.7607\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6960 - acc: 0.3901 - val_loss: 0.6947 - val_acc: 0.7509\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6956 - acc: 0.7573 - val_loss: 0.6948 - val_acc: 0.7499\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6952 - acc: 0.7559 - val_loss: 0.6950 - val_acc: 0.7519\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 1, dense_activation = sigmoid, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 46ms/step - loss: 0.6945 - acc: 0.7461 - val_loss: 0.6984 - val_acc: 0.7401\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6944 - acc: 0.7511 - val_loss: 0.6982 - val_acc: 0.7401\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6943 - acc: 0.7515 - val_loss: 0.6980 - val_acc: 0.7411\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6943 - acc: 0.7519 - val_loss: 0.6978 - val_acc: 0.7437\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6942 - acc: 0.7518 - val_loss: 0.6976 - val_acc: 0.7437\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6942 - acc: 0.7525 - val_loss: 0.6974 - val_acc: 0.7447\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6941 - acc: 0.7524 - val_loss: 0.6973 - val_acc: 0.7447\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6940 - acc: 0.7534 - val_loss: 0.6971 - val_acc: 0.7463\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6940 - acc: 0.7540 - val_loss: 0.6969 - val_acc: 0.7478\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6939 - acc: 0.7536 - val_loss: 0.6968 - val_acc: 0.7478\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6939 - acc: 0.7531 - val_loss: 0.6966 - val_acc: 0.7494\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6938 - acc: 0.7538 - val_loss: 0.6964 - val_acc: 0.7494\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6937 - acc: 0.7538 - val_loss: 0.6963 - val_acc: 0.7494\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6937 - acc: 0.7547 - val_loss: 0.6960 - val_acc: 0.7499\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6936 - acc: 0.7549 - val_loss: 0.6960 - val_acc: 0.7499\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6936 - acc: 0.7553 - val_loss: 0.6958 - val_acc: 0.7509\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6935 - acc: 0.7546 - val_loss: 0.6958 - val_acc: 0.7509\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6935 - acc: 0.7555 - val_loss: 0.6956 - val_acc: 0.7514\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6934 - acc: 0.7569 - val_loss: 0.6955 - val_acc: 0.7514\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6934 - acc: 0.7571 - val_loss: 0.6953 - val_acc: 0.7514\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6933 - acc: 0.7576 - val_loss: 0.6952 - val_acc: 0.7514\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7576 - val_loss: 0.6951 - val_acc: 0.7524\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6932 - acc: 0.7578 - val_loss: 0.6949 - val_acc: 0.7530\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6931 - acc: 0.7583 - val_loss: 0.6947 - val_acc: 0.7530\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6931 - acc: 0.7589 - val_loss: 0.6947 - val_acc: 0.7535\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6930 - acc: 0.7586 - val_loss: 0.6946 - val_acc: 0.7535\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6930 - acc: 0.7587 - val_loss: 0.6946 - val_acc: 0.7530\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6929 - acc: 0.7587 - val_loss: 0.6944 - val_acc: 0.7535\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6929 - acc: 0.7586 - val_loss: 0.6942 - val_acc: 0.7535\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6928 - acc: 0.7586 - val_loss: 0.6942 - val_acc: 0.7535\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6928 - acc: 0.7587 - val_loss: 0.6941 - val_acc: 0.7535\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6927 - acc: 0.7590 - val_loss: 0.6940 - val_acc: 0.7540\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6926 - acc: 0.7593 - val_loss: 0.6939 - val_acc: 0.7540\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6926 - acc: 0.7593 - val_loss: 0.6938 - val_acc: 0.7545\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6925 - acc: 0.7600 - val_loss: 0.6938 - val_acc: 0.7545\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6925 - acc: 0.7603 - val_loss: 0.6936 - val_acc: 0.7555\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6924 - acc: 0.7602 - val_loss: 0.6936 - val_acc: 0.7550\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6924 - acc: 0.7602 - val_loss: 0.6935 - val_acc: 0.7550\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6923 - acc: 0.7603 - val_loss: 0.6933 - val_acc: 0.7555\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6923 - acc: 0.7603 - val_loss: 0.6933 - val_acc: 0.7550\n",
            "With LSTM_units = 16, dense_layer = 10, dense_activation = relu, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 45ms/step - loss: 0.6954 - acc: 0.6712 - val_loss: 0.6921 - val_acc: 0.7684\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6953 - acc: 0.6887 - val_loss: 0.6923 - val_acc: 0.7700\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6952 - acc: 0.7669 - val_loss: 0.6926 - val_acc: 0.7669\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6950 - acc: 0.3046 - val_loss: 0.6928 - val_acc: 0.2517\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6949 - acc: 0.5255 - val_loss: 0.6930 - val_acc: 0.7669\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6948 - acc: 0.7649 - val_loss: 0.6932 - val_acc: 0.7638\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 10, dense_activation = relu, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 6s 47ms/step - loss: 0.7025 - acc: 0.2484 - val_loss: 0.6861 - val_acc: 0.2532\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.7009 - acc: 0.2463 - val_loss: 0.6870 - val_acc: 0.2512\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6995 - acc: 0.2441 - val_loss: 0.6881 - val_acc: 0.2476\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6985 - acc: 0.2431 - val_loss: 0.6889 - val_acc: 0.2470\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6976 - acc: 0.2424 - val_loss: 0.6896 - val_acc: 0.2465\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6969 - acc: 0.2402 - val_loss: 0.6903 - val_acc: 0.2450\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 10, dense_activation = relu, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 45ms/step - loss: 0.6971 - acc: 0.2745 - val_loss: 0.6914 - val_acc: 0.2671\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6963 - acc: 0.2505 - val_loss: 0.6925 - val_acc: 0.2532\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6957 - acc: 0.2386 - val_loss: 0.6934 - val_acc: 0.2367\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6951 - acc: 0.2335 - val_loss: 0.6941 - val_acc: 0.2305\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6947 - acc: 0.2881 - val_loss: 0.6945 - val_acc: 0.7287\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6943 - acc: 0.5751 - val_loss: 0.6949 - val_acc: 0.7329\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 10, dense_activation = relu, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 46ms/step - loss: 0.6956 - acc: 0.3473 - val_loss: 0.6927 - val_acc: 0.2460\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6952 - acc: 0.7386 - val_loss: 0.6931 - val_acc: 0.7597\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6948 - acc: 0.7653 - val_loss: 0.6935 - val_acc: 0.7509\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6945 - acc: 0.6411 - val_loss: 0.6937 - val_acc: 0.7463\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6942 - acc: 0.5675 - val_loss: 0.6942 - val_acc: 0.7396\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6939 - acc: 0.7573 - val_loss: 0.6941 - val_acc: 0.7432\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 10, dense_activation = relu, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 45ms/step - loss: 0.6956 - acc: 0.7603 - val_loss: 0.6936 - val_acc: 0.7612\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6952 - acc: 0.7635 - val_loss: 0.6939 - val_acc: 0.7586\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6949 - acc: 0.7631 - val_loss: 0.6944 - val_acc: 0.7576\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6946 - acc: 0.7608 - val_loss: 0.6945 - val_acc: 0.7555\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6944 - acc: 0.7602 - val_loss: 0.6945 - val_acc: 0.7555\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6941 - acc: 0.7612 - val_loss: 0.6943 - val_acc: 0.7571\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 10, dense_activation = relu, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 6s 60ms/step - loss: 0.6957 - acc: 0.7382 - val_loss: 0.6974 - val_acc: 0.7427\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6956 - acc: 0.7522 - val_loss: 0.6972 - val_acc: 0.7437\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6955 - acc: 0.7541 - val_loss: 0.6970 - val_acc: 0.7432\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6955 - acc: 0.7556 - val_loss: 0.6968 - val_acc: 0.7494\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6954 - acc: 0.7562 - val_loss: 0.6967 - val_acc: 0.7488\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6953 - acc: 0.7560 - val_loss: 0.6965 - val_acc: 0.7509\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6952 - acc: 0.7569 - val_loss: 0.6965 - val_acc: 0.7509\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6952 - acc: 0.7578 - val_loss: 0.6962 - val_acc: 0.7524\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6951 - acc: 0.7586 - val_loss: 0.6961 - val_acc: 0.7514\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6950 - acc: 0.7589 - val_loss: 0.6960 - val_acc: 0.7524\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6950 - acc: 0.7594 - val_loss: 0.6958 - val_acc: 0.7524\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6949 - acc: 0.7595 - val_loss: 0.6957 - val_acc: 0.7535\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6948 - acc: 0.7593 - val_loss: 0.6955 - val_acc: 0.7545\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6948 - acc: 0.7589 - val_loss: 0.6954 - val_acc: 0.7555\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6947 - acc: 0.7587 - val_loss: 0.6953 - val_acc: 0.7555\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6946 - acc: 0.7598 - val_loss: 0.6951 - val_acc: 0.7555\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6946 - acc: 0.7602 - val_loss: 0.6950 - val_acc: 0.7566\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6945 - acc: 0.7599 - val_loss: 0.6949 - val_acc: 0.7566\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6944 - acc: 0.7605 - val_loss: 0.6947 - val_acc: 0.7571\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6944 - acc: 0.7607 - val_loss: 0.6946 - val_acc: 0.7581\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6943 - acc: 0.7611 - val_loss: 0.6945 - val_acc: 0.7581\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6942 - acc: 0.7612 - val_loss: 0.6943 - val_acc: 0.7581\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6942 - acc: 0.7603 - val_loss: 0.6943 - val_acc: 0.7592\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6941 - acc: 0.7603 - val_loss: 0.6942 - val_acc: 0.7597\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6940 - acc: 0.7599 - val_loss: 0.6941 - val_acc: 0.7597\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6940 - acc: 0.7603 - val_loss: 0.6940 - val_acc: 0.7597\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7605 - val_loss: 0.6938 - val_acc: 0.7597\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6938 - acc: 0.7612 - val_loss: 0.6937 - val_acc: 0.7607\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6938 - acc: 0.7612 - val_loss: 0.6937 - val_acc: 0.7607\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6937 - acc: 0.7617 - val_loss: 0.6936 - val_acc: 0.7612\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6936 - acc: 0.7617 - val_loss: 0.6934 - val_acc: 0.7607\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6936 - acc: 0.7617 - val_loss: 0.6934 - val_acc: 0.7612\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6935 - acc: 0.7618 - val_loss: 0.6933 - val_acc: 0.7628\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6934 - acc: 0.7616 - val_loss: 0.6932 - val_acc: 0.7628\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6934 - acc: 0.7618 - val_loss: 0.6931 - val_acc: 0.7628\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6933 - acc: 0.7620 - val_loss: 0.6930 - val_acc: 0.7638\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6932 - acc: 0.7609 - val_loss: 0.6929 - val_acc: 0.7633\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6932 - acc: 0.7611 - val_loss: 0.6927 - val_acc: 0.7633\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6931 - acc: 0.7611 - val_loss: 0.6927 - val_acc: 0.7633\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6931 - acc: 0.7609 - val_loss: 0.6926 - val_acc: 0.7617\n",
            "With LSTM_units = 16, dense_layer = 10, dense_activation = sigmoid, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 45ms/step - loss: 0.6975 - acc: 0.3767 - val_loss: 0.6873 - val_acc: 0.2857\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6971 - acc: 0.2819 - val_loss: 0.6876 - val_acc: 0.2842\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6967 - acc: 0.2855 - val_loss: 0.6879 - val_acc: 0.2826\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6964 - acc: 0.2760 - val_loss: 0.6882 - val_acc: 0.2847\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6961 - acc: 0.2738 - val_loss: 0.6886 - val_acc: 0.2831\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6958 - acc: 0.2683 - val_loss: 0.6889 - val_acc: 0.2754\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 10, dense_activation = sigmoid, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 46ms/step - loss: 0.6951 - acc: 0.2556 - val_loss: 0.6919 - val_acc: 0.2532\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6947 - acc: 0.2406 - val_loss: 0.6924 - val_acc: 0.2558\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6943 - acc: 0.7460 - val_loss: 0.6927 - val_acc: 0.7494\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6940 - acc: 0.7564 - val_loss: 0.6932 - val_acc: 0.7437\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6937 - acc: 0.7534 - val_loss: 0.6932 - val_acc: 0.7427\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6935 - acc: 0.7541 - val_loss: 0.6932 - val_acc: 0.7432\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 10, dense_activation = sigmoid, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 46ms/step - loss: 0.6945 - acc: 0.2401 - val_loss: 0.6918 - val_acc: 0.2372\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6942 - acc: 0.2760 - val_loss: 0.6922 - val_acc: 0.2347\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6939 - acc: 0.3700 - val_loss: 0.6925 - val_acc: 0.2372\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6937 - acc: 0.2531 - val_loss: 0.6927 - val_acc: 0.7437\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6935 - acc: 0.7436 - val_loss: 0.6930 - val_acc: 0.7519\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6933 - acc: 0.7630 - val_loss: 0.6931 - val_acc: 0.7540\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 10, dense_activation = sigmoid, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 45ms/step - loss: 0.6980 - acc: 0.2441 - val_loss: 0.6927 - val_acc: 0.2501\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6972 - acc: 0.2379 - val_loss: 0.6934 - val_acc: 0.2460\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6966 - acc: 0.2360 - val_loss: 0.6940 - val_acc: 0.2476\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6961 - acc: 0.2304 - val_loss: 0.6946 - val_acc: 0.2383\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6957 - acc: 0.6552 - val_loss: 0.6947 - val_acc: 0.7638\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6953 - acc: 0.3251 - val_loss: 0.6951 - val_acc: 0.2620\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 10, dense_activation = sigmoid, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 6s 61ms/step - loss: 0.6957 - acc: 0.2242 - val_loss: 0.6953 - val_acc: 0.2264\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6952 - acc: 0.2191 - val_loss: 0.6956 - val_acc: 0.2238\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6947 - acc: 0.7337 - val_loss: 0.6956 - val_acc: 0.7432\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6943 - acc: 0.7591 - val_loss: 0.6949 - val_acc: 0.7504\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7577 - val_loss: 0.6949 - val_acc: 0.7473\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6935 - acc: 0.7590 - val_loss: 0.6947 - val_acc: 0.7473\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6931 - acc: 0.7604 - val_loss: 0.6943 - val_acc: 0.7473\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6928 - acc: 0.7604 - val_loss: 0.6934 - val_acc: 0.7499\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6924 - acc: 0.7616 - val_loss: 0.6930 - val_acc: 0.7499\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6920 - acc: 0.7598 - val_loss: 0.6925 - val_acc: 0.7488\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6915 - acc: 0.7629 - val_loss: 0.6920 - val_acc: 0.7483\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6911 - acc: 0.7617 - val_loss: 0.6910 - val_acc: 0.7504\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6906 - acc: 0.7618 - val_loss: 0.6905 - val_acc: 0.7514\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6901 - acc: 0.7596 - val_loss: 0.6903 - val_acc: 0.7488\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6894 - acc: 0.7631 - val_loss: 0.6889 - val_acc: 0.7504\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6887 - acc: 0.7627 - val_loss: 0.6881 - val_acc: 0.7468\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6878 - acc: 0.7607 - val_loss: 0.6869 - val_acc: 0.7457\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6865 - acc: 0.7547 - val_loss: 0.6857 - val_acc: 0.7457\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6841 - acc: 0.7515 - val_loss: 0.6843 - val_acc: 0.7339\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6752 - acc: 0.7097 - val_loss: 0.6833 - val_acc: 0.6467\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6252 - acc: 0.6869 - val_loss: 0.6162 - val_acc: 0.7457\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.5688 - acc: 0.7705 - val_loss: 0.5415 - val_acc: 0.8138\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.5426 - acc: 0.7908 - val_loss: 0.5351 - val_acc: 0.8102\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.5265 - acc: 0.8039 - val_loss: 0.4975 - val_acc: 0.8293\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.5173 - acc: 0.8062 - val_loss: 0.5146 - val_acc: 0.8118\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.5075 - acc: 0.8116 - val_loss: 0.4954 - val_acc: 0.8262\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.5004 - acc: 0.8186 - val_loss: 0.4775 - val_acc: 0.8345\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4967 - acc: 0.8195 - val_loss: 0.4793 - val_acc: 0.8324\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.4920 - acc: 0.8268 - val_loss: 0.4611 - val_acc: 0.8422\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4875 - acc: 0.8308 - val_loss: 0.4585 - val_acc: 0.8448\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4834 - acc: 0.8346 - val_loss: 0.4807 - val_acc: 0.8277\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4833 - acc: 0.8311 - val_loss: 0.4506 - val_acc: 0.8499\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4747 - acc: 0.8407 - val_loss: 0.4465 - val_acc: 0.8520\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4771 - acc: 0.8339 - val_loss: 0.4448 - val_acc: 0.8525\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4730 - acc: 0.8371 - val_loss: 0.4583 - val_acc: 0.8417\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.4692 - acc: 0.8427 - val_loss: 0.4458 - val_acc: 0.8510\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4676 - acc: 0.8437 - val_loss: 0.4400 - val_acc: 0.8540\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.4686 - acc: 0.8407 - val_loss: 0.4367 - val_acc: 0.8546\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.4711 - acc: 0.8369 - val_loss: 0.4488 - val_acc: 0.8484\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.4653 - acc: 0.8436 - val_loss: 0.4595 - val_acc: 0.8370\n",
            "With LSTM_units = 16, dense_layer = 10, dense_activation = sigmoid, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 46ms/step - loss: 0.6974 - acc: 0.6701 - val_loss: 0.7052 - val_acc: 0.7437\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6972 - acc: 0.7522 - val_loss: 0.7044 - val_acc: 0.7442\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6970 - acc: 0.7519 - val_loss: 0.7037 - val_acc: 0.7442\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6968 - acc: 0.7525 - val_loss: 0.7031 - val_acc: 0.7442\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6966 - acc: 0.7529 - val_loss: 0.7025 - val_acc: 0.7442\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6964 - acc: 0.7529 - val_loss: 0.7019 - val_acc: 0.7457\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6962 - acc: 0.7536 - val_loss: 0.7012 - val_acc: 0.7463\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.6961 - acc: 0.7532 - val_loss: 0.7008 - val_acc: 0.7478\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.6959 - acc: 0.7537 - val_loss: 0.7003 - val_acc: 0.7473\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6958 - acc: 0.7534 - val_loss: 0.6998 - val_acc: 0.7478\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.6956 - acc: 0.7534 - val_loss: 0.6995 - val_acc: 0.7483\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6955 - acc: 0.7531 - val_loss: 0.6989 - val_acc: 0.7499\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6953 - acc: 0.7532 - val_loss: 0.6985 - val_acc: 0.7499\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6952 - acc: 0.7542 - val_loss: 0.6982 - val_acc: 0.7499\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6951 - acc: 0.7554 - val_loss: 0.6977 - val_acc: 0.7504\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6949 - acc: 0.7553 - val_loss: 0.6976 - val_acc: 0.7514\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6948 - acc: 0.7550 - val_loss: 0.6973 - val_acc: 0.7509\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6947 - acc: 0.7544 - val_loss: 0.6969 - val_acc: 0.7509\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6946 - acc: 0.7549 - val_loss: 0.6965 - val_acc: 0.7509\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6944 - acc: 0.7558 - val_loss: 0.6963 - val_acc: 0.7514\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6943 - acc: 0.7559 - val_loss: 0.6960 - val_acc: 0.7509\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6942 - acc: 0.7560 - val_loss: 0.6958 - val_acc: 0.7499\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6941 - acc: 0.7559 - val_loss: 0.6957 - val_acc: 0.7504\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6940 - acc: 0.7568 - val_loss: 0.6953 - val_acc: 0.7504\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6939 - acc: 0.7577 - val_loss: 0.6952 - val_acc: 0.7514\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6938 - acc: 0.7580 - val_loss: 0.6949 - val_acc: 0.7509\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6937 - acc: 0.7587 - val_loss: 0.6948 - val_acc: 0.7519\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6935 - acc: 0.7602 - val_loss: 0.6946 - val_acc: 0.7540\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6934 - acc: 0.7607 - val_loss: 0.6944 - val_acc: 0.7540\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7611 - val_loss: 0.6941 - val_acc: 0.7545\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6932 - acc: 0.7625 - val_loss: 0.6940 - val_acc: 0.7550\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6931 - acc: 0.7618 - val_loss: 0.6937 - val_acc: 0.7561\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6930 - acc: 0.7620 - val_loss: 0.6937 - val_acc: 0.7566\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6929 - acc: 0.7626 - val_loss: 0.6936 - val_acc: 0.7576\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6928 - acc: 0.7626 - val_loss: 0.6933 - val_acc: 0.7571\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6927 - acc: 0.7627 - val_loss: 0.6929 - val_acc: 0.7586\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6925 - acc: 0.7635 - val_loss: 0.6930 - val_acc: 0.7581\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6924 - acc: 0.7639 - val_loss: 0.6927 - val_acc: 0.7586\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6923 - acc: 0.7644 - val_loss: 0.6926 - val_acc: 0.7592\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6922 - acc: 0.7648 - val_loss: 0.6925 - val_acc: 0.7597\n",
            "With LSTM_units = 16, dense_layer = 50, dense_activation = relu, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 45ms/step - loss: 0.6936 - acc: 0.7427 - val_loss: 0.6973 - val_acc: 0.7416\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6935 - acc: 0.7540 - val_loss: 0.6971 - val_acc: 0.7442\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6934 - acc: 0.7549 - val_loss: 0.6968 - val_acc: 0.7483\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6934 - acc: 0.7564 - val_loss: 0.6965 - val_acc: 0.7488\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7572 - val_loss: 0.6964 - val_acc: 0.7488\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6932 - acc: 0.7569 - val_loss: 0.6962 - val_acc: 0.7504\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6931 - acc: 0.7565 - val_loss: 0.6959 - val_acc: 0.7504\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6930 - acc: 0.7565 - val_loss: 0.6958 - val_acc: 0.7514\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6930 - acc: 0.7565 - val_loss: 0.6955 - val_acc: 0.7514\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6929 - acc: 0.7567 - val_loss: 0.6955 - val_acc: 0.7519\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6928 - acc: 0.7573 - val_loss: 0.6952 - val_acc: 0.7530\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6927 - acc: 0.7582 - val_loss: 0.6951 - val_acc: 0.7535\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6927 - acc: 0.7580 - val_loss: 0.6948 - val_acc: 0.7540\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 2s 40ms/step - loss: 0.6926 - acc: 0.7582 - val_loss: 0.6946 - val_acc: 0.7545\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6925 - acc: 0.7587 - val_loss: 0.6945 - val_acc: 0.7550\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6924 - acc: 0.7591 - val_loss: 0.6944 - val_acc: 0.7550\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6924 - acc: 0.7590 - val_loss: 0.6943 - val_acc: 0.7550\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6923 - acc: 0.7598 - val_loss: 0.6941 - val_acc: 0.7566\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6922 - acc: 0.7598 - val_loss: 0.6940 - val_acc: 0.7561\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6921 - acc: 0.7602 - val_loss: 0.6939 - val_acc: 0.7561\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6920 - acc: 0.7614 - val_loss: 0.6937 - val_acc: 0.7566\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6920 - acc: 0.7616 - val_loss: 0.6936 - val_acc: 0.7571\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6919 - acc: 0.7621 - val_loss: 0.6934 - val_acc: 0.7571\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6918 - acc: 0.7623 - val_loss: 0.6933 - val_acc: 0.7571\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6917 - acc: 0.7623 - val_loss: 0.6931 - val_acc: 0.7571\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6917 - acc: 0.7622 - val_loss: 0.6931 - val_acc: 0.7571\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6916 - acc: 0.7626 - val_loss: 0.6929 - val_acc: 0.7576\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6915 - acc: 0.7631 - val_loss: 0.6927 - val_acc: 0.7576\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6914 - acc: 0.7634 - val_loss: 0.6926 - val_acc: 0.7576\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 2s 40ms/step - loss: 0.6913 - acc: 0.7638 - val_loss: 0.6923 - val_acc: 0.7597\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.6913 - acc: 0.7636 - val_loss: 0.6923 - val_acc: 0.7597\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 2s 41ms/step - loss: 0.6912 - acc: 0.7640 - val_loss: 0.6923 - val_acc: 0.7597\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6911 - acc: 0.7643 - val_loss: 0.6922 - val_acc: 0.7597\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6910 - acc: 0.7643 - val_loss: 0.6920 - val_acc: 0.7602\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6909 - acc: 0.7653 - val_loss: 0.6919 - val_acc: 0.7597\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6909 - acc: 0.7657 - val_loss: 0.6917 - val_acc: 0.7607\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 3s 42ms/step - loss: 0.6908 - acc: 0.7653 - val_loss: 0.6917 - val_acc: 0.7602\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 2s 41ms/step - loss: 0.6907 - acc: 0.7660 - val_loss: 0.6915 - val_acc: 0.7607\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6906 - acc: 0.7660 - val_loss: 0.6914 - val_acc: 0.7607\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6905 - acc: 0.7665 - val_loss: 0.6913 - val_acc: 0.7612\n",
            "With LSTM_units = 16, dense_layer = 50, dense_activation = relu, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 48ms/step - loss: 0.6953 - acc: 0.7345 - val_loss: 0.7032 - val_acc: 0.7344\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6949 - acc: 0.7474 - val_loss: 0.7020 - val_acc: 0.7396\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6947 - acc: 0.7524 - val_loss: 0.7010 - val_acc: 0.7437\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6944 - acc: 0.7532 - val_loss: 0.7000 - val_acc: 0.7457\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6941 - acc: 0.7531 - val_loss: 0.6989 - val_acc: 0.7478\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6939 - acc: 0.7546 - val_loss: 0.6982 - val_acc: 0.7483\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6937 - acc: 0.7551 - val_loss: 0.6976 - val_acc: 0.7499\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6935 - acc: 0.7556 - val_loss: 0.6971 - val_acc: 0.7504\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6933 - acc: 0.7563 - val_loss: 0.6963 - val_acc: 0.7524\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6931 - acc: 0.7576 - val_loss: 0.6958 - val_acc: 0.7504\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.6929 - acc: 0.7583 - val_loss: 0.6953 - val_acc: 0.7519\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6926 - acc: 0.7585 - val_loss: 0.6949 - val_acc: 0.7519\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6924 - acc: 0.7599 - val_loss: 0.6942 - val_acc: 0.7530\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6922 - acc: 0.7611 - val_loss: 0.6939 - val_acc: 0.7530\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.6920 - acc: 0.7614 - val_loss: 0.6932 - val_acc: 0.7545\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6918 - acc: 0.7614 - val_loss: 0.6932 - val_acc: 0.7530\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6916 - acc: 0.7625 - val_loss: 0.6925 - val_acc: 0.7550\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6914 - acc: 0.7644 - val_loss: 0.6919 - val_acc: 0.7566\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6911 - acc: 0.7657 - val_loss: 0.6917 - val_acc: 0.7561\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6909 - acc: 0.7674 - val_loss: 0.6914 - val_acc: 0.7524\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6906 - acc: 0.7669 - val_loss: 0.6911 - val_acc: 0.7530\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6903 - acc: 0.7676 - val_loss: 0.6905 - val_acc: 0.7530\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6900 - acc: 0.7657 - val_loss: 0.6903 - val_acc: 0.7540\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6897 - acc: 0.7674 - val_loss: 0.6897 - val_acc: 0.7550\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6894 - acc: 0.7670 - val_loss: 0.6894 - val_acc: 0.7540\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6890 - acc: 0.7679 - val_loss: 0.6888 - val_acc: 0.7514\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6886 - acc: 0.7654 - val_loss: 0.6885 - val_acc: 0.7509\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.6881 - acc: 0.7676 - val_loss: 0.6876 - val_acc: 0.7488\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6876 - acc: 0.7676 - val_loss: 0.6870 - val_acc: 0.7457\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6870 - acc: 0.7657 - val_loss: 0.6864 - val_acc: 0.7432\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6862 - acc: 0.7666 - val_loss: 0.6844 - val_acc: 0.7421\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6852 - acc: 0.7663 - val_loss: 0.6834 - val_acc: 0.7488\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6837 - acc: 0.7611 - val_loss: 0.6810 - val_acc: 0.7488\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6806 - acc: 0.7627 - val_loss: 0.6761 - val_acc: 0.7406\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6705 - acc: 0.7629 - val_loss: 0.6611 - val_acc: 0.7339\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6282 - acc: 0.7399 - val_loss: 0.6044 - val_acc: 0.7468\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.5806 - acc: 0.7509 - val_loss: 0.5511 - val_acc: 0.7942\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.5617 - acc: 0.7616 - val_loss: 0.5532 - val_acc: 0.7715\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.5491 - acc: 0.7698 - val_loss: 0.5402 - val_acc: 0.7782\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.5414 - acc: 0.7716 - val_loss: 0.5307 - val_acc: 0.7844\n",
            "With LSTM_units = 16, dense_layer = 50, dense_activation = relu, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 44ms/step - loss: 0.6966 - acc: 0.4415 - val_loss: 0.6953 - val_acc: 0.2249\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6963 - acc: 0.7297 - val_loss: 0.6954 - val_acc: 0.7401\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 39ms/step - loss: 0.6960 - acc: 0.6338 - val_loss: 0.6956 - val_acc: 0.7385\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6958 - acc: 0.7520 - val_loss: 0.6957 - val_acc: 0.7432\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6956 - acc: 0.7532 - val_loss: 0.6956 - val_acc: 0.7421\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6954 - acc: 0.7509 - val_loss: 0.6957 - val_acc: 0.7432\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 50, dense_activation = relu, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 6s 45ms/step - loss: 0.6975 - acc: 0.7769 - val_loss: 0.6904 - val_acc: 0.7803\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6968 - acc: 0.7810 - val_loss: 0.6916 - val_acc: 0.7731\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6962 - acc: 0.7796 - val_loss: 0.6922 - val_acc: 0.7700\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6958 - acc: 0.7665 - val_loss: 0.6928 - val_acc: 0.7710\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6954 - acc: 0.7702 - val_loss: 0.6933 - val_acc: 0.7674\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6950 - acc: 0.7654 - val_loss: 0.6933 - val_acc: 0.7684\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 50, dense_activation = relu, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 47ms/step - loss: 0.6974 - acc: 0.2302 - val_loss: 0.6933 - val_acc: 0.2352\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6966 - acc: 0.4074 - val_loss: 0.6941 - val_acc: 0.2310\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6960 - acc: 0.2240 - val_loss: 0.6948 - val_acc: 0.2228\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6956 - acc: 0.4053 - val_loss: 0.6949 - val_acc: 0.2274\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6951 - acc: 0.5467 - val_loss: 0.6947 - val_acc: 0.7323\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6947 - acc: 0.7434 - val_loss: 0.6948 - val_acc: 0.7323\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 50, dense_activation = relu, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 47ms/step - loss: 0.6936 - acc: 0.2168 - val_loss: 0.6949 - val_acc: 0.2218\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6935 - acc: 0.7016 - val_loss: 0.6948 - val_acc: 0.7313\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6934 - acc: 0.7425 - val_loss: 0.6947 - val_acc: 0.7329\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6933 - acc: 0.7431 - val_loss: 0.6947 - val_acc: 0.7344\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6932 - acc: 0.7451 - val_loss: 0.6946 - val_acc: 0.7354\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6932 - acc: 0.7446 - val_loss: 0.6947 - val_acc: 0.7349\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6931 - acc: 0.7465 - val_loss: 0.6946 - val_acc: 0.7354\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6930 - acc: 0.7467 - val_loss: 0.6945 - val_acc: 0.7349\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6929 - acc: 0.7474 - val_loss: 0.6945 - val_acc: 0.7354\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6928 - acc: 0.7492 - val_loss: 0.6944 - val_acc: 0.7370\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6927 - acc: 0.7491 - val_loss: 0.6943 - val_acc: 0.7365\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6927 - acc: 0.7489 - val_loss: 0.6943 - val_acc: 0.7385\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6926 - acc: 0.7509 - val_loss: 0.6941 - val_acc: 0.7411\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6925 - acc: 0.7506 - val_loss: 0.6941 - val_acc: 0.7401\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6924 - acc: 0.7515 - val_loss: 0.6940 - val_acc: 0.7411\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6923 - acc: 0.7523 - val_loss: 0.6938 - val_acc: 0.7406\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6922 - acc: 0.7514 - val_loss: 0.6938 - val_acc: 0.7406\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6922 - acc: 0.7514 - val_loss: 0.6937 - val_acc: 0.7406\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6921 - acc: 0.7515 - val_loss: 0.6936 - val_acc: 0.7406\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6920 - acc: 0.7507 - val_loss: 0.6936 - val_acc: 0.7406\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6919 - acc: 0.7523 - val_loss: 0.6934 - val_acc: 0.7406\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6918 - acc: 0.7523 - val_loss: 0.6933 - val_acc: 0.7406\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6917 - acc: 0.7523 - val_loss: 0.6933 - val_acc: 0.7396\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6916 - acc: 0.7519 - val_loss: 0.6931 - val_acc: 0.7396\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6915 - acc: 0.7515 - val_loss: 0.6930 - val_acc: 0.7396\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6914 - acc: 0.7511 - val_loss: 0.6929 - val_acc: 0.7396\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6913 - acc: 0.7507 - val_loss: 0.6929 - val_acc: 0.7390\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6912 - acc: 0.7519 - val_loss: 0.6926 - val_acc: 0.7396\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6911 - acc: 0.7510 - val_loss: 0.6925 - val_acc: 0.7390\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6910 - acc: 0.7514 - val_loss: 0.6924 - val_acc: 0.7396\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6909 - acc: 0.7500 - val_loss: 0.6923 - val_acc: 0.7390\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6908 - acc: 0.7498 - val_loss: 0.6921 - val_acc: 0.7390\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6907 - acc: 0.7488 - val_loss: 0.6922 - val_acc: 0.7365\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6906 - acc: 0.7487 - val_loss: 0.6919 - val_acc: 0.7365\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6905 - acc: 0.7480 - val_loss: 0.6918 - val_acc: 0.7344\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6904 - acc: 0.7479 - val_loss: 0.6916 - val_acc: 0.7344\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6903 - acc: 0.7484 - val_loss: 0.6916 - val_acc: 0.7339\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6901 - acc: 0.7478 - val_loss: 0.6914 - val_acc: 0.7329\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6900 - acc: 0.7483 - val_loss: 0.6912 - val_acc: 0.7329\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6899 - acc: 0.7484 - val_loss: 0.6910 - val_acc: 0.7323\n",
            "With LSTM_units = 16, dense_layer = 50, dense_activation = sigmoid, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 4s 42ms/step - loss: 0.6952 - acc: 0.5065 - val_loss: 0.6984 - val_acc: 0.7200\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6952 - acc: 0.7304 - val_loss: 0.6984 - val_acc: 0.7194\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6951 - acc: 0.7386 - val_loss: 0.6984 - val_acc: 0.7210\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6950 - acc: 0.7402 - val_loss: 0.6983 - val_acc: 0.7292\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6949 - acc: 0.7411 - val_loss: 0.6982 - val_acc: 0.7308\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6948 - acc: 0.7466 - val_loss: 0.6982 - val_acc: 0.7354\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6947 - acc: 0.7473 - val_loss: 0.6981 - val_acc: 0.7354\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6947 - acc: 0.7495 - val_loss: 0.6980 - val_acc: 0.7390\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6946 - acc: 0.7504 - val_loss: 0.6980 - val_acc: 0.7390\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6945 - acc: 0.7501 - val_loss: 0.6979 - val_acc: 0.7385\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6944 - acc: 0.7510 - val_loss: 0.6978 - val_acc: 0.7406\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6943 - acc: 0.7513 - val_loss: 0.6977 - val_acc: 0.7406\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6943 - acc: 0.7514 - val_loss: 0.6977 - val_acc: 0.7421\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6942 - acc: 0.7523 - val_loss: 0.6975 - val_acc: 0.7421\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6941 - acc: 0.7529 - val_loss: 0.6975 - val_acc: 0.7437\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6940 - acc: 0.7529 - val_loss: 0.6974 - val_acc: 0.7442\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6940 - acc: 0.7534 - val_loss: 0.6972 - val_acc: 0.7437\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6939 - acc: 0.7531 - val_loss: 0.6972 - val_acc: 0.7452\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6938 - acc: 0.7544 - val_loss: 0.6971 - val_acc: 0.7452\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6937 - acc: 0.7544 - val_loss: 0.6970 - val_acc: 0.7452\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6937 - acc: 0.7540 - val_loss: 0.6969 - val_acc: 0.7452\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6936 - acc: 0.7544 - val_loss: 0.6968 - val_acc: 0.7452\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6935 - acc: 0.7556 - val_loss: 0.6967 - val_acc: 0.7468\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6934 - acc: 0.7558 - val_loss: 0.6966 - val_acc: 0.7488\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6934 - acc: 0.7559 - val_loss: 0.6965 - val_acc: 0.7494\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6933 - acc: 0.7560 - val_loss: 0.6963 - val_acc: 0.7504\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6932 - acc: 0.7568 - val_loss: 0.6962 - val_acc: 0.7509\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6931 - acc: 0.7576 - val_loss: 0.6960 - val_acc: 0.7514\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6931 - acc: 0.7573 - val_loss: 0.6960 - val_acc: 0.7514\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6930 - acc: 0.7583 - val_loss: 0.6959 - val_acc: 0.7509\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6929 - acc: 0.7582 - val_loss: 0.6957 - val_acc: 0.7514\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6928 - acc: 0.7589 - val_loss: 0.6956 - val_acc: 0.7519\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6928 - acc: 0.7587 - val_loss: 0.6955 - val_acc: 0.7519\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6927 - acc: 0.7594 - val_loss: 0.6954 - val_acc: 0.7519\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6926 - acc: 0.7598 - val_loss: 0.6953 - val_acc: 0.7524\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6925 - acc: 0.7599 - val_loss: 0.6950 - val_acc: 0.7530\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6925 - acc: 0.7608 - val_loss: 0.6950 - val_acc: 0.7524\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6924 - acc: 0.7605 - val_loss: 0.6949 - val_acc: 0.7540\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6923 - acc: 0.7612 - val_loss: 0.6947 - val_acc: 0.7545\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6922 - acc: 0.7614 - val_loss: 0.6946 - val_acc: 0.7545\n",
            "With LSTM_units = 16, dense_layer = 50, dense_activation = sigmoid, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 44ms/step - loss: 0.6950 - acc: 0.5925 - val_loss: 0.6984 - val_acc: 0.7385\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6948 - acc: 0.7518 - val_loss: 0.6977 - val_acc: 0.7442\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6946 - acc: 0.7495 - val_loss: 0.6974 - val_acc: 0.7416\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6944 - acc: 0.7546 - val_loss: 0.6967 - val_acc: 0.7473\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6942 - acc: 0.7571 - val_loss: 0.6962 - val_acc: 0.7504\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6940 - acc: 0.7571 - val_loss: 0.6958 - val_acc: 0.7509\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6938 - acc: 0.7596 - val_loss: 0.6952 - val_acc: 0.7535\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6936 - acc: 0.7595 - val_loss: 0.6948 - val_acc: 0.7540\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6934 - acc: 0.7607 - val_loss: 0.6944 - val_acc: 0.7550\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6932 - acc: 0.7617 - val_loss: 0.6940 - val_acc: 0.7566\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6930 - acc: 0.7626 - val_loss: 0.6938 - val_acc: 0.7571\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6928 - acc: 0.7632 - val_loss: 0.6932 - val_acc: 0.7586\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6926 - acc: 0.7647 - val_loss: 0.6929 - val_acc: 0.7586\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6923 - acc: 0.7651 - val_loss: 0.6926 - val_acc: 0.7597\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6921 - acc: 0.7653 - val_loss: 0.6924 - val_acc: 0.7597\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6919 - acc: 0.7662 - val_loss: 0.6922 - val_acc: 0.7628\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6917 - acc: 0.7669 - val_loss: 0.6920 - val_acc: 0.7638\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6914 - acc: 0.7678 - val_loss: 0.6916 - val_acc: 0.7633\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6912 - acc: 0.7697 - val_loss: 0.6909 - val_acc: 0.7643\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6909 - acc: 0.7680 - val_loss: 0.6912 - val_acc: 0.7648\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6907 - acc: 0.7688 - val_loss: 0.6903 - val_acc: 0.7674\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6904 - acc: 0.7707 - val_loss: 0.6903 - val_acc: 0.7674\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6901 - acc: 0.7715 - val_loss: 0.6896 - val_acc: 0.7684\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6898 - acc: 0.7729 - val_loss: 0.6895 - val_acc: 0.7669\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6894 - acc: 0.7734 - val_loss: 0.6890 - val_acc: 0.7690\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6891 - acc: 0.7763 - val_loss: 0.6888 - val_acc: 0.7695\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6887 - acc: 0.7769 - val_loss: 0.6884 - val_acc: 0.7684\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6883 - acc: 0.7776 - val_loss: 0.6878 - val_acc: 0.7669\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6879 - acc: 0.7776 - val_loss: 0.6872 - val_acc: 0.7679\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6875 - acc: 0.7781 - val_loss: 0.6870 - val_acc: 0.7664\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6870 - acc: 0.7754 - val_loss: 0.6865 - val_acc: 0.7633\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6865 - acc: 0.7774 - val_loss: 0.6858 - val_acc: 0.7622\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6858 - acc: 0.7769 - val_loss: 0.6838 - val_acc: 0.7669\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6850 - acc: 0.7796 - val_loss: 0.6829 - val_acc: 0.7679\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6841 - acc: 0.7754 - val_loss: 0.6816 - val_acc: 0.7653\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6828 - acc: 0.7758 - val_loss: 0.6797 - val_acc: 0.7720\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6806 - acc: 0.7769 - val_loss: 0.6740 - val_acc: 0.7788\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6761 - acc: 0.7812 - val_loss: 0.6743 - val_acc: 0.7576\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6642 - acc: 0.7785 - val_loss: 0.6641 - val_acc: 0.7555\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6295 - acc: 0.7528 - val_loss: 0.6359 - val_acc: 0.7628\n",
            "With LSTM_units = 16, dense_layer = 50, dense_activation = sigmoid, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 42ms/step - loss: 0.6991 - acc: 0.7666 - val_loss: 0.6869 - val_acc: 0.7535\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6984 - acc: 0.5247 - val_loss: 0.6876 - val_acc: 0.2501\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6978 - acc: 0.2445 - val_loss: 0.6882 - val_acc: 0.2501\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6973 - acc: 0.2436 - val_loss: 0.6888 - val_acc: 0.2491\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6968 - acc: 0.2429 - val_loss: 0.6893 - val_acc: 0.2496\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6965 - acc: 0.2419 - val_loss: 0.6900 - val_acc: 0.2496\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 50, dense_activation = sigmoid, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 5s 43ms/step - loss: 0.6958 - acc: 0.5256 - val_loss: 0.6956 - val_acc: 0.7468\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6954 - acc: 0.7239 - val_loss: 0.6955 - val_acc: 0.7555\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6951 - acc: 0.7569 - val_loss: 0.6953 - val_acc: 0.7576\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6948 - acc: 0.7545 - val_loss: 0.6951 - val_acc: 0.7576\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6945 - acc: 0.7586 - val_loss: 0.6948 - val_acc: 0.7607\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6941 - acc: 0.7572 - val_loss: 0.6946 - val_acc: 0.7602\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6939 - acc: 0.7596 - val_loss: 0.6940 - val_acc: 0.7612\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6936 - acc: 0.7574 - val_loss: 0.6946 - val_acc: 0.7576\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6932 - acc: 0.7602 - val_loss: 0.6938 - val_acc: 0.7607\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6929 - acc: 0.7607 - val_loss: 0.6930 - val_acc: 0.7607\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6926 - acc: 0.7614 - val_loss: 0.6932 - val_acc: 0.7612\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6923 - acc: 0.7622 - val_loss: 0.6924 - val_acc: 0.7638\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6920 - acc: 0.7631 - val_loss: 0.6921 - val_acc: 0.7638\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 2s 36ms/step - loss: 0.6917 - acc: 0.7644 - val_loss: 0.6915 - val_acc: 0.7638\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 2s 38ms/step - loss: 0.6913 - acc: 0.7632 - val_loss: 0.6915 - val_acc: 0.7622\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6910 - acc: 0.7642 - val_loss: 0.6909 - val_acc: 0.7638\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6906 - acc: 0.7678 - val_loss: 0.6901 - val_acc: 0.7690\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6902 - acc: 0.7707 - val_loss: 0.6895 - val_acc: 0.7684\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6898 - acc: 0.7723 - val_loss: 0.6892 - val_acc: 0.7684\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6893 - acc: 0.7727 - val_loss: 0.6888 - val_acc: 0.7690\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6889 - acc: 0.7716 - val_loss: 0.6883 - val_acc: 0.7679\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6885 - acc: 0.7727 - val_loss: 0.6876 - val_acc: 0.7684\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6879 - acc: 0.7749 - val_loss: 0.6868 - val_acc: 0.7679\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6873 - acc: 0.7751 - val_loss: 0.6867 - val_acc: 0.7674\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6866 - acc: 0.7754 - val_loss: 0.6858 - val_acc: 0.7653\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 2s 37ms/step - loss: 0.6860 - acc: 0.7747 - val_loss: 0.6855 - val_acc: 0.7648\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6852 - acc: 0.7773 - val_loss: 0.6842 - val_acc: 0.7633\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6843 - acc: 0.7733 - val_loss: 0.6849 - val_acc: 0.7540\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6835 - acc: 0.7709 - val_loss: 0.6831 - val_acc: 0.7540\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6818 - acc: 0.7671 - val_loss: 0.6819 - val_acc: 0.7509\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6789 - acc: 0.7523 - val_loss: 0.6807 - val_acc: 0.7385\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6651 - acc: 0.6748 - val_loss: 0.6884 - val_acc: 0.6313\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6200 - acc: 0.7163 - val_loss: 0.6206 - val_acc: 0.8061\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.5907 - acc: 0.7794 - val_loss: 0.6248 - val_acc: 0.7968\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.5732 - acc: 0.7986 - val_loss: 0.6003 - val_acc: 0.8159\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.5637 - acc: 0.8077 - val_loss: 0.5874 - val_acc: 0.8216\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.5577 - acc: 0.8008 - val_loss: 0.5825 - val_acc: 0.8200\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.5461 - acc: 0.8137 - val_loss: 0.5670 - val_acc: 0.8272\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.5394 - acc: 0.8019 - val_loss: 0.5644 - val_acc: 0.8216\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.5300 - acc: 0.8224 - val_loss: 0.5389 - val_acc: 0.8427\n",
            "With LSTM_units = 16, dense_layer = 50, dense_activation = sigmoid, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 4s 43ms/step - loss: 0.6966 - acc: 0.2284 - val_loss: 0.6939 - val_acc: 0.2316\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6960 - acc: 0.2242 - val_loss: 0.6943 - val_acc: 0.2269\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 2s 34ms/step - loss: 0.6956 - acc: 0.2223 - val_loss: 0.6945 - val_acc: 0.2264\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6952 - acc: 0.4475 - val_loss: 0.6946 - val_acc: 0.7494\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6948 - acc: 0.7617 - val_loss: 0.6949 - val_acc: 0.7401\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 2s 35ms/step - loss: 0.6945 - acc: 0.4260 - val_loss: 0.6950 - val_acc: 0.7442\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 16, dense_layer = 50, dense_activation = sigmoid, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 87ms/step - loss: 0.6990 - acc: 0.2557 - val_loss: 0.6870 - val_acc: 0.2548\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6978 - acc: 0.2473 - val_loss: 0.6882 - val_acc: 0.2532\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6969 - acc: 0.2460 - val_loss: 0.6891 - val_acc: 0.2517\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 77ms/step - loss: 0.6961 - acc: 0.2447 - val_loss: 0.6900 - val_acc: 0.2496\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 77ms/step - loss: 0.6955 - acc: 0.2411 - val_loss: 0.6909 - val_acc: 0.2470\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6950 - acc: 0.2415 - val_loss: 0.6916 - val_acc: 0.2465\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 64, dense_layer = 1, dense_activation = relu, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 88ms/step - loss: 0.6970 - acc: 0.7683 - val_loss: 0.6914 - val_acc: 0.7653\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6964 - acc: 0.7198 - val_loss: 0.6924 - val_acc: 0.7267\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6959 - acc: 0.4732 - val_loss: 0.6932 - val_acc: 0.5467\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6955 - acc: 0.7427 - val_loss: 0.6938 - val_acc: 0.7473\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6952 - acc: 0.7540 - val_loss: 0.6941 - val_acc: 0.7488\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.6949 - acc: 0.7498 - val_loss: 0.6947 - val_acc: 0.7406\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 64, dense_layer = 1, dense_activation = relu, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 8s 89ms/step - loss: 0.6950 - acc: 0.7189 - val_loss: 0.6970 - val_acc: 0.7494\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6945 - acc: 0.7485 - val_loss: 0.6967 - val_acc: 0.7452\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6941 - acc: 0.7489 - val_loss: 0.6962 - val_acc: 0.7432\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6935 - acc: 0.7544 - val_loss: 0.6951 - val_acc: 0.7468\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6931 - acc: 0.7541 - val_loss: 0.6951 - val_acc: 0.7463\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6925 - acc: 0.7525 - val_loss: 0.6946 - val_acc: 0.7437\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6920 - acc: 0.7544 - val_loss: 0.6935 - val_acc: 0.7447\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.6914 - acc: 0.7520 - val_loss: 0.6934 - val_acc: 0.7411\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6907 - acc: 0.7525 - val_loss: 0.6928 - val_acc: 0.7365\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6900 - acc: 0.7465 - val_loss: 0.6922 - val_acc: 0.7329\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6889 - acc: 0.7409 - val_loss: 0.6918 - val_acc: 0.7308\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6873 - acc: 0.7337 - val_loss: 0.6916 - val_acc: 0.7179\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6837 - acc: 0.6802 - val_loss: 0.6995 - val_acc: 0.5926\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6651 - acc: 0.5142 - val_loss: 0.6988 - val_acc: 0.6044\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.5922 - acc: 0.7522 - val_loss: 0.5955 - val_acc: 0.8288\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.5533 - acc: 0.8072 - val_loss: 0.5569 - val_acc: 0.8412\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.5282 - acc: 0.8266 - val_loss: 0.5475 - val_acc: 0.8334\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.5077 - acc: 0.8246 - val_loss: 0.4907 - val_acc: 0.8669\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4845 - acc: 0.8417 - val_loss: 0.4866 - val_acc: 0.8556\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4673 - acc: 0.8515 - val_loss: 0.4372 - val_acc: 0.8736\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4555 - acc: 0.8535 - val_loss: 0.4284 - val_acc: 0.8742\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4502 - acc: 0.8565 - val_loss: 0.4164 - val_acc: 0.8778\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4412 - acc: 0.8632 - val_loss: 0.4120 - val_acc: 0.8778\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4353 - acc: 0.8631 - val_loss: 0.4015 - val_acc: 0.8840\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4309 - acc: 0.8660 - val_loss: 0.3997 - val_acc: 0.8845\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4268 - acc: 0.8699 - val_loss: 0.4072 - val_acc: 0.8726\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4251 - acc: 0.8676 - val_loss: 0.3911 - val_acc: 0.8876\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4208 - acc: 0.8726 - val_loss: 0.3843 - val_acc: 0.8876\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4175 - acc: 0.8749 - val_loss: 0.4115 - val_acc: 0.8690\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4147 - acc: 0.8736 - val_loss: 0.4025 - val_acc: 0.8773\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4117 - acc: 0.8762 - val_loss: 0.3852 - val_acc: 0.8855\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4095 - acc: 0.8785 - val_loss: 0.3908 - val_acc: 0.8798\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4061 - acc: 0.8784 - val_loss: 0.3763 - val_acc: 0.8891\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.4024 - acc: 0.8814 - val_loss: 0.3736 - val_acc: 0.8912\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.4007 - acc: 0.8820 - val_loss: 0.3848 - val_acc: 0.8829\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3987 - acc: 0.8839 - val_loss: 0.3901 - val_acc: 0.8809\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3967 - acc: 0.8873 - val_loss: 0.3749 - val_acc: 0.8896\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3966 - acc: 0.8860 - val_loss: 0.3779 - val_acc: 0.8876\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3954 - acc: 0.8841 - val_loss: 0.3841 - val_acc: 0.8840\n",
            "Epoch 39: early stopping\n",
            "With LSTM_units = 64, dense_layer = 1, dense_activation = relu, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 89ms/step - loss: 0.6958 - acc: 0.3026 - val_loss: 0.6929 - val_acc: 0.2321\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 77ms/step - loss: 0.6947 - acc: 0.2362 - val_loss: 0.6946 - val_acc: 0.2326\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6940 - acc: 0.3404 - val_loss: 0.6955 - val_acc: 0.7308\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6935 - acc: 0.7527 - val_loss: 0.6950 - val_acc: 0.7473\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6929 - acc: 0.7480 - val_loss: 0.6953 - val_acc: 0.7396\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6925 - acc: 0.7474 - val_loss: 0.6950 - val_acc: 0.7421\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 64, dense_layer = 1, dense_activation = relu, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 88ms/step - loss: 0.6951 - acc: 0.7642 - val_loss: 0.6938 - val_acc: 0.7519\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6938 - acc: 0.7471 - val_loss: 0.6955 - val_acc: 0.7344\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6927 - acc: 0.7449 - val_loss: 0.6962 - val_acc: 0.7256\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6915 - acc: 0.7434 - val_loss: 0.6953 - val_acc: 0.7236\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6899 - acc: 0.7359 - val_loss: 0.6942 - val_acc: 0.7194\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6859 - acc: 0.7012 - val_loss: 0.7025 - val_acc: 0.6137\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 64, dense_layer = 1, dense_activation = relu, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 88ms/step - loss: 0.6936 - acc: 0.5235 - val_loss: 0.6976 - val_acc: 0.7380\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6928 - acc: 0.7452 - val_loss: 0.6965 - val_acc: 0.7421\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6919 - acc: 0.7555 - val_loss: 0.6944 - val_acc: 0.7452\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6910 - acc: 0.7568 - val_loss: 0.6941 - val_acc: 0.7411\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.6898 - acc: 0.7515 - val_loss: 0.6933 - val_acc: 0.7329\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6884 - acc: 0.7474 - val_loss: 0.6917 - val_acc: 0.7318\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6841 - acc: 0.7248 - val_loss: 0.6989 - val_acc: 0.6261\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6137 - acc: 0.6437 - val_loss: 0.5576 - val_acc: 0.8319\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.5067 - acc: 0.8309 - val_loss: 0.6120 - val_acc: 0.7720\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4801 - acc: 0.8349 - val_loss: 0.4326 - val_acc: 0.8618\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4654 - acc: 0.8415 - val_loss: 0.4085 - val_acc: 0.8695\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4544 - acc: 0.8504 - val_loss: 0.4489 - val_acc: 0.8391\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4445 - acc: 0.8504 - val_loss: 0.4339 - val_acc: 0.8432\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4393 - acc: 0.8463 - val_loss: 0.4049 - val_acc: 0.8556\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4307 - acc: 0.8440 - val_loss: 0.4342 - val_acc: 0.8355\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4181 - acc: 0.8449 - val_loss: 0.3647 - val_acc: 0.8721\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4062 - acc: 0.8495 - val_loss: 0.3861 - val_acc: 0.8520\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3964 - acc: 0.8496 - val_loss: 0.3673 - val_acc: 0.8618\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3898 - acc: 0.8571 - val_loss: 0.3763 - val_acc: 0.8556\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3834 - acc: 0.8533 - val_loss: 0.3867 - val_acc: 0.8468\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.3783 - acc: 0.8540 - val_loss: 0.3637 - val_acc: 0.8556\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 77ms/step - loss: 0.3709 - acc: 0.8584 - val_loss: 0.3586 - val_acc: 0.8571\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.3660 - acc: 0.8584 - val_loss: 0.3700 - val_acc: 0.8504\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.3630 - acc: 0.8583 - val_loss: 0.3915 - val_acc: 0.8314\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3580 - acc: 0.8573 - val_loss: 0.3702 - val_acc: 0.8427\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3520 - acc: 0.8580 - val_loss: 0.3489 - val_acc: 0.8566\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3470 - acc: 0.8607 - val_loss: 0.3566 - val_acc: 0.8453\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3412 - acc: 0.8582 - val_loss: 0.3648 - val_acc: 0.8406\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3367 - acc: 0.8588 - val_loss: 0.3171 - val_acc: 0.8690\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3348 - acc: 0.8624 - val_loss: 0.3468 - val_acc: 0.8473\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3306 - acc: 0.8592 - val_loss: 0.3668 - val_acc: 0.8365\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3235 - acc: 0.8663 - val_loss: 0.3142 - val_acc: 0.8659\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3201 - acc: 0.8672 - val_loss: 0.3503 - val_acc: 0.8458\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3157 - acc: 0.8681 - val_loss: 0.3446 - val_acc: 0.8479\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3111 - acc: 0.8664 - val_loss: 0.3286 - val_acc: 0.8540\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3098 - acc: 0.8713 - val_loss: 0.3456 - val_acc: 0.8442\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3084 - acc: 0.8705 - val_loss: 0.3198 - val_acc: 0.8608\n",
            "Epoch 37: early stopping\n",
            "With LSTM_units = 64, dense_layer = 1, dense_activation = relu, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 86ms/step - loss: 0.6951 - acc: 0.2297 - val_loss: 0.6934 - val_acc: 0.2326\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6948 - acc: 0.4922 - val_loss: 0.6939 - val_acc: 0.2310\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6945 - acc: 0.6235 - val_loss: 0.6943 - val_acc: 0.7096\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6942 - acc: 0.7314 - val_loss: 0.6946 - val_acc: 0.7277\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6939 - acc: 0.7348 - val_loss: 0.6951 - val_acc: 0.7215\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6937 - acc: 0.5163 - val_loss: 0.6954 - val_acc: 0.7194\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 64, dense_layer = 1, dense_activation = sigmoid, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 9s 97ms/step - loss: 0.6948 - acc: 0.3823 - val_loss: 0.6932 - val_acc: 0.7323\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6945 - acc: 0.2700 - val_loss: 0.6937 - val_acc: 0.2254\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6942 - acc: 0.7164 - val_loss: 0.6941 - val_acc: 0.7251\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6940 - acc: 0.7284 - val_loss: 0.6942 - val_acc: 0.7287\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6938 - acc: 0.7380 - val_loss: 0.6943 - val_acc: 0.7261\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6935 - acc: 0.7367 - val_loss: 0.6945 - val_acc: 0.7267\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 64, dense_layer = 1, dense_activation = sigmoid, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 90ms/step - loss: 0.6951 - acc: 0.3001 - val_loss: 0.6975 - val_acc: 0.7478\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6945 - acc: 0.7533 - val_loss: 0.6968 - val_acc: 0.7499\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6940 - acc: 0.7523 - val_loss: 0.6963 - val_acc: 0.7488\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6935 - acc: 0.7511 - val_loss: 0.6959 - val_acc: 0.7457\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6930 - acc: 0.7523 - val_loss: 0.6945 - val_acc: 0.7488\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6925 - acc: 0.7529 - val_loss: 0.6947 - val_acc: 0.7421\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6920 - acc: 0.7524 - val_loss: 0.6936 - val_acc: 0.7447\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6914 - acc: 0.7529 - val_loss: 0.6931 - val_acc: 0.7447\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6908 - acc: 0.7547 - val_loss: 0.6922 - val_acc: 0.7463\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6901 - acc: 0.7583 - val_loss: 0.6911 - val_acc: 0.7468\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6893 - acc: 0.7560 - val_loss: 0.6907 - val_acc: 0.7411\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6882 - acc: 0.7542 - val_loss: 0.6893 - val_acc: 0.7390\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6865 - acc: 0.7529 - val_loss: 0.6902 - val_acc: 0.7318\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6834 - acc: 0.7425 - val_loss: 0.6929 - val_acc: 0.7138\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6618 - acc: 0.6698 - val_loss: 0.7211 - val_acc: 0.6220\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.5685 - acc: 0.7827 - val_loss: 0.5661 - val_acc: 0.8489\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.5205 - acc: 0.8260 - val_loss: 0.5077 - val_acc: 0.8644\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4967 - acc: 0.8360 - val_loss: 0.5001 - val_acc: 0.8489\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.4896 - acc: 0.8313 - val_loss: 0.4623 - val_acc: 0.8608\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.4758 - acc: 0.8435 - val_loss: 0.4698 - val_acc: 0.8504\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4684 - acc: 0.8450 - val_loss: 0.5123 - val_acc: 0.8128\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4613 - acc: 0.8428 - val_loss: 0.4794 - val_acc: 0.8329\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4555 - acc: 0.8469 - val_loss: 0.4410 - val_acc: 0.8577\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4505 - acc: 0.8466 - val_loss: 0.4682 - val_acc: 0.8319\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.4436 - acc: 0.8518 - val_loss: 0.4283 - val_acc: 0.8602\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4402 - acc: 0.8553 - val_loss: 0.4614 - val_acc: 0.8329\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4378 - acc: 0.8469 - val_loss: 0.4218 - val_acc: 0.8618\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4329 - acc: 0.8554 - val_loss: 0.3988 - val_acc: 0.8669\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4297 - acc: 0.8580 - val_loss: 0.4356 - val_acc: 0.8458\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4276 - acc: 0.8549 - val_loss: 0.4677 - val_acc: 0.8252\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4228 - acc: 0.8578 - val_loss: 0.4379 - val_acc: 0.8489\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4188 - acc: 0.8605 - val_loss: 0.4057 - val_acc: 0.8628\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4168 - acc: 0.8614 - val_loss: 0.3928 - val_acc: 0.8685\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4110 - acc: 0.8641 - val_loss: 0.4154 - val_acc: 0.8571\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4081 - acc: 0.8629 - val_loss: 0.3912 - val_acc: 0.8685\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 5s 77ms/step - loss: 0.4043 - acc: 0.8678 - val_loss: 0.3879 - val_acc: 0.8716\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.4015 - acc: 0.8690 - val_loss: 0.3855 - val_acc: 0.8726\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3969 - acc: 0.8725 - val_loss: 0.3986 - val_acc: 0.8654\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3930 - acc: 0.8725 - val_loss: 0.3851 - val_acc: 0.8695\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3915 - acc: 0.8712 - val_loss: 0.3787 - val_acc: 0.8716\n",
            "With LSTM_units = 64, dense_layer = 1, dense_activation = sigmoid, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 88ms/step - loss: 0.6989 - acc: 0.2557 - val_loss: 0.6899 - val_acc: 0.2455\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6962 - acc: 0.2401 - val_loss: 0.6925 - val_acc: 0.2419\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6948 - acc: 0.2337 - val_loss: 0.6939 - val_acc: 0.2352\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6939 - acc: 0.2210 - val_loss: 0.6954 - val_acc: 0.2238\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6933 - acc: 0.2178 - val_loss: 0.6959 - val_acc: 0.2182\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6927 - acc: 0.5354 - val_loss: 0.6954 - val_acc: 0.7256\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 64, dense_layer = 1, dense_activation = sigmoid, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 89ms/step - loss: 0.6938 - acc: 0.7511 - val_loss: 0.6944 - val_acc: 0.7478\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6928 - acc: 0.7545 - val_loss: 0.6942 - val_acc: 0.7473\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6918 - acc: 0.7569 - val_loss: 0.6937 - val_acc: 0.7442\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6907 - acc: 0.7532 - val_loss: 0.6935 - val_acc: 0.7380\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6892 - acc: 0.7501 - val_loss: 0.6920 - val_acc: 0.7349\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.6865 - acc: 0.7453 - val_loss: 0.6936 - val_acc: 0.7143\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6581 - acc: 0.6449 - val_loss: 0.6711 - val_acc: 0.7808\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.5772 - acc: 0.7914 - val_loss: 0.6483 - val_acc: 0.7855\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.5296 - acc: 0.8128 - val_loss: 0.5451 - val_acc: 0.8298\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.5009 - acc: 0.8201 - val_loss: 0.4893 - val_acc: 0.8386\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.4814 - acc: 0.8222 - val_loss: 0.4202 - val_acc: 0.8659\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4747 - acc: 0.8277 - val_loss: 0.4448 - val_acc: 0.8406\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4597 - acc: 0.8312 - val_loss: 0.4462 - val_acc: 0.8319\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4527 - acc: 0.8309 - val_loss: 0.4735 - val_acc: 0.8051\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4440 - acc: 0.8331 - val_loss: 0.4183 - val_acc: 0.8422\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4370 - acc: 0.8322 - val_loss: 0.3931 - val_acc: 0.8613\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4309 - acc: 0.8360 - val_loss: 0.4034 - val_acc: 0.8484\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4245 - acc: 0.8330 - val_loss: 0.4034 - val_acc: 0.8463\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4169 - acc: 0.8410 - val_loss: 0.3869 - val_acc: 0.8535\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4115 - acc: 0.8418 - val_loss: 0.3875 - val_acc: 0.8535\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4052 - acc: 0.8415 - val_loss: 0.3604 - val_acc: 0.8695\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4001 - acc: 0.8438 - val_loss: 0.3842 - val_acc: 0.8494\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3938 - acc: 0.8435 - val_loss: 0.3698 - val_acc: 0.8540\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3887 - acc: 0.8473 - val_loss: 0.3676 - val_acc: 0.8520\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3832 - acc: 0.8428 - val_loss: 0.3839 - val_acc: 0.8412\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3745 - acc: 0.8480 - val_loss: 0.3691 - val_acc: 0.8468\n",
            "Epoch 26: early stopping\n",
            "With LSTM_units = 64, dense_layer = 1, dense_activation = sigmoid, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 89ms/step - loss: 0.6946 - acc: 0.3262 - val_loss: 0.6956 - val_acc: 0.7349\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6936 - acc: 0.2380 - val_loss: 0.6953 - val_acc: 0.7323\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6928 - acc: 0.7478 - val_loss: 0.6953 - val_acc: 0.7349\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6919 - acc: 0.7448 - val_loss: 0.6944 - val_acc: 0.7354\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6908 - acc: 0.7562 - val_loss: 0.6931 - val_acc: 0.7318\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6892 - acc: 0.7403 - val_loss: 0.6936 - val_acc: 0.7225\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6802 - acc: 0.6660 - val_loss: 0.7330 - val_acc: 0.4972\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.5552 - acc: 0.7660 - val_loss: 0.5762 - val_acc: 0.8293\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4958 - acc: 0.8352 - val_loss: 0.4945 - val_acc: 0.8587\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4746 - acc: 0.8392 - val_loss: 0.5164 - val_acc: 0.8159\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4620 - acc: 0.8418 - val_loss: 0.4390 - val_acc: 0.8628\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4494 - acc: 0.8398 - val_loss: 0.4371 - val_acc: 0.8525\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4339 - acc: 0.8401 - val_loss: 0.3973 - val_acc: 0.8721\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4227 - acc: 0.8462 - val_loss: 0.3817 - val_acc: 0.8757\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4117 - acc: 0.8509 - val_loss: 0.3705 - val_acc: 0.8793\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4051 - acc: 0.8520 - val_loss: 0.3730 - val_acc: 0.8752\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3977 - acc: 0.8504 - val_loss: 0.3560 - val_acc: 0.8829\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3889 - acc: 0.8560 - val_loss: 0.3664 - val_acc: 0.8690\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.3842 - acc: 0.8547 - val_loss: 0.3528 - val_acc: 0.8783\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.3799 - acc: 0.8573 - val_loss: 0.3517 - val_acc: 0.8767\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3741 - acc: 0.8575 - val_loss: 0.3515 - val_acc: 0.8711\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3688 - acc: 0.8601 - val_loss: 0.3862 - val_acc: 0.8479\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3695 - acc: 0.8564 - val_loss: 0.3391 - val_acc: 0.8757\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3588 - acc: 0.8614 - val_loss: 0.3412 - val_acc: 0.8726\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3524 - acc: 0.8640 - val_loss: 0.3304 - val_acc: 0.8762\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3465 - acc: 0.8654 - val_loss: 0.3283 - val_acc: 0.8736\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3411 - acc: 0.8662 - val_loss: 0.3285 - val_acc: 0.8742\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.3360 - acc: 0.8700 - val_loss: 0.3233 - val_acc: 0.8721\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.3325 - acc: 0.8704 - val_loss: 0.3423 - val_acc: 0.8628\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3278 - acc: 0.8700 - val_loss: 0.3489 - val_acc: 0.8618\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3225 - acc: 0.8703 - val_loss: 0.3224 - val_acc: 0.8700\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3195 - acc: 0.8694 - val_loss: 0.3305 - val_acc: 0.8638\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3153 - acc: 0.8741 - val_loss: 0.3358 - val_acc: 0.8613\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3146 - acc: 0.8692 - val_loss: 0.3131 - val_acc: 0.8747\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3093 - acc: 0.8740 - val_loss: 0.2791 - val_acc: 0.8927\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3046 - acc: 0.8784 - val_loss: 0.2835 - val_acc: 0.8901\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.2999 - acc: 0.8812 - val_loss: 0.3011 - val_acc: 0.8783\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3005 - acc: 0.8798 - val_loss: 0.3217 - val_acc: 0.8633\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.2949 - acc: 0.8842 - val_loss: 0.3269 - val_acc: 0.8644\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.2915 - acc: 0.8824 - val_loss: 0.2900 - val_acc: 0.8871\n",
            "Epoch 40: early stopping\n",
            "With LSTM_units = 64, dense_layer = 1, dense_activation = sigmoid, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 8s 88ms/step - loss: 0.6945 - acc: 0.7587 - val_loss: 0.6920 - val_acc: 0.7437\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6942 - acc: 0.5364 - val_loss: 0.6927 - val_acc: 0.7091\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6939 - acc: 0.7509 - val_loss: 0.6930 - val_acc: 0.7344\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.6937 - acc: 0.7518 - val_loss: 0.6934 - val_acc: 0.7359\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.6934 - acc: 0.7425 - val_loss: 0.6937 - val_acc: 0.7334\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.6932 - acc: 0.7473 - val_loss: 0.6938 - val_acc: 0.7339\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 64, dense_layer = 10, dense_activation = relu, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 92ms/step - loss: 0.6985 - acc: 0.3126 - val_loss: 0.6890 - val_acc: 0.2656\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6977 - acc: 0.2542 - val_loss: 0.6898 - val_acc: 0.2625\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6970 - acc: 0.2513 - val_loss: 0.6907 - val_acc: 0.2548\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6965 - acc: 0.2493 - val_loss: 0.6914 - val_acc: 0.2465\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6960 - acc: 0.2433 - val_loss: 0.6924 - val_acc: 0.2378\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6955 - acc: 0.2397 - val_loss: 0.6930 - val_acc: 0.2326\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 64, dense_layer = 10, dense_activation = relu, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 88ms/step - loss: 0.6942 - acc: 0.2224 - val_loss: 0.6966 - val_acc: 0.2285\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6935 - acc: 0.7230 - val_loss: 0.6966 - val_acc: 0.7390\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6928 - acc: 0.7497 - val_loss: 0.6965 - val_acc: 0.7303\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6922 - acc: 0.7434 - val_loss: 0.6957 - val_acc: 0.7323\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6914 - acc: 0.7465 - val_loss: 0.6954 - val_acc: 0.7334\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6906 - acc: 0.7451 - val_loss: 0.6934 - val_acc: 0.7380\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6895 - acc: 0.7488 - val_loss: 0.6931 - val_acc: 0.7339\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6879 - acc: 0.7420 - val_loss: 0.6918 - val_acc: 0.7318\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6841 - acc: 0.7320 - val_loss: 0.6946 - val_acc: 0.6808\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6333 - acc: 0.6558 - val_loss: 0.6041 - val_acc: 0.8097\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.5228 - acc: 0.8054 - val_loss: 0.5058 - val_acc: 0.8427\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4859 - acc: 0.8255 - val_loss: 0.5264 - val_acc: 0.8061\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4672 - acc: 0.8175 - val_loss: 0.4086 - val_acc: 0.8654\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4547 - acc: 0.8291 - val_loss: 0.3988 - val_acc: 0.8675\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4439 - acc: 0.8306 - val_loss: 0.4293 - val_acc: 0.8319\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4336 - acc: 0.8253 - val_loss: 0.4039 - val_acc: 0.8432\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4257 - acc: 0.8313 - val_loss: 0.4256 - val_acc: 0.8288\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4170 - acc: 0.8361 - val_loss: 0.4252 - val_acc: 0.8252\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4095 - acc: 0.8342 - val_loss: 0.3864 - val_acc: 0.8432\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4049 - acc: 0.8352 - val_loss: 0.4212 - val_acc: 0.8210\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3969 - acc: 0.8329 - val_loss: 0.3600 - val_acc: 0.8613\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3913 - acc: 0.8316 - val_loss: 0.3668 - val_acc: 0.8566\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3831 - acc: 0.8366 - val_loss: 0.3513 - val_acc: 0.8649\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.3796 - acc: 0.8431 - val_loss: 0.3865 - val_acc: 0.8386\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.3739 - acc: 0.8420 - val_loss: 0.3440 - val_acc: 0.8685\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.3735 - acc: 0.8417 - val_loss: 0.3339 - val_acc: 0.8664\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3666 - acc: 0.8487 - val_loss: 0.3290 - val_acc: 0.8736\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.3637 - acc: 0.8493 - val_loss: 0.3509 - val_acc: 0.8597\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3586 - acc: 0.8515 - val_loss: 0.3488 - val_acc: 0.8592\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3554 - acc: 0.8517 - val_loss: 0.3557 - val_acc: 0.8551\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3518 - acc: 0.8567 - val_loss: 0.3627 - val_acc: 0.8530\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.3480 - acc: 0.8535 - val_loss: 0.3242 - val_acc: 0.8773\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3459 - acc: 0.8567 - val_loss: 0.3212 - val_acc: 0.8773\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.3450 - acc: 0.8600 - val_loss: 0.3858 - val_acc: 0.8329\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.3429 - acc: 0.8576 - val_loss: 0.3881 - val_acc: 0.8308\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3389 - acc: 0.8571 - val_loss: 0.3190 - val_acc: 0.8762\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3350 - acc: 0.8643 - val_loss: 0.3311 - val_acc: 0.8690\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3346 - acc: 0.8593 - val_loss: 0.3127 - val_acc: 0.8778\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3305 - acc: 0.8669 - val_loss: 0.3145 - val_acc: 0.8793\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.3296 - acc: 0.8642 - val_loss: 0.3039 - val_acc: 0.8834\n",
            "With LSTM_units = 64, dense_layer = 10, dense_activation = relu, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 86ms/step - loss: 0.6960 - acc: 0.7502 - val_loss: 0.6973 - val_acc: 0.7483\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6953 - acc: 0.7501 - val_loss: 0.6969 - val_acc: 0.7406\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6947 - acc: 0.7511 - val_loss: 0.6966 - val_acc: 0.7401\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6941 - acc: 0.7505 - val_loss: 0.6964 - val_acc: 0.7349\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6934 - acc: 0.7464 - val_loss: 0.6955 - val_acc: 0.7334\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6927 - acc: 0.7438 - val_loss: 0.6948 - val_acc: 0.7298\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6918 - acc: 0.7362 - val_loss: 0.6948 - val_acc: 0.7246\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6907 - acc: 0.7320 - val_loss: 0.6944 - val_acc: 0.7189\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6890 - acc: 0.7226 - val_loss: 0.6940 - val_acc: 0.7076\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6854 - acc: 0.7030 - val_loss: 0.6990 - val_acc: 0.6395\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6699 - acc: 0.5598 - val_loss: 0.6823 - val_acc: 0.6390\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.5756 - acc: 0.7417 - val_loss: 0.5849 - val_acc: 0.7953\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.5193 - acc: 0.8061 - val_loss: 0.5348 - val_acc: 0.8252\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4974 - acc: 0.8246 - val_loss: 0.4508 - val_acc: 0.8644\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4902 - acc: 0.8251 - val_loss: 0.4758 - val_acc: 0.8453\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 89ms/step - loss: 0.4757 - acc: 0.8221 - val_loss: 0.4261 - val_acc: 0.8685\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 89ms/step - loss: 0.4632 - acc: 0.8322 - val_loss: 0.4929 - val_acc: 0.8107\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 89ms/step - loss: 0.4582 - acc: 0.8285 - val_loss: 0.4753 - val_acc: 0.8143\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.4499 - acc: 0.8316 - val_loss: 0.4219 - val_acc: 0.8561\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4432 - acc: 0.8413 - val_loss: 0.4676 - val_acc: 0.8190\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.4465 - acc: 0.8281 - val_loss: 0.4265 - val_acc: 0.8432\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4333 - acc: 0.8420 - val_loss: 0.3916 - val_acc: 0.8680\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4285 - acc: 0.8447 - val_loss: 0.4155 - val_acc: 0.8468\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4258 - acc: 0.8480 - val_loss: 0.3919 - val_acc: 0.8649\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4219 - acc: 0.8496 - val_loss: 0.3914 - val_acc: 0.8638\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4184 - acc: 0.8493 - val_loss: 0.3905 - val_acc: 0.8644\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4150 - acc: 0.8553 - val_loss: 0.4135 - val_acc: 0.8442\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.4119 - acc: 0.8538 - val_loss: 0.3835 - val_acc: 0.8649\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4090 - acc: 0.8554 - val_loss: 0.3917 - val_acc: 0.8566\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4078 - acc: 0.8525 - val_loss: 0.3838 - val_acc: 0.8664\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4045 - acc: 0.8575 - val_loss: 0.3897 - val_acc: 0.8571\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4015 - acc: 0.8616 - val_loss: 0.4185 - val_acc: 0.8401\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.3998 - acc: 0.8553 - val_loss: 0.3763 - val_acc: 0.8695\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3977 - acc: 0.8591 - val_loss: 0.3707 - val_acc: 0.8726\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3974 - acc: 0.8619 - val_loss: 0.4137 - val_acc: 0.8412\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3933 - acc: 0.8609 - val_loss: 0.3623 - val_acc: 0.8793\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3902 - acc: 0.8607 - val_loss: 0.3733 - val_acc: 0.8685\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3879 - acc: 0.8601 - val_loss: 0.3517 - val_acc: 0.8819\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3834 - acc: 0.8664 - val_loss: 0.3612 - val_acc: 0.8742\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3815 - acc: 0.8640 - val_loss: 0.3770 - val_acc: 0.8633\n",
            "With LSTM_units = 64, dense_layer = 10, dense_activation = relu, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 91ms/step - loss: 0.6949 - acc: 0.2686 - val_loss: 0.6953 - val_acc: 0.7612\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6939 - acc: 0.6166 - val_loss: 0.6958 - val_acc: 0.7509\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6929 - acc: 0.7533 - val_loss: 0.6947 - val_acc: 0.7509\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6919 - acc: 0.7572 - val_loss: 0.6937 - val_acc: 0.7478\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6907 - acc: 0.7513 - val_loss: 0.6930 - val_acc: 0.7390\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6893 - acc: 0.7574 - val_loss: 0.6920 - val_acc: 0.7251\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6863 - acc: 0.7404 - val_loss: 0.6889 - val_acc: 0.7194\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6402 - acc: 0.6722 - val_loss: 0.6042 - val_acc: 0.7958\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.5112 - acc: 0.8028 - val_loss: 0.5000 - val_acc: 0.8293\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.4678 - acc: 0.8181 - val_loss: 0.4515 - val_acc: 0.8375\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.4453 - acc: 0.8202 - val_loss: 0.4249 - val_acc: 0.8422\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4286 - acc: 0.8272 - val_loss: 0.4003 - val_acc: 0.8535\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4156 - acc: 0.8358 - val_loss: 0.3924 - val_acc: 0.8504\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4063 - acc: 0.8409 - val_loss: 0.3792 - val_acc: 0.8566\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3990 - acc: 0.8414 - val_loss: 0.3827 - val_acc: 0.8504\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3948 - acc: 0.8441 - val_loss: 0.3473 - val_acc: 0.8721\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3868 - acc: 0.8469 - val_loss: 0.3564 - val_acc: 0.8659\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3807 - acc: 0.8496 - val_loss: 0.3623 - val_acc: 0.8675\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.3746 - acc: 0.8522 - val_loss: 0.3688 - val_acc: 0.8525\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3655 - acc: 0.8547 - val_loss: 0.3997 - val_acc: 0.8288\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.3601 - acc: 0.8485 - val_loss: 0.3865 - val_acc: 0.8345\n",
            "Epoch 21: early stopping\n",
            "With LSTM_units = 64, dense_layer = 10, dense_activation = relu, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 8s 90ms/step - loss: 0.6950 - acc: 0.4557 - val_loss: 0.6974 - val_acc: 0.7530\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6940 - acc: 0.7586 - val_loss: 0.6955 - val_acc: 0.7540\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 77ms/step - loss: 0.6931 - acc: 0.7558 - val_loss: 0.6953 - val_acc: 0.7571\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6921 - acc: 0.7639 - val_loss: 0.6940 - val_acc: 0.7494\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6908 - acc: 0.7507 - val_loss: 0.6926 - val_acc: 0.7478\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6892 - acc: 0.7591 - val_loss: 0.6884 - val_acc: 0.7509\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6860 - acc: 0.7504 - val_loss: 0.6827 - val_acc: 0.7602\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6604 - acc: 0.7368 - val_loss: 0.6666 - val_acc: 0.7483\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.5312 - acc: 0.8058 - val_loss: 0.5783 - val_acc: 0.8076\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4866 - acc: 0.8227 - val_loss: 0.4975 - val_acc: 0.8319\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4666 - acc: 0.8370 - val_loss: 0.4670 - val_acc: 0.8386\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4572 - acc: 0.8414 - val_loss: 0.5026 - val_acc: 0.8128\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4508 - acc: 0.8414 - val_loss: 0.4372 - val_acc: 0.8525\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4421 - acc: 0.8486 - val_loss: 0.4264 - val_acc: 0.8551\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4342 - acc: 0.8505 - val_loss: 0.4337 - val_acc: 0.8453\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.4292 - acc: 0.8536 - val_loss: 0.4228 - val_acc: 0.8530\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 90ms/step - loss: 0.4222 - acc: 0.8544 - val_loss: 0.3963 - val_acc: 0.8644\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 6s 91ms/step - loss: 0.4158 - acc: 0.8605 - val_loss: 0.3978 - val_acc: 0.8613\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.4132 - acc: 0.8594 - val_loss: 0.3898 - val_acc: 0.8669\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4062 - acc: 0.8662 - val_loss: 0.3801 - val_acc: 0.8716\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.4003 - acc: 0.8634 - val_loss: 0.3930 - val_acc: 0.8654\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3980 - acc: 0.8652 - val_loss: 0.3668 - val_acc: 0.8798\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.3920 - acc: 0.8701 - val_loss: 0.3717 - val_acc: 0.8752\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.3854 - acc: 0.8705 - val_loss: 0.3651 - val_acc: 0.8773\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.3831 - acc: 0.8703 - val_loss: 0.3679 - val_acc: 0.8716\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 89ms/step - loss: 0.3770 - acc: 0.8731 - val_loss: 0.3284 - val_acc: 0.8938\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.3761 - acc: 0.8723 - val_loss: 0.3776 - val_acc: 0.8685\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.3692 - acc: 0.8780 - val_loss: 0.3482 - val_acc: 0.8819\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3652 - acc: 0.8767 - val_loss: 0.3614 - val_acc: 0.8742\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.3609 - acc: 0.8816 - val_loss: 0.3740 - val_acc: 0.8680\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.3564 - acc: 0.8829 - val_loss: 0.3312 - val_acc: 0.8938\n",
            "Epoch 31: early stopping\n",
            "With LSTM_units = 64, dense_layer = 10, dense_activation = relu, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 8s 95ms/step - loss: 0.6961 - acc: 0.4411 - val_loss: 0.6894 - val_acc: 0.2888\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.6954 - acc: 0.4271 - val_loss: 0.6904 - val_acc: 0.2800\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6947 - acc: 0.2512 - val_loss: 0.6915 - val_acc: 0.2439\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.6943 - acc: 0.4037 - val_loss: 0.6921 - val_acc: 0.2682\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.6939 - acc: 0.5369 - val_loss: 0.6927 - val_acc: 0.7561\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.6935 - acc: 0.6750 - val_loss: 0.6935 - val_acc: 0.7447\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 64, dense_layer = 10, dense_activation = sigmoid, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 8s 94ms/step - loss: 0.6947 - acc: 0.7492 - val_loss: 0.6989 - val_acc: 0.7514\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.6945 - acc: 0.7532 - val_loss: 0.6986 - val_acc: 0.7519\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6943 - acc: 0.7524 - val_loss: 0.6984 - val_acc: 0.7483\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 89ms/step - loss: 0.6941 - acc: 0.7528 - val_loss: 0.6979 - val_acc: 0.7468\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6939 - acc: 0.7536 - val_loss: 0.6977 - val_acc: 0.7488\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.6937 - acc: 0.7540 - val_loss: 0.6973 - val_acc: 0.7478\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.6935 - acc: 0.7527 - val_loss: 0.6973 - val_acc: 0.7463\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6933 - acc: 0.7534 - val_loss: 0.6970 - val_acc: 0.7457\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.6931 - acc: 0.7544 - val_loss: 0.6967 - val_acc: 0.7457\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.6929 - acc: 0.7550 - val_loss: 0.6966 - val_acc: 0.7457\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.6927 - acc: 0.7546 - val_loss: 0.6960 - val_acc: 0.7463\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6925 - acc: 0.7549 - val_loss: 0.6955 - val_acc: 0.7463\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6923 - acc: 0.7547 - val_loss: 0.6957 - val_acc: 0.7457\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.6920 - acc: 0.7540 - val_loss: 0.6953 - val_acc: 0.7432\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.6918 - acc: 0.7534 - val_loss: 0.6953 - val_acc: 0.7396\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 90ms/step - loss: 0.6915 - acc: 0.7525 - val_loss: 0.6947 - val_acc: 0.7380\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6913 - acc: 0.7527 - val_loss: 0.6947 - val_acc: 0.7370\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.6910 - acc: 0.7527 - val_loss: 0.6941 - val_acc: 0.7339\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.6906 - acc: 0.7507 - val_loss: 0.6936 - val_acc: 0.7349\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.6903 - acc: 0.7505 - val_loss: 0.6935 - val_acc: 0.7329\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.6899 - acc: 0.7495 - val_loss: 0.6935 - val_acc: 0.7303\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.6895 - acc: 0.7479 - val_loss: 0.6930 - val_acc: 0.7303\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.6890 - acc: 0.7456 - val_loss: 0.6924 - val_acc: 0.7292\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6884 - acc: 0.7426 - val_loss: 0.6926 - val_acc: 0.7256\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.6876 - acc: 0.7381 - val_loss: 0.6923 - val_acc: 0.7277\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.6867 - acc: 0.7327 - val_loss: 0.6918 - val_acc: 0.7143\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6851 - acc: 0.7273 - val_loss: 0.6917 - val_acc: 0.7060\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.6823 - acc: 0.7149 - val_loss: 0.6924 - val_acc: 0.6849\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6749 - acc: 0.6460 - val_loss: 0.6998 - val_acc: 0.5859\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.6376 - acc: 0.6107 - val_loss: 0.6363 - val_acc: 0.7375\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.5688 - acc: 0.7493 - val_loss: 0.6258 - val_acc: 0.7535\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.5410 - acc: 0.7767 - val_loss: 0.5322 - val_acc: 0.8247\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.5268 - acc: 0.7973 - val_loss: 0.5487 - val_acc: 0.8030\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.5153 - acc: 0.8015 - val_loss: 0.5257 - val_acc: 0.8118\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.5065 - acc: 0.8054 - val_loss: 0.5025 - val_acc: 0.8241\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.4985 - acc: 0.8126 - val_loss: 0.4938 - val_acc: 0.8262\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.4925 - acc: 0.8177 - val_loss: 0.4804 - val_acc: 0.8381\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 6s 91ms/step - loss: 0.4861 - acc: 0.8192 - val_loss: 0.4586 - val_acc: 0.8489\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 6s 91ms/step - loss: 0.4817 - acc: 0.8184 - val_loss: 0.4590 - val_acc: 0.8453\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.4771 - acc: 0.8233 - val_loss: 0.4639 - val_acc: 0.8360\n",
            "With LSTM_units = 64, dense_layer = 10, dense_activation = sigmoid, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 8s 94ms/step - loss: 0.6945 - acc: 0.4718 - val_loss: 0.6940 - val_acc: 0.7282\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.6935 - acc: 0.5863 - val_loss: 0.6945 - val_acc: 0.7277\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6928 - acc: 0.7335 - val_loss: 0.6960 - val_acc: 0.7215\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.6921 - acc: 0.7411 - val_loss: 0.6954 - val_acc: 0.7261\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6914 - acc: 0.7420 - val_loss: 0.6957 - val_acc: 0.7251\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.6905 - acc: 0.7402 - val_loss: 0.6947 - val_acc: 0.7277\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 64, dense_layer = 10, dense_activation = sigmoid, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 8s 106ms/step - loss: 0.6943 - acc: 0.4918 - val_loss: 0.6965 - val_acc: 0.7225\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.6936 - acc: 0.7411 - val_loss: 0.6961 - val_acc: 0.7298\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6931 - acc: 0.7433 - val_loss: 0.6946 - val_acc: 0.7375\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.6925 - acc: 0.7435 - val_loss: 0.6945 - val_acc: 0.7287\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.6918 - acc: 0.7416 - val_loss: 0.6938 - val_acc: 0.7292\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6911 - acc: 0.7436 - val_loss: 0.6933 - val_acc: 0.7298\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.6902 - acc: 0.7440 - val_loss: 0.6920 - val_acc: 0.7334\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6893 - acc: 0.7431 - val_loss: 0.6922 - val_acc: 0.7318\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.6878 - acc: 0.7360 - val_loss: 0.6924 - val_acc: 0.7205\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.6850 - acc: 0.7280 - val_loss: 0.6927 - val_acc: 0.6926\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6765 - acc: 0.5937 - val_loss: 0.7178 - val_acc: 0.5111\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6198 - acc: 0.6384 - val_loss: 0.6010 - val_acc: 0.8009\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.5214 - acc: 0.8250 - val_loss: 0.5179 - val_acc: 0.8566\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.4940 - acc: 0.8456 - val_loss: 0.4902 - val_acc: 0.8608\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.4781 - acc: 0.8489 - val_loss: 0.4741 - val_acc: 0.8592\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.4675 - acc: 0.8496 - val_loss: 0.4568 - val_acc: 0.8638\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4601 - acc: 0.8533 - val_loss: 0.4313 - val_acc: 0.8685\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.4570 - acc: 0.8505 - val_loss: 0.4284 - val_acc: 0.8680\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.4485 - acc: 0.8460 - val_loss: 0.4054 - val_acc: 0.8706\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.4433 - acc: 0.8516 - val_loss: 0.4272 - val_acc: 0.8566\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.4372 - acc: 0.8502 - val_loss: 0.3920 - val_acc: 0.8814\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.4302 - acc: 0.8486 - val_loss: 0.4304 - val_acc: 0.8463\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.4274 - acc: 0.8542 - val_loss: 0.4140 - val_acc: 0.8525\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.4202 - acc: 0.8524 - val_loss: 0.3757 - val_acc: 0.8783\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4161 - acc: 0.8575 - val_loss: 0.3831 - val_acc: 0.8706\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.4119 - acc: 0.8574 - val_loss: 0.3787 - val_acc: 0.8700\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4076 - acc: 0.8585 - val_loss: 0.3882 - val_acc: 0.8628\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.4052 - acc: 0.8588 - val_loss: 0.3752 - val_acc: 0.8706\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.4008 - acc: 0.8615 - val_loss: 0.3641 - val_acc: 0.8762\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.3985 - acc: 0.8638 - val_loss: 0.3622 - val_acc: 0.8778\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.3946 - acc: 0.8638 - val_loss: 0.3680 - val_acc: 0.8767\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3927 - acc: 0.8672 - val_loss: 0.3837 - val_acc: 0.8644\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.3897 - acc: 0.8656 - val_loss: 0.3898 - val_acc: 0.8592\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3862 - acc: 0.8640 - val_loss: 0.3463 - val_acc: 0.8860\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.3842 - acc: 0.8708 - val_loss: 0.3787 - val_acc: 0.8628\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.3829 - acc: 0.8682 - val_loss: 0.3496 - val_acc: 0.8855\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3791 - acc: 0.8691 - val_loss: 0.3772 - val_acc: 0.8613\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.3760 - acc: 0.8711 - val_loss: 0.3858 - val_acc: 0.8577\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3746 - acc: 0.8668 - val_loss: 0.3603 - val_acc: 0.8695\n",
            "Epoch 39: early stopping\n",
            "With LSTM_units = 64, dense_layer = 10, dense_activation = sigmoid, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 8s 97ms/step - loss: 0.6972 - acc: 0.2662 - val_loss: 0.6938 - val_acc: 0.2316\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6950 - acc: 0.4815 - val_loss: 0.6946 - val_acc: 0.7272\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.6939 - acc: 0.7194 - val_loss: 0.6966 - val_acc: 0.7225\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6929 - acc: 0.7295 - val_loss: 0.6957 - val_acc: 0.7261\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6916 - acc: 0.7324 - val_loss: 0.6948 - val_acc: 0.7179\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.6893 - acc: 0.7153 - val_loss: 0.6964 - val_acc: 0.6741\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 64, dense_layer = 10, dense_activation = sigmoid, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 8s 92ms/step - loss: 0.6942 - acc: 0.6687 - val_loss: 0.6971 - val_acc: 0.7447\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6929 - acc: 0.7565 - val_loss: 0.6954 - val_acc: 0.7385\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6916 - acc: 0.7505 - val_loss: 0.6943 - val_acc: 0.7349\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 89ms/step - loss: 0.6902 - acc: 0.7516 - val_loss: 0.6934 - val_acc: 0.7334\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.6884 - acc: 0.7447 - val_loss: 0.6917 - val_acc: 0.7344\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 89ms/step - loss: 0.6846 - acc: 0.7395 - val_loss: 0.6928 - val_acc: 0.7029\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6501 - acc: 0.6333 - val_loss: 0.6748 - val_acc: 0.7215\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.5542 - acc: 0.7884 - val_loss: 0.5485 - val_acc: 0.8257\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.5084 - acc: 0.8184 - val_loss: 0.5262 - val_acc: 0.8231\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.4789 - acc: 0.8196 - val_loss: 0.4540 - val_acc: 0.8396\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.4569 - acc: 0.8226 - val_loss: 0.4528 - val_acc: 0.8267\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.4391 - acc: 0.8342 - val_loss: 0.4451 - val_acc: 0.8195\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.4280 - acc: 0.8330 - val_loss: 0.4450 - val_acc: 0.8200\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.4166 - acc: 0.8386 - val_loss: 0.4047 - val_acc: 0.8386\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.4082 - acc: 0.8423 - val_loss: 0.3822 - val_acc: 0.8489\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.4024 - acc: 0.8462 - val_loss: 0.3737 - val_acc: 0.8546\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.3959 - acc: 0.8491 - val_loss: 0.3658 - val_acc: 0.8602\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.3888 - acc: 0.8516 - val_loss: 0.3789 - val_acc: 0.8484\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3851 - acc: 0.8554 - val_loss: 0.3999 - val_acc: 0.8381\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.3804 - acc: 0.8536 - val_loss: 0.3514 - val_acc: 0.8628\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.3751 - acc: 0.8575 - val_loss: 0.3595 - val_acc: 0.8587\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3697 - acc: 0.8609 - val_loss: 0.3781 - val_acc: 0.8520\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.3669 - acc: 0.8578 - val_loss: 0.3340 - val_acc: 0.8752\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3615 - acc: 0.8619 - val_loss: 0.3530 - val_acc: 0.8623\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.3560 - acc: 0.8627 - val_loss: 0.3486 - val_acc: 0.8664\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3511 - acc: 0.8656 - val_loss: 0.3339 - val_acc: 0.8685\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3479 - acc: 0.8682 - val_loss: 0.3846 - val_acc: 0.8417\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3438 - acc: 0.8629 - val_loss: 0.3079 - val_acc: 0.8865\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3397 - acc: 0.8631 - val_loss: 0.3242 - val_acc: 0.8742\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.3345 - acc: 0.8683 - val_loss: 0.3362 - val_acc: 0.8685\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3307 - acc: 0.8690 - val_loss: 0.3247 - val_acc: 0.8752\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3246 - acc: 0.8707 - val_loss: 0.3092 - val_acc: 0.8804\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3207 - acc: 0.8740 - val_loss: 0.3293 - val_acc: 0.8623\n",
            "Epoch 33: early stopping\n",
            "With LSTM_units = 64, dense_layer = 10, dense_activation = sigmoid, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 8s 93ms/step - loss: 0.6961 - acc: 0.7357 - val_loss: 0.6979 - val_acc: 0.7416\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6958 - acc: 0.7471 - val_loss: 0.6979 - val_acc: 0.7396\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6956 - acc: 0.7484 - val_loss: 0.6976 - val_acc: 0.7406\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.6954 - acc: 0.7500 - val_loss: 0.6975 - val_acc: 0.7427\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6952 - acc: 0.7510 - val_loss: 0.6973 - val_acc: 0.7427\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.6950 - acc: 0.7496 - val_loss: 0.6971 - val_acc: 0.7421\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6947 - acc: 0.7502 - val_loss: 0.6970 - val_acc: 0.7416\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6946 - acc: 0.7471 - val_loss: 0.6970 - val_acc: 0.7390\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.6943 - acc: 0.7492 - val_loss: 0.6965 - val_acc: 0.7421\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6941 - acc: 0.7520 - val_loss: 0.6961 - val_acc: 0.7427\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6939 - acc: 0.7506 - val_loss: 0.6962 - val_acc: 0.7406\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6937 - acc: 0.7513 - val_loss: 0.6961 - val_acc: 0.7390\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6935 - acc: 0.7509 - val_loss: 0.6959 - val_acc: 0.7375\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6933 - acc: 0.7522 - val_loss: 0.6955 - val_acc: 0.7385\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6931 - acc: 0.7511 - val_loss: 0.6954 - val_acc: 0.7349\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.6928 - acc: 0.7502 - val_loss: 0.6953 - val_acc: 0.7354\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6926 - acc: 0.7483 - val_loss: 0.6949 - val_acc: 0.7380\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.6924 - acc: 0.7501 - val_loss: 0.6947 - val_acc: 0.7359\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6922 - acc: 0.7505 - val_loss: 0.6941 - val_acc: 0.7380\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6919 - acc: 0.7498 - val_loss: 0.6942 - val_acc: 0.7354\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.6917 - acc: 0.7485 - val_loss: 0.6939 - val_acc: 0.7339\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6914 - acc: 0.7482 - val_loss: 0.6940 - val_acc: 0.7313\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.6911 - acc: 0.7475 - val_loss: 0.6937 - val_acc: 0.7313\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6908 - acc: 0.7465 - val_loss: 0.6934 - val_acc: 0.7308\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6905 - acc: 0.7456 - val_loss: 0.6934 - val_acc: 0.7292\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6902 - acc: 0.7430 - val_loss: 0.6931 - val_acc: 0.7287\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6898 - acc: 0.7425 - val_loss: 0.6928 - val_acc: 0.7287\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.6895 - acc: 0.7409 - val_loss: 0.6929 - val_acc: 0.7277\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6890 - acc: 0.7425 - val_loss: 0.6923 - val_acc: 0.7282\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.6885 - acc: 0.7389 - val_loss: 0.6919 - val_acc: 0.7277\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 5s 89ms/step - loss: 0.6879 - acc: 0.7384 - val_loss: 0.6916 - val_acc: 0.7251\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.6872 - acc: 0.7357 - val_loss: 0.6920 - val_acc: 0.7210\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.6864 - acc: 0.7286 - val_loss: 0.6921 - val_acc: 0.7169\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6852 - acc: 0.7248 - val_loss: 0.6922 - val_acc: 0.7055\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6835 - acc: 0.7051 - val_loss: 0.6947 - val_acc: 0.6782\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6805 - acc: 0.6642 - val_loss: 0.6990 - val_acc: 0.6178\n",
            "Epoch 36: early stopping\n",
            "With LSTM_units = 64, dense_layer = 50, dense_activation = relu, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 8s 92ms/step - loss: 0.6942 - acc: 0.2208 - val_loss: 0.6943 - val_acc: 0.2223\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6940 - acc: 0.2156 - val_loss: 0.6944 - val_acc: 0.2218\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6937 - acc: 0.2917 - val_loss: 0.6946 - val_acc: 0.7236\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6935 - acc: 0.7430 - val_loss: 0.6947 - val_acc: 0.7287\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.6933 - acc: 0.7443 - val_loss: 0.6949 - val_acc: 0.7292\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6931 - acc: 0.7471 - val_loss: 0.6948 - val_acc: 0.7344\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 64, dense_layer = 50, dense_activation = relu, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 8s 102ms/step - loss: 0.6970 - acc: 0.2447 - val_loss: 0.6921 - val_acc: 0.2414\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.6956 - acc: 0.2282 - val_loss: 0.6942 - val_acc: 0.2274\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6947 - acc: 0.4802 - val_loss: 0.6946 - val_acc: 0.7215\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6941 - acc: 0.3705 - val_loss: 0.6955 - val_acc: 0.7055\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6936 - acc: 0.7288 - val_loss: 0.6953 - val_acc: 0.7277\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6931 - acc: 0.7376 - val_loss: 0.6949 - val_acc: 0.7292\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 64, dense_layer = 50, dense_activation = relu, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 91ms/step - loss: 0.6944 - acc: 0.4464 - val_loss: 0.6941 - val_acc: 0.7494\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6935 - acc: 0.6197 - val_loss: 0.6950 - val_acc: 0.7375\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6928 - acc: 0.7522 - val_loss: 0.6952 - val_acc: 0.7437\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6922 - acc: 0.7544 - val_loss: 0.6956 - val_acc: 0.7411\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6916 - acc: 0.7541 - val_loss: 0.6944 - val_acc: 0.7437\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6909 - acc: 0.7578 - val_loss: 0.6931 - val_acc: 0.7468\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6902 - acc: 0.7568 - val_loss: 0.6926 - val_acc: 0.7452\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6892 - acc: 0.7580 - val_loss: 0.6923 - val_acc: 0.7365\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6880 - acc: 0.7558 - val_loss: 0.6914 - val_acc: 0.7370\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.6861 - acc: 0.7430 - val_loss: 0.6914 - val_acc: 0.7334\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6809 - acc: 0.7270 - val_loss: 0.6983 - val_acc: 0.6694\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6010 - acc: 0.6979 - val_loss: 0.5449 - val_acc: 0.8664\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.5237 - acc: 0.8275 - val_loss: 0.5278 - val_acc: 0.8499\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4912 - acc: 0.8375 - val_loss: 0.4930 - val_acc: 0.8504\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.4752 - acc: 0.8364 - val_loss: 0.4340 - val_acc: 0.8675\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4641 - acc: 0.8429 - val_loss: 0.4290 - val_acc: 0.8623\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4566 - acc: 0.8433 - val_loss: 0.4470 - val_acc: 0.8504\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4501 - acc: 0.8414 - val_loss: 0.4191 - val_acc: 0.8582\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4424 - acc: 0.8462 - val_loss: 0.3921 - val_acc: 0.8711\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4368 - acc: 0.8458 - val_loss: 0.4060 - val_acc: 0.8628\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4298 - acc: 0.8473 - val_loss: 0.4039 - val_acc: 0.8608\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.4245 - acc: 0.8513 - val_loss: 0.3861 - val_acc: 0.8680\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4202 - acc: 0.8495 - val_loss: 0.3667 - val_acc: 0.8762\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4134 - acc: 0.8513 - val_loss: 0.4057 - val_acc: 0.8479\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4106 - acc: 0.8481 - val_loss: 0.3724 - val_acc: 0.8711\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4036 - acc: 0.8526 - val_loss: 0.3846 - val_acc: 0.8577\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.3978 - acc: 0.8539 - val_loss: 0.3604 - val_acc: 0.8716\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3920 - acc: 0.8560 - val_loss: 0.3583 - val_acc: 0.8726\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3875 - acc: 0.8597 - val_loss: 0.4106 - val_acc: 0.8391\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3831 - acc: 0.8551 - val_loss: 0.3721 - val_acc: 0.8592\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3776 - acc: 0.8565 - val_loss: 0.3222 - val_acc: 0.8860\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3741 - acc: 0.8598 - val_loss: 0.3740 - val_acc: 0.8566\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3679 - acc: 0.8594 - val_loss: 0.3565 - val_acc: 0.8638\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3630 - acc: 0.8628 - val_loss: 0.3334 - val_acc: 0.8762\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3577 - acc: 0.8596 - val_loss: 0.3576 - val_acc: 0.8618\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3546 - acc: 0.8610 - val_loss: 0.3199 - val_acc: 0.8824\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3497 - acc: 0.8592 - val_loss: 0.3537 - val_acc: 0.8597\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3463 - acc: 0.8613 - val_loss: 0.3510 - val_acc: 0.8582\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3414 - acc: 0.8571 - val_loss: 0.3575 - val_acc: 0.8556\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3381 - acc: 0.8614 - val_loss: 0.3425 - val_acc: 0.8613\n",
            "With LSTM_units = 64, dense_layer = 50, dense_activation = relu, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 91ms/step - loss: 0.6946 - acc: 0.7513 - val_loss: 0.6937 - val_acc: 0.7339\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.6932 - acc: 0.7399 - val_loss: 0.6941 - val_acc: 0.7318\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 89ms/step - loss: 0.6923 - acc: 0.7420 - val_loss: 0.6942 - val_acc: 0.7303\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 89ms/step - loss: 0.6913 - acc: 0.7371 - val_loss: 0.6941 - val_acc: 0.7298\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.6899 - acc: 0.7397 - val_loss: 0.6929 - val_acc: 0.7215\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.6867 - acc: 0.7088 - val_loss: 0.6991 - val_acc: 0.6318\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.6661 - acc: 0.5375 - val_loss: 0.6513 - val_acc: 0.7065\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.5704 - acc: 0.7938 - val_loss: 0.5897 - val_acc: 0.7916\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.5393 - acc: 0.8080 - val_loss: 0.5245 - val_acc: 0.8298\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.5107 - acc: 0.8173 - val_loss: 0.4826 - val_acc: 0.8453\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.4914 - acc: 0.8251 - val_loss: 0.4280 - val_acc: 0.8680\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4762 - acc: 0.8218 - val_loss: 0.4583 - val_acc: 0.8360\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4594 - acc: 0.8294 - val_loss: 0.4412 - val_acc: 0.8386\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4497 - acc: 0.8289 - val_loss: 0.3940 - val_acc: 0.8664\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4423 - acc: 0.8369 - val_loss: 0.4087 - val_acc: 0.8566\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4330 - acc: 0.8454 - val_loss: 0.4063 - val_acc: 0.8556\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4229 - acc: 0.8458 - val_loss: 0.3849 - val_acc: 0.8644\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4175 - acc: 0.8458 - val_loss: 0.3704 - val_acc: 0.8726\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4086 - acc: 0.8498 - val_loss: 0.3687 - val_acc: 0.8716\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4048 - acc: 0.8516 - val_loss: 0.3552 - val_acc: 0.8762\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3976 - acc: 0.8543 - val_loss: 0.4374 - val_acc: 0.8241\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3921 - acc: 0.8518 - val_loss: 0.4152 - val_acc: 0.8355\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3840 - acc: 0.8463 - val_loss: 0.3833 - val_acc: 0.8432\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3722 - acc: 0.8530 - val_loss: 0.3226 - val_acc: 0.8809\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3662 - acc: 0.8525 - val_loss: 0.3367 - val_acc: 0.8685\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3613 - acc: 0.8487 - val_loss: 0.3215 - val_acc: 0.8742\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3543 - acc: 0.8502 - val_loss: 0.3287 - val_acc: 0.8664\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3539 - acc: 0.8560 - val_loss: 0.3746 - val_acc: 0.8288\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3454 - acc: 0.8513 - val_loss: 0.3625 - val_acc: 0.8334\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3388 - acc: 0.8544 - val_loss: 0.3129 - val_acc: 0.8690\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3336 - acc: 0.8566 - val_loss: 0.2973 - val_acc: 0.8793\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.3351 - acc: 0.8569 - val_loss: 0.2920 - val_acc: 0.8793\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3286 - acc: 0.8539 - val_loss: 0.3086 - val_acc: 0.8633\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3213 - acc: 0.8650 - val_loss: 0.2942 - val_acc: 0.8752\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3151 - acc: 0.8627 - val_loss: 0.2819 - val_acc: 0.8834\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3135 - acc: 0.8646 - val_loss: 0.3084 - val_acc: 0.8561\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3101 - acc: 0.8641 - val_loss: 0.3057 - val_acc: 0.8628\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3052 - acc: 0.8671 - val_loss: 0.3452 - val_acc: 0.8417\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3027 - acc: 0.8660 - val_loss: 0.3264 - val_acc: 0.8530\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.2979 - acc: 0.8716 - val_loss: 0.2910 - val_acc: 0.8726\n",
            "Epoch 40: early stopping\n",
            "With LSTM_units = 64, dense_layer = 50, dense_activation = relu, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 89ms/step - loss: 0.6942 - acc: 0.7382 - val_loss: 0.6958 - val_acc: 0.7375\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6932 - acc: 0.7406 - val_loss: 0.6951 - val_acc: 0.7339\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6923 - acc: 0.7467 - val_loss: 0.6942 - val_acc: 0.7334\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6911 - acc: 0.7453 - val_loss: 0.6921 - val_acc: 0.7313\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6898 - acc: 0.7434 - val_loss: 0.6911 - val_acc: 0.7339\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6876 - acc: 0.7284 - val_loss: 0.6922 - val_acc: 0.7112\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6789 - acc: 0.5645 - val_loss: 0.7035 - val_acc: 0.5358\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.5810 - acc: 0.7318 - val_loss: 0.6060 - val_acc: 0.7942\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.5172 - acc: 0.8061 - val_loss: 0.5203 - val_acc: 0.8345\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.4886 - acc: 0.8168 - val_loss: 0.4960 - val_acc: 0.8303\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4679 - acc: 0.8201 - val_loss: 0.4331 - val_acc: 0.8535\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4552 - acc: 0.8266 - val_loss: 0.4590 - val_acc: 0.8257\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4455 - acc: 0.8297 - val_loss: 0.4963 - val_acc: 0.7968\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4397 - acc: 0.8221 - val_loss: 0.4580 - val_acc: 0.8159\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4324 - acc: 0.8322 - val_loss: 0.3990 - val_acc: 0.8489\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4237 - acc: 0.8391 - val_loss: 0.4600 - val_acc: 0.8092\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4240 - acc: 0.8356 - val_loss: 0.3986 - val_acc: 0.8453\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4171 - acc: 0.8364 - val_loss: 0.3844 - val_acc: 0.8577\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4126 - acc: 0.8437 - val_loss: 0.3849 - val_acc: 0.8515\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4037 - acc: 0.8445 - val_loss: 0.3812 - val_acc: 0.8535\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3980 - acc: 0.8471 - val_loss: 0.3701 - val_acc: 0.8597\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3949 - acc: 0.8485 - val_loss: 0.3567 - val_acc: 0.8685\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3908 - acc: 0.8515 - val_loss: 0.3971 - val_acc: 0.8396\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.3852 - acc: 0.8517 - val_loss: 0.3652 - val_acc: 0.8602\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 88ms/step - loss: 0.3814 - acc: 0.8524 - val_loss: 0.3618 - val_acc: 0.8597\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3744 - acc: 0.8588 - val_loss: 0.3736 - val_acc: 0.8525\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3746 - acc: 0.8552 - val_loss: 0.3763 - val_acc: 0.8489\n",
            "Epoch 27: early stopping\n",
            "With LSTM_units = 64, dense_layer = 50, dense_activation = relu, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 89ms/step - loss: 0.6974 - acc: 0.7319 - val_loss: 0.7099 - val_acc: 0.7287\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6967 - acc: 0.7394 - val_loss: 0.7076 - val_acc: 0.7329\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6961 - acc: 0.7433 - val_loss: 0.7053 - val_acc: 0.7370\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6956 - acc: 0.7442 - val_loss: 0.7039 - val_acc: 0.7370\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6953 - acc: 0.7452 - val_loss: 0.7024 - val_acc: 0.7375\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6949 - acc: 0.7458 - val_loss: 0.7013 - val_acc: 0.7385\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6947 - acc: 0.7462 - val_loss: 0.7002 - val_acc: 0.7385\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6944 - acc: 0.7448 - val_loss: 0.6993 - val_acc: 0.7375\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6941 - acc: 0.7458 - val_loss: 0.6984 - val_acc: 0.7380\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6939 - acc: 0.7457 - val_loss: 0.6980 - val_acc: 0.7365\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6937 - acc: 0.7462 - val_loss: 0.6972 - val_acc: 0.7370\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6935 - acc: 0.7456 - val_loss: 0.6969 - val_acc: 0.7349\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6933 - acc: 0.7460 - val_loss: 0.6966 - val_acc: 0.7344\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6930 - acc: 0.7467 - val_loss: 0.6963 - val_acc: 0.7344\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6928 - acc: 0.7464 - val_loss: 0.6958 - val_acc: 0.7329\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6925 - acc: 0.7444 - val_loss: 0.6955 - val_acc: 0.7313\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6923 - acc: 0.7446 - val_loss: 0.6952 - val_acc: 0.7313\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6920 - acc: 0.7421 - val_loss: 0.6951 - val_acc: 0.7267\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6917 - acc: 0.7408 - val_loss: 0.6947 - val_acc: 0.7236\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6914 - acc: 0.7402 - val_loss: 0.6947 - val_acc: 0.7231\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6910 - acc: 0.7394 - val_loss: 0.6945 - val_acc: 0.7236\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6906 - acc: 0.7376 - val_loss: 0.6942 - val_acc: 0.7287\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6901 - acc: 0.7349 - val_loss: 0.6943 - val_acc: 0.7241\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6895 - acc: 0.7313 - val_loss: 0.6945 - val_acc: 0.7169\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6887 - acc: 0.7277 - val_loss: 0.6947 - val_acc: 0.7122\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6876 - acc: 0.7204 - val_loss: 0.6953 - val_acc: 0.7029\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6859 - acc: 0.7016 - val_loss: 0.6976 - val_acc: 0.6746\n",
            "Epoch 27: early stopping\n",
            "With LSTM_units = 64, dense_layer = 50, dense_activation = sigmoid, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 8s 102ms/step - loss: 0.6948 - acc: 0.2333 - val_loss: 0.6958 - val_acc: 0.2218\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6946 - acc: 0.2649 - val_loss: 0.6961 - val_acc: 0.7148\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6943 - acc: 0.7376 - val_loss: 0.6961 - val_acc: 0.7318\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6942 - acc: 0.7346 - val_loss: 0.6965 - val_acc: 0.7267\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6939 - acc: 0.7399 - val_loss: 0.6962 - val_acc: 0.7292\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6937 - acc: 0.7451 - val_loss: 0.6960 - val_acc: 0.7334\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 64, dense_layer = 50, dense_activation = sigmoid, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 90ms/step - loss: 0.6964 - acc: 0.2147 - val_loss: 0.6966 - val_acc: 0.2140\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6957 - acc: 0.4182 - val_loss: 0.6971 - val_acc: 0.7370\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6951 - acc: 0.6023 - val_loss: 0.6968 - val_acc: 0.7442\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6946 - acc: 0.7504 - val_loss: 0.6973 - val_acc: 0.7406\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6941 - acc: 0.7510 - val_loss: 0.6966 - val_acc: 0.7437\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6936 - acc: 0.7533 - val_loss: 0.6955 - val_acc: 0.7452\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6931 - acc: 0.7542 - val_loss: 0.6953 - val_acc: 0.7437\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6927 - acc: 0.7549 - val_loss: 0.6947 - val_acc: 0.7457\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6922 - acc: 0.7527 - val_loss: 0.6945 - val_acc: 0.7447\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6917 - acc: 0.7581 - val_loss: 0.6932 - val_acc: 0.7457\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6912 - acc: 0.7555 - val_loss: 0.6931 - val_acc: 0.7427\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6905 - acc: 0.7532 - val_loss: 0.6922 - val_acc: 0.7437\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6898 - acc: 0.7525 - val_loss: 0.6920 - val_acc: 0.7406\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6888 - acc: 0.7550 - val_loss: 0.6896 - val_acc: 0.7370\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6874 - acc: 0.7427 - val_loss: 0.6900 - val_acc: 0.7292\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6836 - acc: 0.7145 - val_loss: 0.6934 - val_acc: 0.6581\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6515 - acc: 0.5645 - val_loss: 0.6786 - val_acc: 0.6968\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.5356 - acc: 0.8028 - val_loss: 0.5120 - val_acc: 0.8515\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.5017 - acc: 0.8260 - val_loss: 0.4940 - val_acc: 0.8494\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4778 - acc: 0.8374 - val_loss: 0.4436 - val_acc: 0.8602\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4644 - acc: 0.8414 - val_loss: 0.4377 - val_acc: 0.8561\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4561 - acc: 0.8462 - val_loss: 0.4428 - val_acc: 0.8504\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4491 - acc: 0.8445 - val_loss: 0.4250 - val_acc: 0.8602\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.4414 - acc: 0.8462 - val_loss: 0.4213 - val_acc: 0.8582\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.4352 - acc: 0.8530 - val_loss: 0.3992 - val_acc: 0.8649\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.4322 - acc: 0.8551 - val_loss: 0.4231 - val_acc: 0.8515\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.4279 - acc: 0.8544 - val_loss: 0.4247 - val_acc: 0.8468\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4253 - acc: 0.8529 - val_loss: 0.3811 - val_acc: 0.8757\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4177 - acc: 0.8619 - val_loss: 0.3998 - val_acc: 0.8633\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4143 - acc: 0.8627 - val_loss: 0.4075 - val_acc: 0.8597\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4111 - acc: 0.8638 - val_loss: 0.3987 - val_acc: 0.8654\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4095 - acc: 0.8642 - val_loss: 0.3751 - val_acc: 0.8716\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4050 - acc: 0.8650 - val_loss: 0.3785 - val_acc: 0.8706\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4024 - acc: 0.8640 - val_loss: 0.3885 - val_acc: 0.8706\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4000 - acc: 0.8656 - val_loss: 0.3836 - val_acc: 0.8695\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3978 - acc: 0.8640 - val_loss: 0.3597 - val_acc: 0.8804\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3937 - acc: 0.8672 - val_loss: 0.3665 - val_acc: 0.8736\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3896 - acc: 0.8668 - val_loss: 0.3588 - val_acc: 0.8762\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3876 - acc: 0.8664 - val_loss: 0.3503 - val_acc: 0.8809\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3855 - acc: 0.8689 - val_loss: 0.3675 - val_acc: 0.8675\n",
            "With LSTM_units = 64, dense_layer = 50, dense_activation = sigmoid, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 90ms/step - loss: 0.6964 - acc: 0.2291 - val_loss: 0.6943 - val_acc: 0.2280\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6953 - acc: 0.2172 - val_loss: 0.6956 - val_acc: 0.2202\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6945 - acc: 0.6531 - val_loss: 0.6956 - val_acc: 0.7261\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6939 - acc: 0.7422 - val_loss: 0.6962 - val_acc: 0.7241\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.6932 - acc: 0.7371 - val_loss: 0.6960 - val_acc: 0.7246\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6924 - acc: 0.7369 - val_loss: 0.6960 - val_acc: 0.7251\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 64, dense_layer = 50, dense_activation = sigmoid, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 88ms/step - loss: 0.6951 - acc: 0.2222 - val_loss: 0.6959 - val_acc: 0.2238\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6940 - acc: 0.6921 - val_loss: 0.6966 - val_acc: 0.7308\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6930 - acc: 0.7320 - val_loss: 0.6968 - val_acc: 0.7267\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6921 - acc: 0.7417 - val_loss: 0.6948 - val_acc: 0.7303\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.6904 - acc: 0.7338 - val_loss: 0.6952 - val_acc: 0.7117\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6835 - acc: 0.5877 - val_loss: 0.7184 - val_acc: 0.4642\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.5922 - acc: 0.6998 - val_loss: 0.5314 - val_acc: 0.8406\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.5001 - acc: 0.8290 - val_loss: 0.5299 - val_acc: 0.8169\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4828 - acc: 0.8280 - val_loss: 0.4702 - val_acc: 0.8417\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4636 - acc: 0.8406 - val_loss: 0.4702 - val_acc: 0.8324\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4621 - acc: 0.8273 - val_loss: 0.3998 - val_acc: 0.8706\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4453 - acc: 0.8427 - val_loss: 0.4777 - val_acc: 0.8097\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4338 - acc: 0.8445 - val_loss: 0.4078 - val_acc: 0.8556\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4278 - acc: 0.8508 - val_loss: 0.3900 - val_acc: 0.8654\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4219 - acc: 0.8500 - val_loss: 0.4018 - val_acc: 0.8577\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4170 - acc: 0.8490 - val_loss: 0.4348 - val_acc: 0.8329\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4100 - acc: 0.8548 - val_loss: 0.3887 - val_acc: 0.8649\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4077 - acc: 0.8535 - val_loss: 0.4050 - val_acc: 0.8525\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4016 - acc: 0.8589 - val_loss: 0.3892 - val_acc: 0.8597\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.4000 - acc: 0.8574 - val_loss: 0.3854 - val_acc: 0.8597\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3919 - acc: 0.8645 - val_loss: 0.3994 - val_acc: 0.8551\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3887 - acc: 0.8656 - val_loss: 0.4404 - val_acc: 0.8236\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3917 - acc: 0.8573 - val_loss: 0.3565 - val_acc: 0.8767\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3838 - acc: 0.8640 - val_loss: 0.3829 - val_acc: 0.8582\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3785 - acc: 0.8658 - val_loss: 0.3755 - val_acc: 0.8628\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3727 - acc: 0.8708 - val_loss: 0.3983 - val_acc: 0.8510\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3694 - acc: 0.8712 - val_loss: 0.3851 - val_acc: 0.8566\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.3649 - acc: 0.8704 - val_loss: 0.3787 - val_acc: 0.8577\n",
            "Epoch 28: early stopping\n",
            "With LSTM_units = 64, dense_layer = 50, dense_activation = sigmoid, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 7s 86ms/step - loss: 0.6944 - acc: 0.3676 - val_loss: 0.6967 - val_acc: 0.7241\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.6934 - acc: 0.7371 - val_loss: 0.6956 - val_acc: 0.7241\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6923 - acc: 0.7398 - val_loss: 0.6950 - val_acc: 0.7225\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6910 - acc: 0.7345 - val_loss: 0.6954 - val_acc: 0.7194\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.6886 - acc: 0.7253 - val_loss: 0.6937 - val_acc: 0.7055\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.6765 - acc: 0.5785 - val_loss: 0.7059 - val_acc: 0.5647\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.5663 - acc: 0.7653 - val_loss: 0.6332 - val_acc: 0.7886\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.5088 - acc: 0.8388 - val_loss: 0.5031 - val_acc: 0.8659\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4863 - acc: 0.8454 - val_loss: 0.4660 - val_acc: 0.8711\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4746 - acc: 0.8398 - val_loss: 0.4509 - val_acc: 0.8680\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4648 - acc: 0.8482 - val_loss: 0.4248 - val_acc: 0.8736\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.4571 - acc: 0.8487 - val_loss: 0.4176 - val_acc: 0.8726\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 5s 87ms/step - loss: 0.4492 - acc: 0.8552 - val_loss: 0.4508 - val_acc: 0.8386\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 5s 86ms/step - loss: 0.4443 - acc: 0.8495 - val_loss: 0.4280 - val_acc: 0.8504\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 5s 79ms/step - loss: 0.4418 - acc: 0.8542 - val_loss: 0.4255 - val_acc: 0.8551\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4363 - acc: 0.8499 - val_loss: 0.4564 - val_acc: 0.8247\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 5s 78ms/step - loss: 0.4276 - acc: 0.8459 - val_loss: 0.3890 - val_acc: 0.8711\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4190 - acc: 0.8498 - val_loss: 0.4102 - val_acc: 0.8504\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4133 - acc: 0.8442 - val_loss: 0.3745 - val_acc: 0.8690\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4091 - acc: 0.8468 - val_loss: 0.3589 - val_acc: 0.8757\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.4004 - acc: 0.8518 - val_loss: 0.4101 - val_acc: 0.8412\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.4000 - acc: 0.8500 - val_loss: 0.4325 - val_acc: 0.8262\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3927 - acc: 0.8462 - val_loss: 0.3524 - val_acc: 0.8700\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3840 - acc: 0.8491 - val_loss: 0.3459 - val_acc: 0.8721\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3767 - acc: 0.8534 - val_loss: 0.3845 - val_acc: 0.8468\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3712 - acc: 0.8515 - val_loss: 0.3515 - val_acc: 0.8577\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3630 - acc: 0.8509 - val_loss: 0.3435 - val_acc: 0.8597\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3600 - acc: 0.8524 - val_loss: 0.3554 - val_acc: 0.8525\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3495 - acc: 0.8522 - val_loss: 0.3378 - val_acc: 0.8571\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3438 - acc: 0.8584 - val_loss: 0.3650 - val_acc: 0.8463\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3434 - acc: 0.8576 - val_loss: 0.3425 - val_acc: 0.8577\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3390 - acc: 0.8566 - val_loss: 0.3572 - val_acc: 0.8499\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 5s 83ms/step - loss: 0.3314 - acc: 0.8650 - val_loss: 0.3652 - val_acc: 0.8458\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 5s 82ms/step - loss: 0.3256 - acc: 0.8672 - val_loss: 0.3292 - val_acc: 0.8638\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 5s 85ms/step - loss: 0.3222 - acc: 0.8696 - val_loss: 0.3403 - val_acc: 0.8587\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 5s 84ms/step - loss: 0.3274 - acc: 0.8597 - val_loss: 0.2961 - val_acc: 0.8845\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3192 - acc: 0.8721 - val_loss: 0.3435 - val_acc: 0.8577\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 5s 81ms/step - loss: 0.3156 - acc: 0.8711 - val_loss: 0.3306 - val_acc: 0.8644\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3105 - acc: 0.8708 - val_loss: 0.3188 - val_acc: 0.8669\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 5s 80ms/step - loss: 0.3091 - acc: 0.8749 - val_loss: 0.3275 - val_acc: 0.8664\n",
            "With LSTM_units = 64, dense_layer = 50, dense_activation = sigmoid, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 11s 136ms/step - loss: 0.6969 - acc: 0.2334 - val_loss: 0.6939 - val_acc: 0.2290\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.6962 - acc: 0.2164 - val_loss: 0.6949 - val_acc: 0.2243\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6956 - acc: 0.2143 - val_loss: 0.6958 - val_acc: 0.2145\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 127ms/step - loss: 0.6952 - acc: 0.2086 - val_loss: 0.6967 - val_acc: 0.2120\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 127ms/step - loss: 0.6949 - acc: 0.2112 - val_loss: 0.6968 - val_acc: 0.7040\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 127ms/step - loss: 0.6946 - acc: 0.7289 - val_loss: 0.6968 - val_acc: 0.7184\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 128, dense_layer = 1, dense_activation = relu, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 136ms/step - loss: 0.6951 - acc: 0.2214 - val_loss: 0.6959 - val_acc: 0.2161\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6947 - acc: 0.6469 - val_loss: 0.6961 - val_acc: 0.7261\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6943 - acc: 0.7328 - val_loss: 0.6965 - val_acc: 0.7251\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6940 - acc: 0.7420 - val_loss: 0.6963 - val_acc: 0.7287\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 127ms/step - loss: 0.6937 - acc: 0.7398 - val_loss: 0.6964 - val_acc: 0.7277\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6934 - acc: 0.7349 - val_loss: 0.6965 - val_acc: 0.7282\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 128, dense_layer = 1, dense_activation = relu, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 138ms/step - loss: 0.6947 - acc: 0.4582 - val_loss: 0.6960 - val_acc: 0.7344\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6936 - acc: 0.4838 - val_loss: 0.6964 - val_acc: 0.7298\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 137ms/step - loss: 0.6927 - acc: 0.7430 - val_loss: 0.6952 - val_acc: 0.7334\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 9s 155ms/step - loss: 0.6916 - acc: 0.7360 - val_loss: 0.6956 - val_acc: 0.7225\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 10s 156ms/step - loss: 0.6903 - acc: 0.7368 - val_loss: 0.6939 - val_acc: 0.7267\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 10s 157ms/step - loss: 0.6881 - acc: 0.7360 - val_loss: 0.6933 - val_acc: 0.7153\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 9s 156ms/step - loss: 0.6778 - acc: 0.6237 - val_loss: 0.7087 - val_acc: 0.5307\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 10s 171ms/step - loss: 0.5512 - acc: 0.7596 - val_loss: 0.6053 - val_acc: 0.7911\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 10s 156ms/step - loss: 0.4777 - acc: 0.8324 - val_loss: 0.4655 - val_acc: 0.8391\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.4423 - acc: 0.8460 - val_loss: 0.4398 - val_acc: 0.8396\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 9s 140ms/step - loss: 0.4265 - acc: 0.8459 - val_loss: 0.3941 - val_acc: 0.8566\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.4190 - acc: 0.8426 - val_loss: 0.4060 - val_acc: 0.8432\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.4084 - acc: 0.8480 - val_loss: 0.4390 - val_acc: 0.8174\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 9s 140ms/step - loss: 0.4007 - acc: 0.8471 - val_loss: 0.4212 - val_acc: 0.8241\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.3890 - acc: 0.8552 - val_loss: 0.4021 - val_acc: 0.8370\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.3878 - acc: 0.8499 - val_loss: 0.3727 - val_acc: 0.8566\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.3757 - acc: 0.8529 - val_loss: 0.3945 - val_acc: 0.8334\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.3707 - acc: 0.8468 - val_loss: 0.3271 - val_acc: 0.8736\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.3599 - acc: 0.8520 - val_loss: 0.3240 - val_acc: 0.8664\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.3540 - acc: 0.8490 - val_loss: 0.3823 - val_acc: 0.8293\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 8s 138ms/step - loss: 0.3483 - acc: 0.8513 - val_loss: 0.3073 - val_acc: 0.8736\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.3439 - acc: 0.8480 - val_loss: 0.2920 - val_acc: 0.8845\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 9s 147ms/step - loss: 0.3383 - acc: 0.8578 - val_loss: 0.3981 - val_acc: 0.8164\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.3390 - acc: 0.8500 - val_loss: 0.3096 - val_acc: 0.8711\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.3303 - acc: 0.8578 - val_loss: 0.3148 - val_acc: 0.8685\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.3278 - acc: 0.8569 - val_loss: 0.2899 - val_acc: 0.8829\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 9s 140ms/step - loss: 0.3250 - acc: 0.8607 - val_loss: 0.2986 - val_acc: 0.8711\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.3239 - acc: 0.8596 - val_loss: 0.3144 - val_acc: 0.8700\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.3159 - acc: 0.8614 - val_loss: 0.3925 - val_acc: 0.8190\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 8s 139ms/step - loss: 0.3139 - acc: 0.8592 - val_loss: 0.2852 - val_acc: 0.8850\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3103 - acc: 0.8652 - val_loss: 0.3699 - val_acc: 0.8360\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.3066 - acc: 0.8636 - val_loss: 0.3151 - val_acc: 0.8623\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.3010 - acc: 0.8662 - val_loss: 0.2715 - val_acc: 0.8917\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.3008 - acc: 0.8689 - val_loss: 0.2748 - val_acc: 0.8845\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.3010 - acc: 0.8673 - val_loss: 0.3177 - val_acc: 0.8592\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.2956 - acc: 0.8686 - val_loss: 0.2915 - val_acc: 0.8767\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.2920 - acc: 0.8708 - val_loss: 0.2764 - val_acc: 0.8834\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.2869 - acc: 0.8765 - val_loss: 0.2920 - val_acc: 0.8757\n",
            "Epoch 38: early stopping\n",
            "With LSTM_units = 128, dense_layer = 1, dense_activation = relu, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 11s 149ms/step - loss: 0.6951 - acc: 0.7571 - val_loss: 0.6978 - val_acc: 0.7561\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 139ms/step - loss: 0.6941 - acc: 0.7618 - val_loss: 0.6970 - val_acc: 0.7555\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.6931 - acc: 0.7660 - val_loss: 0.6934 - val_acc: 0.7628\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.6924 - acc: 0.7679 - val_loss: 0.6931 - val_acc: 0.7628\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 9s 151ms/step - loss: 0.6914 - acc: 0.7678 - val_loss: 0.6922 - val_acc: 0.7592\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.6902 - acc: 0.7620 - val_loss: 0.6907 - val_acc: 0.7514\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.6883 - acc: 0.7613 - val_loss: 0.6913 - val_acc: 0.7385\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.6837 - acc: 0.7439 - val_loss: 0.6801 - val_acc: 0.7463\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 139ms/step - loss: 0.5966 - acc: 0.7707 - val_loss: 0.5870 - val_acc: 0.7865\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.4970 - acc: 0.7985 - val_loss: 0.4429 - val_acc: 0.8293\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 9s 140ms/step - loss: 0.4554 - acc: 0.8104 - val_loss: 0.4088 - val_acc: 0.8334\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.4372 - acc: 0.8146 - val_loss: 0.3828 - val_acc: 0.8504\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.4189 - acc: 0.8223 - val_loss: 0.3783 - val_acc: 0.8473\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.4092 - acc: 0.8328 - val_loss: 0.4090 - val_acc: 0.8298\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 8s 139ms/step - loss: 0.4025 - acc: 0.8353 - val_loss: 0.3629 - val_acc: 0.8556\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.3907 - acc: 0.8415 - val_loss: 0.3942 - val_acc: 0.8365\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.3844 - acc: 0.8436 - val_loss: 0.3625 - val_acc: 0.8571\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 9s 140ms/step - loss: 0.3775 - acc: 0.8486 - val_loss: 0.3313 - val_acc: 0.8742\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.3752 - acc: 0.8473 - val_loss: 0.3205 - val_acc: 0.8757\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 9s 140ms/step - loss: 0.3696 - acc: 0.8477 - val_loss: 0.3515 - val_acc: 0.8633\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.3650 - acc: 0.8529 - val_loss: 0.3260 - val_acc: 0.8736\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 9s 140ms/step - loss: 0.3592 - acc: 0.8554 - val_loss: 0.3451 - val_acc: 0.8608\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.3543 - acc: 0.8556 - val_loss: 0.3256 - val_acc: 0.8716\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.3492 - acc: 0.8574 - val_loss: 0.3490 - val_acc: 0.8587\n",
            "Epoch 24: early stopping\n",
            "With LSTM_units = 128, dense_layer = 1, dense_activation = relu, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 11s 148ms/step - loss: 0.6935 - acc: 0.6343 - val_loss: 0.6947 - val_acc: 0.7349\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.6917 - acc: 0.6965 - val_loss: 0.6941 - val_acc: 0.7277\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.6893 - acc: 0.7238 - val_loss: 0.6915 - val_acc: 0.7112\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.6533 - acc: 0.6186 - val_loss: 0.6443 - val_acc: 0.7555\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 138ms/step - loss: 0.4935 - acc: 0.8066 - val_loss: 0.4053 - val_acc: 0.8608\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.4423 - acc: 0.8161 - val_loss: 0.3819 - val_acc: 0.8504\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.4150 - acc: 0.8218 - val_loss: 0.3617 - val_acc: 0.8546\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.3978 - acc: 0.8124 - val_loss: 0.3752 - val_acc: 0.8345\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3786 - acc: 0.8271 - val_loss: 0.3385 - val_acc: 0.8535\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.3650 - acc: 0.8288 - val_loss: 0.3138 - val_acc: 0.8675\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 8s 139ms/step - loss: 0.3597 - acc: 0.8282 - val_loss: 0.3213 - val_acc: 0.8618\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3554 - acc: 0.8328 - val_loss: 0.3264 - val_acc: 0.8587\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3408 - acc: 0.8409 - val_loss: 0.3111 - val_acc: 0.8669\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 8s 137ms/step - loss: 0.3383 - acc: 0.8397 - val_loss: 0.3041 - val_acc: 0.8721\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.3293 - acc: 0.8504 - val_loss: 0.2897 - val_acc: 0.8757\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.3280 - acc: 0.8520 - val_loss: 0.2944 - val_acc: 0.8742\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.3236 - acc: 0.8536 - val_loss: 0.3107 - val_acc: 0.8675\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.3163 - acc: 0.8560 - val_loss: 0.2803 - val_acc: 0.8798\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.3151 - acc: 0.8584 - val_loss: 0.3299 - val_acc: 0.8504\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.3116 - acc: 0.8554 - val_loss: 0.2801 - val_acc: 0.8788\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 9s 140ms/step - loss: 0.3045 - acc: 0.8606 - val_loss: 0.3253 - val_acc: 0.8479\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.2996 - acc: 0.8629 - val_loss: 0.2768 - val_acc: 0.8824\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.2965 - acc: 0.8656 - val_loss: 0.3377 - val_acc: 0.8406\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.2897 - acc: 0.8665 - val_loss: 0.2796 - val_acc: 0.8742\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.2925 - acc: 0.8624 - val_loss: 0.2528 - val_acc: 0.8938\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 8s 138ms/step - loss: 0.2870 - acc: 0.8689 - val_loss: 0.2820 - val_acc: 0.8706\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.2832 - acc: 0.8686 - val_loss: 0.3099 - val_acc: 0.8530\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 8s 138ms/step - loss: 0.2766 - acc: 0.8761 - val_loss: 0.2799 - val_acc: 0.8736\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.2762 - acc: 0.8723 - val_loss: 0.2405 - val_acc: 0.9005\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.2755 - acc: 0.8748 - val_loss: 0.2611 - val_acc: 0.8891\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.2707 - acc: 0.8760 - val_loss: 0.2310 - val_acc: 0.9036\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.2650 - acc: 0.8812 - val_loss: 0.2649 - val_acc: 0.8850\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.2632 - acc: 0.8785 - val_loss: 0.2960 - val_acc: 0.8618\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.2566 - acc: 0.8830 - val_loss: 0.2640 - val_acc: 0.8891\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.2510 - acc: 0.8890 - val_loss: 0.2905 - val_acc: 0.8736\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.2564 - acc: 0.8820 - val_loss: 0.3419 - val_acc: 0.8566\n",
            "Epoch 36: early stopping\n",
            "With LSTM_units = 128, dense_layer = 1, dense_activation = relu, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 11s 141ms/step - loss: 0.6950 - acc: 0.2232 - val_loss: 0.6985 - val_acc: 0.2125\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6930 - acc: 0.6891 - val_loss: 0.6946 - val_acc: 0.7272\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.6907 - acc: 0.7233 - val_loss: 0.6954 - val_acc: 0.7127\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6823 - acc: 0.6364 - val_loss: 0.6972 - val_acc: 0.6173\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.5473 - acc: 0.7838 - val_loss: 0.4524 - val_acc: 0.8597\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.4711 - acc: 0.8213 - val_loss: 0.4098 - val_acc: 0.8453\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.4380 - acc: 0.8267 - val_loss: 0.4055 - val_acc: 0.8314\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.4230 - acc: 0.8195 - val_loss: 0.3573 - val_acc: 0.8628\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.4011 - acc: 0.8304 - val_loss: 0.3582 - val_acc: 0.8577\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3847 - acc: 0.8324 - val_loss: 0.3290 - val_acc: 0.8675\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3753 - acc: 0.8335 - val_loss: 0.3330 - val_acc: 0.8602\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3695 - acc: 0.8319 - val_loss: 0.3083 - val_acc: 0.8742\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3556 - acc: 0.8392 - val_loss: 0.3596 - val_acc: 0.8417\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3473 - acc: 0.8442 - val_loss: 0.3419 - val_acc: 0.8499\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3343 - acc: 0.8485 - val_loss: 0.3015 - val_acc: 0.8731\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3251 - acc: 0.8481 - val_loss: 0.2824 - val_acc: 0.8819\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.3267 - acc: 0.8500 - val_loss: 0.3356 - val_acc: 0.8479\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 140ms/step - loss: 0.3230 - acc: 0.8515 - val_loss: 0.2825 - val_acc: 0.8788\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 8s 138ms/step - loss: 0.3136 - acc: 0.8543 - val_loss: 0.3011 - val_acc: 0.8638\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.3063 - acc: 0.8629 - val_loss: 0.3259 - val_acc: 0.8484\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3082 - acc: 0.8597 - val_loss: 0.2589 - val_acc: 0.8943\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.2980 - acc: 0.8641 - val_loss: 0.2611 - val_acc: 0.8958\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3001 - acc: 0.8663 - val_loss: 0.2683 - val_acc: 0.8845\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.2938 - acc: 0.8654 - val_loss: 0.3689 - val_acc: 0.8319\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.2917 - acc: 0.8627 - val_loss: 0.2573 - val_acc: 0.9025\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.2988 - acc: 0.8651 - val_loss: 0.2811 - val_acc: 0.8711\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.2859 - acc: 0.8699 - val_loss: 0.2876 - val_acc: 0.8680\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.2804 - acc: 0.8729 - val_loss: 0.2653 - val_acc: 0.8824\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.2800 - acc: 0.8752 - val_loss: 0.3513 - val_acc: 0.8365\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.2788 - acc: 0.8736 - val_loss: 0.2828 - val_acc: 0.8762\n",
            "Epoch 30: early stopping\n",
            "With LSTM_units = 128, dense_layer = 1, dense_activation = relu, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 140ms/step - loss: 0.6958 - acc: 0.6276 - val_loss: 0.6966 - val_acc: 0.7231\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6954 - acc: 0.7265 - val_loss: 0.6970 - val_acc: 0.7231\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6951 - acc: 0.7326 - val_loss: 0.6971 - val_acc: 0.7231\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6948 - acc: 0.7323 - val_loss: 0.6970 - val_acc: 0.7205\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6945 - acc: 0.7328 - val_loss: 0.6971 - val_acc: 0.7210\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6941 - acc: 0.7368 - val_loss: 0.6968 - val_acc: 0.7246\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 128, dense_layer = 1, dense_activation = sigmoid, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 139ms/step - loss: 0.6956 - acc: 0.2580 - val_loss: 0.6922 - val_acc: 0.2573\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6949 - acc: 0.2374 - val_loss: 0.6935 - val_acc: 0.2316\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6944 - acc: 0.2237 - val_loss: 0.6947 - val_acc: 0.2218\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.6940 - acc: 0.2192 - val_loss: 0.6949 - val_acc: 0.2223\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.6937 - acc: 0.5260 - val_loss: 0.6953 - val_acc: 0.2197\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.6934 - acc: 0.2164 - val_loss: 0.6956 - val_acc: 0.7065\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 128, dense_layer = 1, dense_activation = sigmoid, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 141ms/step - loss: 0.6950 - acc: 0.2286 - val_loss: 0.6952 - val_acc: 0.2207\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6936 - acc: 0.6169 - val_loss: 0.6975 - val_acc: 0.7200\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6926 - acc: 0.6092 - val_loss: 0.6961 - val_acc: 0.7261\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6916 - acc: 0.7495 - val_loss: 0.6944 - val_acc: 0.7308\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.6904 - acc: 0.7440 - val_loss: 0.6934 - val_acc: 0.7292\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6887 - acc: 0.7464 - val_loss: 0.6945 - val_acc: 0.7231\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6853 - acc: 0.7286 - val_loss: 0.6957 - val_acc: 0.6890\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.6475 - acc: 0.6124 - val_loss: 0.6788 - val_acc: 0.7720\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.5169 - acc: 0.8121 - val_loss: 0.4919 - val_acc: 0.8334\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.4667 - acc: 0.8245 - val_loss: 0.4461 - val_acc: 0.8381\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.4477 - acc: 0.8232 - val_loss: 0.4473 - val_acc: 0.8231\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.4343 - acc: 0.8298 - val_loss: 0.4163 - val_acc: 0.8350\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.4190 - acc: 0.8349 - val_loss: 0.4030 - val_acc: 0.8453\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.4100 - acc: 0.8369 - val_loss: 0.3666 - val_acc: 0.8638\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 8s 138ms/step - loss: 0.3996 - acc: 0.8442 - val_loss: 0.3560 - val_acc: 0.8638\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3889 - acc: 0.8373 - val_loss: 0.3749 - val_acc: 0.8412\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3821 - acc: 0.8362 - val_loss: 0.3229 - val_acc: 0.8664\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3776 - acc: 0.8338 - val_loss: 0.3200 - val_acc: 0.8654\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3632 - acc: 0.8407 - val_loss: 0.3688 - val_acc: 0.8365\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3567 - acc: 0.8377 - val_loss: 0.3342 - val_acc: 0.8540\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3538 - acc: 0.8418 - val_loss: 0.3568 - val_acc: 0.8365\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.3423 - acc: 0.8436 - val_loss: 0.3606 - val_acc: 0.8345\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3368 - acc: 0.8503 - val_loss: 0.3647 - val_acc: 0.8345\n",
            "Epoch 23: early stopping\n",
            "With LSTM_units = 128, dense_layer = 1, dense_activation = sigmoid, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 138ms/step - loss: 0.6940 - acc: 0.3912 - val_loss: 0.6980 - val_acc: 0.7205\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6930 - acc: 0.6221 - val_loss: 0.6965 - val_acc: 0.7256\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6919 - acc: 0.7431 - val_loss: 0.6945 - val_acc: 0.7298\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6907 - acc: 0.7453 - val_loss: 0.6922 - val_acc: 0.7318\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6889 - acc: 0.7389 - val_loss: 0.6937 - val_acc: 0.7174\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6842 - acc: 0.6940 - val_loss: 0.7080 - val_acc: 0.5730\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.6142 - acc: 0.6493 - val_loss: 0.5538 - val_acc: 0.8401\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.5088 - acc: 0.8326 - val_loss: 0.5310 - val_acc: 0.8236\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.4685 - acc: 0.8429 - val_loss: 0.4162 - val_acc: 0.8695\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.4541 - acc: 0.8516 - val_loss: 0.4021 - val_acc: 0.8711\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.4410 - acc: 0.8525 - val_loss: 0.3935 - val_acc: 0.8700\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.4314 - acc: 0.8529 - val_loss: 0.3859 - val_acc: 0.8659\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.4238 - acc: 0.8558 - val_loss: 0.3651 - val_acc: 0.8798\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.4158 - acc: 0.8543 - val_loss: 0.3857 - val_acc: 0.8577\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.4067 - acc: 0.8533 - val_loss: 0.3527 - val_acc: 0.8814\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.4044 - acc: 0.8549 - val_loss: 0.3832 - val_acc: 0.8520\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3922 - acc: 0.8606 - val_loss: 0.3596 - val_acc: 0.8669\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 137ms/step - loss: 0.3880 - acc: 0.8596 - val_loss: 0.3507 - val_acc: 0.8731\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3822 - acc: 0.8611 - val_loss: 0.3415 - val_acc: 0.8742\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3777 - acc: 0.8651 - val_loss: 0.3486 - val_acc: 0.8675\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3718 - acc: 0.8636 - val_loss: 0.3118 - val_acc: 0.8958\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3673 - acc: 0.8689 - val_loss: 0.3443 - val_acc: 0.8685\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3643 - acc: 0.8654 - val_loss: 0.3794 - val_acc: 0.8448\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3573 - acc: 0.8659 - val_loss: 0.2985 - val_acc: 0.8938\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.3536 - acc: 0.8687 - val_loss: 0.3007 - val_acc: 0.8907\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3533 - acc: 0.8658 - val_loss: 0.3343 - val_acc: 0.8721\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3449 - acc: 0.8683 - val_loss: 0.3907 - val_acc: 0.8319\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3449 - acc: 0.8652 - val_loss: 0.2878 - val_acc: 0.8922\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 8s 139ms/step - loss: 0.3370 - acc: 0.8676 - val_loss: 0.3426 - val_acc: 0.8623\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.3374 - acc: 0.8665 - val_loss: 0.2950 - val_acc: 0.8855\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.3379 - acc: 0.8613 - val_loss: 0.3005 - val_acc: 0.8798\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3272 - acc: 0.8695 - val_loss: 0.3065 - val_acc: 0.8752\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3253 - acc: 0.8713 - val_loss: 0.4729 - val_acc: 0.7891\n",
            "Epoch 33: early stopping\n",
            "With LSTM_units = 128, dense_layer = 1, dense_activation = sigmoid, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 11s 140ms/step - loss: 0.6947 - acc: 0.6628 - val_loss: 0.6937 - val_acc: 0.7344\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6921 - acc: 0.7470 - val_loss: 0.6954 - val_acc: 0.7287\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6902 - acc: 0.7447 - val_loss: 0.6929 - val_acc: 0.7329\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 137ms/step - loss: 0.6859 - acc: 0.7348 - val_loss: 0.6859 - val_acc: 0.7231\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.5956 - acc: 0.7489 - val_loss: 0.5736 - val_acc: 0.8247\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.4959 - acc: 0.8263 - val_loss: 0.4354 - val_acc: 0.8644\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.4536 - acc: 0.8406 - val_loss: 0.4463 - val_acc: 0.8365\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.4335 - acc: 0.8438 - val_loss: 0.4587 - val_acc: 0.8159\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.4144 - acc: 0.8493 - val_loss: 0.3790 - val_acc: 0.8556\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.4068 - acc: 0.8423 - val_loss: 0.3485 - val_acc: 0.8711\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.3881 - acc: 0.8404 - val_loss: 0.3323 - val_acc: 0.8711\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.3789 - acc: 0.8447 - val_loss: 0.4485 - val_acc: 0.7994\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3654 - acc: 0.8456 - val_loss: 0.3775 - val_acc: 0.8324\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.3538 - acc: 0.8487 - val_loss: 0.3323 - val_acc: 0.8561\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 8s 139ms/step - loss: 0.3568 - acc: 0.8393 - val_loss: 0.3550 - val_acc: 0.8370\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 139ms/step - loss: 0.3450 - acc: 0.8447 - val_loss: 0.3789 - val_acc: 0.8252\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3282 - acc: 0.8502 - val_loss: 0.2887 - val_acc: 0.8731\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3232 - acc: 0.8547 - val_loss: 0.3811 - val_acc: 0.8272\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3186 - acc: 0.8553 - val_loss: 0.2931 - val_acc: 0.8690\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.3143 - acc: 0.8591 - val_loss: 0.3091 - val_acc: 0.8592\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.3227 - acc: 0.8502 - val_loss: 0.3510 - val_acc: 0.8339\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.3059 - acc: 0.8638 - val_loss: 0.2967 - val_acc: 0.8659\n",
            "Epoch 22: early stopping\n",
            "With LSTM_units = 128, dense_layer = 1, dense_activation = sigmoid, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 11s 144ms/step - loss: 0.6944 - acc: 0.7541 - val_loss: 0.6952 - val_acc: 0.7468\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6928 - acc: 0.7485 - val_loss: 0.6933 - val_acc: 0.7463\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.6914 - acc: 0.7523 - val_loss: 0.6924 - val_acc: 0.7411\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.6892 - acc: 0.7424 - val_loss: 0.6921 - val_acc: 0.7261\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6611 - acc: 0.6467 - val_loss: 0.5925 - val_acc: 0.8190\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.5124 - acc: 0.8263 - val_loss: 0.4734 - val_acc: 0.8427\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.4617 - acc: 0.8126 - val_loss: 0.4102 - val_acc: 0.8479\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.4287 - acc: 0.8266 - val_loss: 0.4186 - val_acc: 0.8308\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.4097 - acc: 0.8351 - val_loss: 0.3829 - val_acc: 0.8499\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.4001 - acc: 0.8331 - val_loss: 0.4989 - val_acc: 0.7597\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.3819 - acc: 0.8361 - val_loss: 0.3948 - val_acc: 0.8324\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3722 - acc: 0.8348 - val_loss: 0.3302 - val_acc: 0.8700\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 8s 139ms/step - loss: 0.3582 - acc: 0.8389 - val_loss: 0.3112 - val_acc: 0.8778\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.3521 - acc: 0.8418 - val_loss: 0.4140 - val_acc: 0.8164\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3500 - acc: 0.8382 - val_loss: 0.3378 - val_acc: 0.8468\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3349 - acc: 0.8428 - val_loss: 0.2727 - val_acc: 0.8917\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.3347 - acc: 0.8455 - val_loss: 0.3782 - val_acc: 0.8262\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.3252 - acc: 0.8466 - val_loss: 0.3276 - val_acc: 0.8499\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.3195 - acc: 0.8499 - val_loss: 0.3276 - val_acc: 0.8520\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3158 - acc: 0.8487 - val_loss: 0.2847 - val_acc: 0.8773\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.3106 - acc: 0.8534 - val_loss: 0.3628 - val_acc: 0.8267\n",
            "Epoch 21: early stopping\n",
            "With LSTM_units = 128, dense_layer = 1, dense_activation = sigmoid, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 11s 141ms/step - loss: 0.6941 - acc: 0.6472 - val_loss: 0.6941 - val_acc: 0.7334\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6936 - acc: 0.7390 - val_loss: 0.6951 - val_acc: 0.7287\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.6933 - acc: 0.7300 - val_loss: 0.6955 - val_acc: 0.7267\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.6930 - acc: 0.7427 - val_loss: 0.6949 - val_acc: 0.7308\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6927 - acc: 0.7373 - val_loss: 0.6955 - val_acc: 0.7231\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.6924 - acc: 0.7377 - val_loss: 0.6951 - val_acc: 0.7272\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 128, dense_layer = 10, dense_activation = relu, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 138ms/step - loss: 0.6953 - acc: 0.4316 - val_loss: 0.6945 - val_acc: 0.7344\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6947 - acc: 0.7422 - val_loss: 0.6957 - val_acc: 0.7215\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6942 - acc: 0.7393 - val_loss: 0.6962 - val_acc: 0.7200\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.6938 - acc: 0.7375 - val_loss: 0.6969 - val_acc: 0.7205\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 137ms/step - loss: 0.6935 - acc: 0.7371 - val_loss: 0.6965 - val_acc: 0.7210\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6931 - acc: 0.7363 - val_loss: 0.6965 - val_acc: 0.7205\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 128, dense_layer = 10, dense_activation = relu, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 140ms/step - loss: 0.6945 - acc: 0.7485 - val_loss: 0.6971 - val_acc: 0.7323\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.6935 - acc: 0.7488 - val_loss: 0.6953 - val_acc: 0.7344\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6925 - acc: 0.7476 - val_loss: 0.6948 - val_acc: 0.7375\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6915 - acc: 0.7400 - val_loss: 0.6937 - val_acc: 0.7282\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6901 - acc: 0.7455 - val_loss: 0.6925 - val_acc: 0.7308\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.6879 - acc: 0.7431 - val_loss: 0.6941 - val_acc: 0.7179\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 139ms/step - loss: 0.6805 - acc: 0.6757 - val_loss: 0.7050 - val_acc: 0.5812\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.5701 - acc: 0.7342 - val_loss: 0.5065 - val_acc: 0.8556\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.4850 - acc: 0.8333 - val_loss: 0.4203 - val_acc: 0.8659\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.4582 - acc: 0.8319 - val_loss: 0.4069 - val_acc: 0.8664\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 8s 127ms/step - loss: 0.4410 - acc: 0.8374 - val_loss: 0.4170 - val_acc: 0.8494\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.4247 - acc: 0.8397 - val_loss: 0.3785 - val_acc: 0.8597\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.4120 - acc: 0.8392 - val_loss: 0.3505 - val_acc: 0.8680\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.4066 - acc: 0.8370 - val_loss: 0.4308 - val_acc: 0.8252\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.3967 - acc: 0.8339 - val_loss: 0.3772 - val_acc: 0.8479\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.3907 - acc: 0.8337 - val_loss: 0.3692 - val_acc: 0.8510\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3777 - acc: 0.8404 - val_loss: 0.3612 - val_acc: 0.8571\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.3697 - acc: 0.8471 - val_loss: 0.3554 - val_acc: 0.8597\n",
            "Epoch 18: early stopping\n",
            "With LSTM_units = 128, dense_layer = 10, dense_activation = relu, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 11s 145ms/step - loss: 0.6950 - acc: 0.2478 - val_loss: 0.6934 - val_acc: 0.2481\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6933 - acc: 0.2219 - val_loss: 0.6961 - val_acc: 0.2197\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6924 - acc: 0.6709 - val_loss: 0.6952 - val_acc: 0.7241\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.6914 - acc: 0.7461 - val_loss: 0.6953 - val_acc: 0.7272\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6901 - acc: 0.7407 - val_loss: 0.6937 - val_acc: 0.7267\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6876 - acc: 0.7204 - val_loss: 0.6956 - val_acc: 0.6900\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 128, dense_layer = 10, dense_activation = relu, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 139ms/step - loss: 0.6955 - acc: 0.2480 - val_loss: 0.6969 - val_acc: 0.2166\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.6932 - acc: 0.5329 - val_loss: 0.6967 - val_acc: 0.7210\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.6914 - acc: 0.7338 - val_loss: 0.6973 - val_acc: 0.7189\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.6875 - acc: 0.7177 - val_loss: 0.7034 - val_acc: 0.6163\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.6116 - acc: 0.6544 - val_loss: 0.6443 - val_acc: 0.7674\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.5032 - acc: 0.8125 - val_loss: 0.4445 - val_acc: 0.8510\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.4621 - acc: 0.8276 - val_loss: 0.4508 - val_acc: 0.8308\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.4364 - acc: 0.8334 - val_loss: 0.3717 - val_acc: 0.8675\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.4206 - acc: 0.8307 - val_loss: 0.3922 - val_acc: 0.8473\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.4040 - acc: 0.8360 - val_loss: 0.3953 - val_acc: 0.8365\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.3914 - acc: 0.8330 - val_loss: 0.3613 - val_acc: 0.8582\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3779 - acc: 0.8340 - val_loss: 0.3511 - val_acc: 0.8530\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3646 - acc: 0.8370 - val_loss: 0.3161 - val_acc: 0.8742\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.3584 - acc: 0.8414 - val_loss: 0.3342 - val_acc: 0.8597\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.3466 - acc: 0.8426 - val_loss: 0.4179 - val_acc: 0.8092\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.3439 - acc: 0.8467 - val_loss: 0.3521 - val_acc: 0.8479\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3371 - acc: 0.8494 - val_loss: 0.3431 - val_acc: 0.8525\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3357 - acc: 0.8460 - val_loss: 0.4067 - val_acc: 0.8081\n",
            "Epoch 18: early stopping\n",
            "With LSTM_units = 128, dense_layer = 10, dense_activation = relu, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 141ms/step - loss: 0.6946 - acc: 0.6779 - val_loss: 0.6958 - val_acc: 0.7344\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6929 - acc: 0.7417 - val_loss: 0.6965 - val_acc: 0.7215\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6909 - acc: 0.7119 - val_loss: 0.6955 - val_acc: 0.7086\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.6763 - acc: 0.5536 - val_loss: 0.6644 - val_acc: 0.7215\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.5597 - acc: 0.7818 - val_loss: 0.5837 - val_acc: 0.8118\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.4929 - acc: 0.8190 - val_loss: 0.5018 - val_acc: 0.8056\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.4590 - acc: 0.8190 - val_loss: 0.4166 - val_acc: 0.8406\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.4393 - acc: 0.8306 - val_loss: 0.4579 - val_acc: 0.8092\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.4250 - acc: 0.8298 - val_loss: 0.3893 - val_acc: 0.8504\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.4102 - acc: 0.8317 - val_loss: 0.4152 - val_acc: 0.8298\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 8s 137ms/step - loss: 0.4006 - acc: 0.8291 - val_loss: 0.3557 - val_acc: 0.8530\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.3861 - acc: 0.8373 - val_loss: 0.3888 - val_acc: 0.8308\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3763 - acc: 0.8312 - val_loss: 0.3927 - val_acc: 0.8298\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3618 - acc: 0.8351 - val_loss: 0.3648 - val_acc: 0.8484\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3564 - acc: 0.8371 - val_loss: 0.3714 - val_acc: 0.8417\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3431 - acc: 0.8444 - val_loss: 0.3568 - val_acc: 0.8432\n",
            "Epoch 16: early stopping\n",
            "With LSTM_units = 128, dense_layer = 10, dense_activation = relu, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 11s 144ms/step - loss: 0.6943 - acc: 0.5524 - val_loss: 0.6986 - val_acc: 0.7282\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 137ms/step - loss: 0.6939 - acc: 0.7460 - val_loss: 0.6977 - val_acc: 0.7318\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.6936 - acc: 0.7515 - val_loss: 0.6962 - val_acc: 0.7401\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.6932 - acc: 0.7478 - val_loss: 0.6958 - val_acc: 0.7396\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.6929 - acc: 0.7509 - val_loss: 0.6956 - val_acc: 0.7380\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6926 - acc: 0.7505 - val_loss: 0.6952 - val_acc: 0.7385\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6923 - acc: 0.7502 - val_loss: 0.6943 - val_acc: 0.7421\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6919 - acc: 0.7518 - val_loss: 0.6939 - val_acc: 0.7416\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 9s 140ms/step - loss: 0.6916 - acc: 0.7509 - val_loss: 0.6940 - val_acc: 0.7401\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.6912 - acc: 0.7518 - val_loss: 0.6937 - val_acc: 0.7401\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 8s 126ms/step - loss: 0.6908 - acc: 0.7523 - val_loss: 0.6933 - val_acc: 0.7385\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6904 - acc: 0.7546 - val_loss: 0.6929 - val_acc: 0.7370\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.6900 - acc: 0.7515 - val_loss: 0.6929 - val_acc: 0.7334\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6895 - acc: 0.7474 - val_loss: 0.6921 - val_acc: 0.7329\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.6889 - acc: 0.7496 - val_loss: 0.6919 - val_acc: 0.7334\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.6882 - acc: 0.7474 - val_loss: 0.6912 - val_acc: 0.7334\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.6874 - acc: 0.7479 - val_loss: 0.6912 - val_acc: 0.7359\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6863 - acc: 0.7415 - val_loss: 0.6916 - val_acc: 0.7261\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.6847 - acc: 0.7292 - val_loss: 0.6917 - val_acc: 0.7143\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6814 - acc: 0.7140 - val_loss: 0.6954 - val_acc: 0.6756\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 8s 126ms/step - loss: 0.6669 - acc: 0.6005 - val_loss: 0.7223 - val_acc: 0.5327\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 8s 127ms/step - loss: 0.5634 - acc: 0.7470 - val_loss: 0.5732 - val_acc: 0.8128\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.5050 - acc: 0.8250 - val_loss: 0.5473 - val_acc: 0.8123\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.4820 - acc: 0.8312 - val_loss: 0.4935 - val_acc: 0.8350\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.4666 - acc: 0.8319 - val_loss: 0.4417 - val_acc: 0.8546\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.4550 - acc: 0.8351 - val_loss: 0.4565 - val_acc: 0.8412\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.4451 - acc: 0.8343 - val_loss: 0.4239 - val_acc: 0.8571\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.4386 - acc: 0.8375 - val_loss: 0.4011 - val_acc: 0.8644\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.4304 - acc: 0.8355 - val_loss: 0.4132 - val_acc: 0.8520\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.4252 - acc: 0.8353 - val_loss: 0.3894 - val_acc: 0.8628\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.4212 - acc: 0.8396 - val_loss: 0.3801 - val_acc: 0.8664\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.4185 - acc: 0.8393 - val_loss: 0.3835 - val_acc: 0.8618\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 9s 153ms/step - loss: 0.4130 - acc: 0.8377 - val_loss: 0.3963 - val_acc: 0.8473\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 9s 152ms/step - loss: 0.4099 - acc: 0.8407 - val_loss: 0.4096 - val_acc: 0.8334\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.4078 - acc: 0.8396 - val_loss: 0.3819 - val_acc: 0.8540\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.4051 - acc: 0.8410 - val_loss: 0.4079 - val_acc: 0.8314\n",
            "Epoch 36: early stopping\n",
            "With LSTM_units = 128, dense_layer = 10, dense_activation = sigmoid, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 13s 155ms/step - loss: 0.6948 - acc: 0.7251 - val_loss: 0.7002 - val_acc: 0.7241\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.6944 - acc: 0.7378 - val_loss: 0.6991 - val_acc: 0.7272\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.6941 - acc: 0.7409 - val_loss: 0.6983 - val_acc: 0.7334\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.6938 - acc: 0.7429 - val_loss: 0.6974 - val_acc: 0.7318\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.6935 - acc: 0.7416 - val_loss: 0.6969 - val_acc: 0.7323\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 9s 146ms/step - loss: 0.6932 - acc: 0.7439 - val_loss: 0.6964 - val_acc: 0.7303\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.6929 - acc: 0.7431 - val_loss: 0.6960 - val_acc: 0.7287\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.6926 - acc: 0.7429 - val_loss: 0.6957 - val_acc: 0.7277\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.6922 - acc: 0.7439 - val_loss: 0.6951 - val_acc: 0.7251\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.6919 - acc: 0.7406 - val_loss: 0.6951 - val_acc: 0.7225\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.6915 - acc: 0.7390 - val_loss: 0.6947 - val_acc: 0.7246\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.6910 - acc: 0.7369 - val_loss: 0.6944 - val_acc: 0.7241\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.6904 - acc: 0.7368 - val_loss: 0.6941 - val_acc: 0.7236\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.6897 - acc: 0.7342 - val_loss: 0.6943 - val_acc: 0.7210\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.6888 - acc: 0.7246 - val_loss: 0.6949 - val_acc: 0.7081\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.6872 - acc: 0.7171 - val_loss: 0.6957 - val_acc: 0.6926\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.6841 - acc: 0.6730 - val_loss: 0.7026 - val_acc: 0.6091\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.6760 - acc: 0.5331 - val_loss: 0.7398 - val_acc: 0.4064\n",
            "Epoch 18: early stopping\n",
            "With LSTM_units = 128, dense_layer = 10, dense_activation = sigmoid, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 11s 152ms/step - loss: 0.6957 - acc: 0.2423 - val_loss: 0.6937 - val_acc: 0.2336\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.6936 - acc: 0.2125 - val_loss: 0.6963 - val_acc: 0.2151\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.6924 - acc: 0.6085 - val_loss: 0.6964 - val_acc: 0.7133\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.6912 - acc: 0.7282 - val_loss: 0.6943 - val_acc: 0.7287\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.6896 - acc: 0.7295 - val_loss: 0.6930 - val_acc: 0.7200\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.6858 - acc: 0.7117 - val_loss: 0.6975 - val_acc: 0.6601\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.6297 - acc: 0.6326 - val_loss: 0.6515 - val_acc: 0.7788\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.5143 - acc: 0.8162 - val_loss: 0.4968 - val_acc: 0.8386\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.4624 - acc: 0.8346 - val_loss: 0.4266 - val_acc: 0.8571\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.4477 - acc: 0.8248 - val_loss: 0.4161 - val_acc: 0.8463\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.4292 - acc: 0.8366 - val_loss: 0.4218 - val_acc: 0.8345\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 9s 149ms/step - loss: 0.4160 - acc: 0.8373 - val_loss: 0.3621 - val_acc: 0.8680\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 9s 147ms/step - loss: 0.4073 - acc: 0.8428 - val_loss: 0.3729 - val_acc: 0.8608\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 10s 157ms/step - loss: 0.4021 - acc: 0.8402 - val_loss: 0.3435 - val_acc: 0.8706\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.3918 - acc: 0.8475 - val_loss: 0.3894 - val_acc: 0.8437\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.3856 - acc: 0.8460 - val_loss: 0.4629 - val_acc: 0.7886\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3831 - acc: 0.8391 - val_loss: 0.3649 - val_acc: 0.8510\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.3717 - acc: 0.8447 - val_loss: 0.3347 - val_acc: 0.8649\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.3664 - acc: 0.8446 - val_loss: 0.3555 - val_acc: 0.8484\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 9s 147ms/step - loss: 0.3592 - acc: 0.8445 - val_loss: 0.3629 - val_acc: 0.8412\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.3492 - acc: 0.8444 - val_loss: 0.3290 - val_acc: 0.8577\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3471 - acc: 0.8454 - val_loss: 0.3459 - val_acc: 0.8442\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 9s 140ms/step - loss: 0.3425 - acc: 0.8466 - val_loss: 0.3468 - val_acc: 0.8391\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.3391 - acc: 0.8478 - val_loss: 0.3405 - val_acc: 0.8427\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3334 - acc: 0.8498 - val_loss: 0.3321 - val_acc: 0.8489\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.3313 - acc: 0.8526 - val_loss: 0.3545 - val_acc: 0.8350\n",
            "Epoch 26: early stopping\n",
            "With LSTM_units = 128, dense_layer = 10, dense_activation = sigmoid, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 11s 151ms/step - loss: 0.6947 - acc: 0.6623 - val_loss: 0.6977 - val_acc: 0.7298\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.6937 - acc: 0.7433 - val_loss: 0.6965 - val_acc: 0.7308\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.6928 - acc: 0.7424 - val_loss: 0.6954 - val_acc: 0.7308\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.6919 - acc: 0.7411 - val_loss: 0.6947 - val_acc: 0.7225\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.6906 - acc: 0.7399 - val_loss: 0.6945 - val_acc: 0.7241\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 9s 140ms/step - loss: 0.6876 - acc: 0.7162 - val_loss: 0.6979 - val_acc: 0.6715\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.6594 - acc: 0.5630 - val_loss: 0.6195 - val_acc: 0.7855\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.5314 - acc: 0.8128 - val_loss: 0.5529 - val_acc: 0.8143\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.4834 - acc: 0.8330 - val_loss: 0.4483 - val_acc: 0.8592\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.4559 - acc: 0.8395 - val_loss: 0.4332 - val_acc: 0.8463\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.4431 - acc: 0.8395 - val_loss: 0.3990 - val_acc: 0.8608\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.4323 - acc: 0.8371 - val_loss: 0.3842 - val_acc: 0.8613\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.4216 - acc: 0.8364 - val_loss: 0.3859 - val_acc: 0.8530\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.4124 - acc: 0.8392 - val_loss: 0.4011 - val_acc: 0.8453\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.4008 - acc: 0.8375 - val_loss: 0.3819 - val_acc: 0.8463\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.3937 - acc: 0.8428 - val_loss: 0.3801 - val_acc: 0.8417\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3883 - acc: 0.8426 - val_loss: 0.3620 - val_acc: 0.8546\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3782 - acc: 0.8420 - val_loss: 0.3845 - val_acc: 0.8355\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.3731 - acc: 0.8429 - val_loss: 0.3661 - val_acc: 0.8427\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3657 - acc: 0.8459 - val_loss: 0.3530 - val_acc: 0.8494\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.3622 - acc: 0.8456 - val_loss: 0.3328 - val_acc: 0.8628\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3570 - acc: 0.8445 - val_loss: 0.3335 - val_acc: 0.8613\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 9s 152ms/step - loss: 0.3515 - acc: 0.8487 - val_loss: 0.3167 - val_acc: 0.8695\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 9s 147ms/step - loss: 0.3445 - acc: 0.8526 - val_loss: 0.3754 - val_acc: 0.8360\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3420 - acc: 0.8515 - val_loss: 0.3041 - val_acc: 0.8778\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3368 - acc: 0.8535 - val_loss: 0.3017 - val_acc: 0.8767\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3344 - acc: 0.8569 - val_loss: 0.3631 - val_acc: 0.8401\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.3299 - acc: 0.8538 - val_loss: 0.3594 - val_acc: 0.8417\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.3272 - acc: 0.8593 - val_loss: 0.3486 - val_acc: 0.8479\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.3234 - acc: 0.8589 - val_loss: 0.3140 - val_acc: 0.8659\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.3247 - acc: 0.8562 - val_loss: 0.3679 - val_acc: 0.8314\n",
            "Epoch 31: early stopping\n",
            "With LSTM_units = 128, dense_layer = 10, dense_activation = sigmoid, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 11s 151ms/step - loss: 0.6948 - acc: 0.7488 - val_loss: 0.6942 - val_acc: 0.7597\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.6934 - acc: 0.7585 - val_loss: 0.6937 - val_acc: 0.7509\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 9s 140ms/step - loss: 0.6920 - acc: 0.7568 - val_loss: 0.6935 - val_acc: 0.7416\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.6904 - acc: 0.7554 - val_loss: 0.6950 - val_acc: 0.7246\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.6867 - acc: 0.7244 - val_loss: 0.6880 - val_acc: 0.7117\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.5873 - acc: 0.7261 - val_loss: 0.5594 - val_acc: 0.8303\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 9s 148ms/step - loss: 0.4831 - acc: 0.8349 - val_loss: 0.3966 - val_acc: 0.8773\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.4426 - acc: 0.8400 - val_loss: 0.4734 - val_acc: 0.8143\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.4292 - acc: 0.8396 - val_loss: 0.4246 - val_acc: 0.8360\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.4169 - acc: 0.8398 - val_loss: 0.3546 - val_acc: 0.8700\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.4042 - acc: 0.8404 - val_loss: 0.3545 - val_acc: 0.8700\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 9s 147ms/step - loss: 0.3897 - acc: 0.8361 - val_loss: 0.3163 - val_acc: 0.8809\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.3782 - acc: 0.8377 - val_loss: 0.4015 - val_acc: 0.8277\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.3635 - acc: 0.8380 - val_loss: 0.3391 - val_acc: 0.8520\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3537 - acc: 0.8433 - val_loss: 0.4022 - val_acc: 0.8107\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.3508 - acc: 0.8447 - val_loss: 0.3877 - val_acc: 0.8205\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.3426 - acc: 0.8460 - val_loss: 0.3408 - val_acc: 0.8499\n",
            "Epoch 17: early stopping\n",
            "With LSTM_units = 128, dense_layer = 10, dense_activation = sigmoid, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 11s 150ms/step - loss: 0.6952 - acc: 0.4435 - val_loss: 0.6985 - val_acc: 0.7339\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.6936 - acc: 0.7434 - val_loss: 0.6970 - val_acc: 0.7298\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.6916 - acc: 0.7493 - val_loss: 0.6941 - val_acc: 0.7246\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 139ms/step - loss: 0.6884 - acc: 0.7255 - val_loss: 0.6955 - val_acc: 0.6818\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.6215 - acc: 0.6598 - val_loss: 0.5373 - val_acc: 0.8360\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 9s 146ms/step - loss: 0.4978 - acc: 0.8239 - val_loss: 0.4971 - val_acc: 0.8174\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 9s 150ms/step - loss: 0.4536 - acc: 0.8264 - val_loss: 0.4123 - val_acc: 0.8463\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.4224 - acc: 0.8357 - val_loss: 0.3876 - val_acc: 0.8510\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 9s 152ms/step - loss: 0.4132 - acc: 0.8335 - val_loss: 0.3603 - val_acc: 0.8582\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 10s 164ms/step - loss: 0.4040 - acc: 0.8298 - val_loss: 0.4249 - val_acc: 0.8210\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 9s 148ms/step - loss: 0.3869 - acc: 0.8356 - val_loss: 0.3599 - val_acc: 0.8473\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.3792 - acc: 0.8272 - val_loss: 0.3817 - val_acc: 0.8324\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3654 - acc: 0.8375 - val_loss: 0.4433 - val_acc: 0.7978\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 9s 153ms/step - loss: 0.3554 - acc: 0.8370 - val_loss: 0.3665 - val_acc: 0.8386\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3487 - acc: 0.8386 - val_loss: 0.3580 - val_acc: 0.8412\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 137ms/step - loss: 0.3442 - acc: 0.8413 - val_loss: 0.4013 - val_acc: 0.8107\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3361 - acc: 0.8411 - val_loss: 0.3020 - val_acc: 0.8690\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 138ms/step - loss: 0.3414 - acc: 0.8393 - val_loss: 0.5722 - val_acc: 0.7019\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 9s 140ms/step - loss: 0.3467 - acc: 0.8389 - val_loss: 0.2891 - val_acc: 0.8731\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.3240 - acc: 0.8502 - val_loss: 0.3044 - val_acc: 0.8659\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3182 - acc: 0.8505 - val_loss: 0.2831 - val_acc: 0.8742\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.3162 - acc: 0.8529 - val_loss: 0.2833 - val_acc: 0.8752\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3206 - acc: 0.8500 - val_loss: 0.3526 - val_acc: 0.8365\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.3088 - acc: 0.8516 - val_loss: 0.2734 - val_acc: 0.8809\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 9s 141ms/step - loss: 0.3060 - acc: 0.8560 - val_loss: 0.3498 - val_acc: 0.8417\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.2950 - acc: 0.8634 - val_loss: 0.2885 - val_acc: 0.8716\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 8s 138ms/step - loss: 0.2911 - acc: 0.8616 - val_loss: 0.2816 - val_acc: 0.8747\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.2905 - acc: 0.8588 - val_loss: 0.2852 - val_acc: 0.8706\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.2843 - acc: 0.8655 - val_loss: 0.3343 - val_acc: 0.8479\n",
            "Epoch 29: early stopping\n",
            "With LSTM_units = 128, dense_layer = 10, dense_activation = sigmoid, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 11s 142ms/step - loss: 0.6954 - acc: 0.7556 - val_loss: 0.6938 - val_acc: 0.7375\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.6948 - acc: 0.6896 - val_loss: 0.6947 - val_acc: 0.7256\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.6943 - acc: 0.7393 - val_loss: 0.6952 - val_acc: 0.7277\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 140ms/step - loss: 0.6939 - acc: 0.7424 - val_loss: 0.6955 - val_acc: 0.7282\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.6936 - acc: 0.7395 - val_loss: 0.6960 - val_acc: 0.7251\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 137ms/step - loss: 0.6933 - acc: 0.7376 - val_loss: 0.6961 - val_acc: 0.7246\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 128, dense_layer = 50, dense_activation = relu, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 141ms/step - loss: 0.6953 - acc: 0.7495 - val_loss: 0.6981 - val_acc: 0.7488\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 138ms/step - loss: 0.6949 - acc: 0.7555 - val_loss: 0.6976 - val_acc: 0.7452\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6946 - acc: 0.7505 - val_loss: 0.6978 - val_acc: 0.7437\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.6943 - acc: 0.7480 - val_loss: 0.6972 - val_acc: 0.7406\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 137ms/step - loss: 0.6940 - acc: 0.7438 - val_loss: 0.6973 - val_acc: 0.7323\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6937 - acc: 0.7447 - val_loss: 0.6968 - val_acc: 0.7298\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.6934 - acc: 0.7407 - val_loss: 0.6966 - val_acc: 0.7298\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.6931 - acc: 0.7393 - val_loss: 0.6961 - val_acc: 0.7261\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 138ms/step - loss: 0.6927 - acc: 0.7389 - val_loss: 0.6961 - val_acc: 0.7236\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.6923 - acc: 0.7364 - val_loss: 0.6955 - val_acc: 0.7236\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.6920 - acc: 0.7353 - val_loss: 0.6959 - val_acc: 0.7210\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.6915 - acc: 0.7346 - val_loss: 0.6950 - val_acc: 0.7215\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.6911 - acc: 0.7332 - val_loss: 0.6956 - val_acc: 0.7215\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6906 - acc: 0.7337 - val_loss: 0.6945 - val_acc: 0.7236\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 8s 138ms/step - loss: 0.6900 - acc: 0.7311 - val_loss: 0.6947 - val_acc: 0.7210\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 138ms/step - loss: 0.6893 - acc: 0.7289 - val_loss: 0.6949 - val_acc: 0.7148\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6883 - acc: 0.7262 - val_loss: 0.6952 - val_acc: 0.7102\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.6869 - acc: 0.7177 - val_loss: 0.6957 - val_acc: 0.6957\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.6846 - acc: 0.6904 - val_loss: 0.7002 - val_acc: 0.6576\n",
            "Epoch 19: early stopping\n",
            "With LSTM_units = 128, dense_layer = 50, dense_activation = relu, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 141ms/step - loss: 0.6968 - acc: 0.5881 - val_loss: 0.6938 - val_acc: 0.2274\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 138ms/step - loss: 0.6948 - acc: 0.2627 - val_loss: 0.6957 - val_acc: 0.2161\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6938 - acc: 0.5418 - val_loss: 0.6949 - val_acc: 0.7354\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 137ms/step - loss: 0.6929 - acc: 0.7411 - val_loss: 0.6959 - val_acc: 0.7246\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.6920 - acc: 0.7510 - val_loss: 0.6939 - val_acc: 0.7354\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6909 - acc: 0.7451 - val_loss: 0.6940 - val_acc: 0.7282\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 128, dense_layer = 50, dense_activation = relu, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 141ms/step - loss: 0.6952 - acc: 0.6761 - val_loss: 0.6947 - val_acc: 0.7437\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.6940 - acc: 0.7487 - val_loss: 0.6960 - val_acc: 0.7334\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.6931 - acc: 0.7493 - val_loss: 0.6954 - val_acc: 0.7339\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.6922 - acc: 0.7415 - val_loss: 0.6958 - val_acc: 0.7272\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.6910 - acc: 0.7442 - val_loss: 0.6934 - val_acc: 0.7287\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6894 - acc: 0.7411 - val_loss: 0.6938 - val_acc: 0.7225\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6842 - acc: 0.6939 - val_loss: 0.7079 - val_acc: 0.5694\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.5927 - acc: 0.6848 - val_loss: 0.5154 - val_acc: 0.8448\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.4988 - acc: 0.8231 - val_loss: 0.4236 - val_acc: 0.8638\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.4665 - acc: 0.8271 - val_loss: 0.4143 - val_acc: 0.8530\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 8s 137ms/step - loss: 0.4425 - acc: 0.8295 - val_loss: 0.3932 - val_acc: 0.8535\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.4278 - acc: 0.8275 - val_loss: 0.3688 - val_acc: 0.8608\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.4152 - acc: 0.8307 - val_loss: 0.3693 - val_acc: 0.8535\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.4043 - acc: 0.8259 - val_loss: 0.3514 - val_acc: 0.8540\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3928 - acc: 0.8304 - val_loss: 0.3612 - val_acc: 0.8412\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.3886 - acc: 0.8232 - val_loss: 0.3953 - val_acc: 0.8210\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.3766 - acc: 0.8329 - val_loss: 0.4074 - val_acc: 0.8159\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3700 - acc: 0.8321 - val_loss: 0.3637 - val_acc: 0.8396\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.3618 - acc: 0.8353 - val_loss: 0.3548 - val_acc: 0.8442\n",
            "Epoch 19: early stopping\n",
            "With LSTM_units = 128, dense_layer = 50, dense_activation = relu, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 137ms/step - loss: 0.6939 - acc: 0.2121 - val_loss: 0.6977 - val_acc: 0.2130\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6922 - acc: 0.6738 - val_loss: 0.6947 - val_acc: 0.7261\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.6901 - acc: 0.7409 - val_loss: 0.6947 - val_acc: 0.7179\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.6757 - acc: 0.6435 - val_loss: 0.6557 - val_acc: 0.7282\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.5406 - acc: 0.8112 - val_loss: 0.4950 - val_acc: 0.8525\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.4707 - acc: 0.8338 - val_loss: 0.4039 - val_acc: 0.8628\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.4406 - acc: 0.8270 - val_loss: 0.3804 - val_acc: 0.8690\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.4193 - acc: 0.8346 - val_loss: 0.3882 - val_acc: 0.8432\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.4067 - acc: 0.8268 - val_loss: 0.3587 - val_acc: 0.8556\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3914 - acc: 0.8351 - val_loss: 0.3973 - val_acc: 0.8283\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3757 - acc: 0.8346 - val_loss: 0.3284 - val_acc: 0.8649\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.3680 - acc: 0.8395 - val_loss: 0.3704 - val_acc: 0.8417\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3607 - acc: 0.8400 - val_loss: 0.3422 - val_acc: 0.8525\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 8s 138ms/step - loss: 0.3514 - acc: 0.8422 - val_loss: 0.3690 - val_acc: 0.8345\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 8s 137ms/step - loss: 0.3395 - acc: 0.8428 - val_loss: 0.3291 - val_acc: 0.8556\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3319 - acc: 0.8513 - val_loss: 0.3262 - val_acc: 0.8551\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3339 - acc: 0.8429 - val_loss: 0.2853 - val_acc: 0.8736\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3325 - acc: 0.8449 - val_loss: 0.3203 - val_acc: 0.8510\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.3138 - acc: 0.8503 - val_loss: 0.3199 - val_acc: 0.8556\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 8s 136ms/step - loss: 0.3116 - acc: 0.8496 - val_loss: 0.2906 - val_acc: 0.8695\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3060 - acc: 0.8561 - val_loss: 0.3159 - val_acc: 0.8520\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3002 - acc: 0.8616 - val_loss: 0.3183 - val_acc: 0.8540\n",
            "Epoch 22: early stopping\n",
            "With LSTM_units = 128, dense_layer = 50, dense_activation = relu, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 12s 144ms/step - loss: 0.6954 - acc: 0.7591 - val_loss: 0.6955 - val_acc: 0.7390\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 137ms/step - loss: 0.6931 - acc: 0.7528 - val_loss: 0.6958 - val_acc: 0.7313\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6913 - acc: 0.7518 - val_loss: 0.6961 - val_acc: 0.7246\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6885 - acc: 0.7280 - val_loss: 0.6931 - val_acc: 0.7133\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6344 - acc: 0.6825 - val_loss: 0.5218 - val_acc: 0.8566\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.5091 - acc: 0.8062 - val_loss: 0.4341 - val_acc: 0.8561\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.4560 - acc: 0.8245 - val_loss: 0.4385 - val_acc: 0.8236\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.4275 - acc: 0.8366 - val_loss: 0.3795 - val_acc: 0.8623\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.4095 - acc: 0.8426 - val_loss: 0.3782 - val_acc: 0.8546\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3953 - acc: 0.8455 - val_loss: 0.4386 - val_acc: 0.8149\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.3790 - acc: 0.8544 - val_loss: 0.4218 - val_acc: 0.8226\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3810 - acc: 0.8449 - val_loss: 0.3396 - val_acc: 0.8680\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3721 - acc: 0.8445 - val_loss: 0.4553 - val_acc: 0.7963\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3585 - acc: 0.8466 - val_loss: 0.3198 - val_acc: 0.8736\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3514 - acc: 0.8487 - val_loss: 0.3190 - val_acc: 0.8695\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3416 - acc: 0.8535 - val_loss: 0.3302 - val_acc: 0.8623\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.3384 - acc: 0.8549 - val_loss: 0.3058 - val_acc: 0.8736\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3287 - acc: 0.8591 - val_loss: 0.3007 - val_acc: 0.8783\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3241 - acc: 0.8551 - val_loss: 0.3186 - val_acc: 0.8582\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 8s 138ms/step - loss: 0.3189 - acc: 0.8570 - val_loss: 0.3327 - val_acc: 0.8484\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.3147 - acc: 0.8564 - val_loss: 0.2645 - val_acc: 0.8963\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3220 - acc: 0.8607 - val_loss: 0.3078 - val_acc: 0.8664\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.3039 - acc: 0.8656 - val_loss: 0.2868 - val_acc: 0.8834\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.3049 - acc: 0.8647 - val_loss: 0.2917 - val_acc: 0.8778\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3011 - acc: 0.8614 - val_loss: 0.3060 - val_acc: 0.8664\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.2944 - acc: 0.8658 - val_loss: 0.3209 - val_acc: 0.8597\n",
            "Epoch 26: early stopping\n",
            "With LSTM_units = 128, dense_layer = 50, dense_activation = relu, lr = 5e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 137ms/step - loss: 0.6945 - acc: 0.2539 - val_loss: 0.6966 - val_acc: 0.2367\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.6941 - acc: 0.6276 - val_loss: 0.6965 - val_acc: 0.7561\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.6938 - acc: 0.7638 - val_loss: 0.6963 - val_acc: 0.7571\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6935 - acc: 0.7593 - val_loss: 0.6964 - val_acc: 0.7499\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6932 - acc: 0.7544 - val_loss: 0.6963 - val_acc: 0.7452\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6928 - acc: 0.7545 - val_loss: 0.6956 - val_acc: 0.7421\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.6925 - acc: 0.7502 - val_loss: 0.6957 - val_acc: 0.7385\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6922 - acc: 0.7489 - val_loss: 0.6957 - val_acc: 0.7339\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6918 - acc: 0.7502 - val_loss: 0.6948 - val_acc: 0.7318\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6914 - acc: 0.7504 - val_loss: 0.6940 - val_acc: 0.7349\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6909 - acc: 0.7443 - val_loss: 0.6945 - val_acc: 0.7272\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6904 - acc: 0.7427 - val_loss: 0.6942 - val_acc: 0.7267\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6898 - acc: 0.7433 - val_loss: 0.6939 - val_acc: 0.7318\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6891 - acc: 0.7391 - val_loss: 0.6931 - val_acc: 0.7287\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6882 - acc: 0.7377 - val_loss: 0.6929 - val_acc: 0.7256\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.6868 - acc: 0.7341 - val_loss: 0.6926 - val_acc: 0.7163\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6844 - acc: 0.7199 - val_loss: 0.6946 - val_acc: 0.6885\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6776 - acc: 0.6819 - val_loss: 0.7005 - val_acc: 0.6173\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.6146 - acc: 0.6863 - val_loss: 0.6214 - val_acc: 0.8066\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.5243 - acc: 0.8119 - val_loss: 0.5322 - val_acc: 0.8448\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.4979 - acc: 0.8253 - val_loss: 0.5009 - val_acc: 0.8468\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.4770 - acc: 0.8275 - val_loss: 0.4579 - val_acc: 0.8587\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.4608 - acc: 0.8337 - val_loss: 0.4759 - val_acc: 0.8350\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.4513 - acc: 0.8355 - val_loss: 0.4306 - val_acc: 0.8520\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.4439 - acc: 0.8374 - val_loss: 0.4845 - val_acc: 0.8133\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.4376 - acc: 0.8389 - val_loss: 0.4204 - val_acc: 0.8520\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.4317 - acc: 0.8411 - val_loss: 0.4111 - val_acc: 0.8530\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.4273 - acc: 0.8440 - val_loss: 0.4193 - val_acc: 0.8468\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.4229 - acc: 0.8438 - val_loss: 0.3999 - val_acc: 0.8535\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.4204 - acc: 0.8433 - val_loss: 0.3952 - val_acc: 0.8520\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.4163 - acc: 0.8440 - val_loss: 0.3932 - val_acc: 0.8525\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.4139 - acc: 0.8386 - val_loss: 0.3744 - val_acc: 0.8633\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.4083 - acc: 0.8429 - val_loss: 0.3838 - val_acc: 0.8510\n",
            "Epoch 34/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.4048 - acc: 0.8437 - val_loss: 0.3844 - val_acc: 0.8499\n",
            "Epoch 35/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.4013 - acc: 0.8436 - val_loss: 0.3676 - val_acc: 0.8613\n",
            "Epoch 36/40\n",
            "61/61 [==============================] - 8s 127ms/step - loss: 0.3984 - acc: 0.8467 - val_loss: 0.3896 - val_acc: 0.8453\n",
            "Epoch 37/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.3953 - acc: 0.8451 - val_loss: 0.3721 - val_acc: 0.8577\n",
            "Epoch 38/40\n",
            "61/61 [==============================] - 8s 127ms/step - loss: 0.3924 - acc: 0.8454 - val_loss: 0.3588 - val_acc: 0.8633\n",
            "Epoch 39/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.3906 - acc: 0.8450 - val_loss: 0.3913 - val_acc: 0.8360\n",
            "Epoch 40/40\n",
            "61/61 [==============================] - 8s 127ms/step - loss: 0.3866 - acc: 0.8487 - val_loss: 0.3562 - val_acc: 0.8623\n",
            "With LSTM_units = 128, dense_layer = 50, dense_activation = sigmoid, lr = 1e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 135ms/step - loss: 0.6957 - acc: 0.7727 - val_loss: 0.6928 - val_acc: 0.7726\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 125ms/step - loss: 0.6951 - acc: 0.7768 - val_loss: 0.6939 - val_acc: 0.7519\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 126ms/step - loss: 0.6947 - acc: 0.6423 - val_loss: 0.6949 - val_acc: 0.7375\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6943 - acc: 0.7520 - val_loss: 0.6951 - val_acc: 0.7416\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 127ms/step - loss: 0.6940 - acc: 0.7502 - val_loss: 0.6954 - val_acc: 0.7354\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6936 - acc: 0.7442 - val_loss: 0.6958 - val_acc: 0.7313\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 128, dense_layer = 50, dense_activation = sigmoid, lr = 1e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 135ms/step - loss: 0.6944 - acc: 0.2346 - val_loss: 0.6927 - val_acc: 0.2310\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 127ms/step - loss: 0.6931 - acc: 0.3443 - val_loss: 0.6945 - val_acc: 0.7277\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6921 - acc: 0.7340 - val_loss: 0.6948 - val_acc: 0.7292\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6913 - acc: 0.7408 - val_loss: 0.6947 - val_acc: 0.7287\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6901 - acc: 0.7301 - val_loss: 0.6946 - val_acc: 0.7210\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 126ms/step - loss: 0.6878 - acc: 0.7185 - val_loss: 0.6985 - val_acc: 0.6797\n",
            "Epoch 6: early stopping\n",
            "With LSTM_units = 128, dense_layer = 50, dense_activation = sigmoid, lr = 3e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 134ms/step - loss: 0.6943 - acc: 0.7101 - val_loss: 0.6970 - val_acc: 0.7334\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 126ms/step - loss: 0.6932 - acc: 0.7418 - val_loss: 0.6950 - val_acc: 0.7344\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6922 - acc: 0.7449 - val_loss: 0.6948 - val_acc: 0.7282\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6911 - acc: 0.7438 - val_loss: 0.6929 - val_acc: 0.7277\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6898 - acc: 0.7359 - val_loss: 0.6919 - val_acc: 0.7303\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6870 - acc: 0.7252 - val_loss: 0.6956 - val_acc: 0.6916\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6689 - acc: 0.5792 - val_loss: 0.6742 - val_acc: 0.6766\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.5349 - acc: 0.8079 - val_loss: 0.5105 - val_acc: 0.8504\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.4762 - acc: 0.8422 - val_loss: 0.4468 - val_acc: 0.8659\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 8s 126ms/step - loss: 0.4538 - acc: 0.8524 - val_loss: 0.4043 - val_acc: 0.8716\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 8s 126ms/step - loss: 0.4396 - acc: 0.8504 - val_loss: 0.3815 - val_acc: 0.8788\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.4258 - acc: 0.8498 - val_loss: 0.4037 - val_acc: 0.8602\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.4184 - acc: 0.8487 - val_loss: 0.3882 - val_acc: 0.8628\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.4087 - acc: 0.8507 - val_loss: 0.3860 - val_acc: 0.8638\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.4030 - acc: 0.8494 - val_loss: 0.3541 - val_acc: 0.8762\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.3946 - acc: 0.8516 - val_loss: 0.3975 - val_acc: 0.8412\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.3850 - acc: 0.8487 - val_loss: 0.4193 - val_acc: 0.8241\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.3817 - acc: 0.8453 - val_loss: 0.3611 - val_acc: 0.8613\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 9s 155ms/step - loss: 0.3716 - acc: 0.8494 - val_loss: 0.3426 - val_acc: 0.8680\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.3662 - acc: 0.8471 - val_loss: 0.3898 - val_acc: 0.8288\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 8s 132ms/step - loss: 0.3619 - acc: 0.8493 - val_loss: 0.3879 - val_acc: 0.8308\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3575 - acc: 0.8502 - val_loss: 0.3183 - val_acc: 0.8804\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3479 - acc: 0.8580 - val_loss: 0.3802 - val_acc: 0.8360\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3479 - acc: 0.8529 - val_loss: 0.3364 - val_acc: 0.8623\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.3400 - acc: 0.8573 - val_loss: 0.3215 - val_acc: 0.8690\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3395 - acc: 0.8574 - val_loss: 0.2933 - val_acc: 0.8958\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.3333 - acc: 0.8556 - val_loss: 0.3358 - val_acc: 0.8618\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3319 - acc: 0.8570 - val_loss: 0.2990 - val_acc: 0.8855\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.3296 - acc: 0.8575 - val_loss: 0.2935 - val_acc: 0.8850\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.3187 - acc: 0.8629 - val_loss: 0.3164 - val_acc: 0.8695\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 8s 127ms/step - loss: 0.3167 - acc: 0.8624 - val_loss: 0.3573 - val_acc: 0.8494\n",
            "Epoch 31: early stopping\n",
            "With LSTM_units = 128, dense_layer = 50, dense_activation = sigmoid, lr = 3e-05, batch_size = 128 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 11s 136ms/step - loss: 0.6941 - acc: 0.7642 - val_loss: 0.6973 - val_acc: 0.7241\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.6921 - acc: 0.7380 - val_loss: 0.6949 - val_acc: 0.7241\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6884 - acc: 0.7159 - val_loss: 0.7023 - val_acc: 0.6472\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.6279 - acc: 0.6300 - val_loss: 0.6193 - val_acc: 0.8149\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.5134 - acc: 0.8264 - val_loss: 0.4700 - val_acc: 0.8561\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.4682 - acc: 0.8324 - val_loss: 0.4416 - val_acc: 0.8499\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.4392 - acc: 0.8419 - val_loss: 0.3961 - val_acc: 0.8618\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.4215 - acc: 0.8441 - val_loss: 0.4000 - val_acc: 0.8504\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 127ms/step - loss: 0.4106 - acc: 0.8431 - val_loss: 0.3596 - val_acc: 0.8669\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.3935 - acc: 0.8475 - val_loss: 0.3712 - val_acc: 0.8551\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3868 - acc: 0.8463 - val_loss: 0.3571 - val_acc: 0.8608\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3770 - acc: 0.8467 - val_loss: 0.3523 - val_acc: 0.8582\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3697 - acc: 0.8459 - val_loss: 0.3373 - val_acc: 0.8659\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.3608 - acc: 0.8500 - val_loss: 0.3340 - val_acc: 0.8685\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 8s 138ms/step - loss: 0.3515 - acc: 0.8529 - val_loss: 0.3636 - val_acc: 0.8422\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.3483 - acc: 0.8498 - val_loss: 0.3034 - val_acc: 0.8767\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3453 - acc: 0.8505 - val_loss: 0.2938 - val_acc: 0.8809\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.3348 - acc: 0.8560 - val_loss: 0.3188 - val_acc: 0.8747\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.3284 - acc: 0.8583 - val_loss: 0.2986 - val_acc: 0.8783\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.3228 - acc: 0.8593 - val_loss: 0.2973 - val_acc: 0.8804\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3212 - acc: 0.8579 - val_loss: 0.3234 - val_acc: 0.8587\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.3280 - acc: 0.8536 - val_loss: 0.3007 - val_acc: 0.8804\n",
            "Epoch 22: early stopping\n",
            "With LSTM_units = 128, dense_layer = 50, dense_activation = sigmoid, lr = 5e-05, batch_size = 64 done!!!\n",
            "Epoch 1/40\n",
            "61/61 [==============================] - 10s 136ms/step - loss: 0.6947 - acc: 0.7475 - val_loss: 0.6960 - val_acc: 0.7494\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6933 - acc: 0.7506 - val_loss: 0.6947 - val_acc: 0.7452\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.6917 - acc: 0.7511 - val_loss: 0.6953 - val_acc: 0.7318\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.6889 - acc: 0.7390 - val_loss: 0.6923 - val_acc: 0.7122\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.6019 - acc: 0.7279 - val_loss: 0.6500 - val_acc: 0.7679\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.4928 - acc: 0.8166 - val_loss: 0.4317 - val_acc: 0.8494\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.4511 - acc: 0.8166 - val_loss: 0.4227 - val_acc: 0.8288\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 8s 135ms/step - loss: 0.4289 - acc: 0.8132 - val_loss: 0.3929 - val_acc: 0.8468\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.4072 - acc: 0.8150 - val_loss: 0.3537 - val_acc: 0.8540\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.3885 - acc: 0.8244 - val_loss: 0.3829 - val_acc: 0.8360\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.3764 - acc: 0.8263 - val_loss: 0.3547 - val_acc: 0.8551\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3637 - acc: 0.8320 - val_loss: 0.3486 - val_acc: 0.8530\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.3560 - acc: 0.8331 - val_loss: 0.3765 - val_acc: 0.8272\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 9s 140ms/step - loss: 0.3485 - acc: 0.8364 - val_loss: 0.3227 - val_acc: 0.8664\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.3430 - acc: 0.8352 - val_loss: 0.3239 - val_acc: 0.8654\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.3339 - acc: 0.8382 - val_loss: 0.3013 - val_acc: 0.8690\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.3228 - acc: 0.8455 - val_loss: 0.3144 - val_acc: 0.8654\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.3186 - acc: 0.8447 - val_loss: 0.3343 - val_acc: 0.8525\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3131 - acc: 0.8468 - val_loss: 0.3145 - val_acc: 0.8597\n",
            "Epoch 20/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3113 - acc: 0.8486 - val_loss: 0.2959 - val_acc: 0.8700\n",
            "Epoch 21/40\n",
            "61/61 [==============================] - 8s 131ms/step - loss: 0.3031 - acc: 0.8524 - val_loss: 0.3031 - val_acc: 0.8638\n",
            "Epoch 22/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.3058 - acc: 0.8476 - val_loss: 0.3122 - val_acc: 0.8597\n",
            "Epoch 23/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.2926 - acc: 0.8554 - val_loss: 0.3022 - val_acc: 0.8654\n",
            "Epoch 24/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.2976 - acc: 0.8489 - val_loss: 0.3118 - val_acc: 0.8525\n",
            "Epoch 25/40\n",
            "61/61 [==============================] - 8s 130ms/step - loss: 0.2919 - acc: 0.8618 - val_loss: 0.2766 - val_acc: 0.8721\n",
            "Epoch 26/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.2873 - acc: 0.8575 - val_loss: 0.3251 - val_acc: 0.8412\n",
            "Epoch 27/40\n",
            "61/61 [==============================] - 8s 127ms/step - loss: 0.2823 - acc: 0.8622 - val_loss: 0.3267 - val_acc: 0.8427\n",
            "Epoch 28/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.2855 - acc: 0.8592 - val_loss: 0.2490 - val_acc: 0.8907\n",
            "Epoch 29/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.2801 - acc: 0.8669 - val_loss: 0.3040 - val_acc: 0.8633\n",
            "Epoch 30/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.2674 - acc: 0.8698 - val_loss: 0.3109 - val_acc: 0.8592\n",
            "Epoch 31/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.2678 - acc: 0.8696 - val_loss: 0.2839 - val_acc: 0.8706\n",
            "Epoch 32/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.2694 - acc: 0.8665 - val_loss: 0.2510 - val_acc: 0.8871\n",
            "Epoch 33/40\n",
            "61/61 [==============================] - 8s 128ms/step - loss: 0.2634 - acc: 0.8725 - val_loss: 0.2647 - val_acc: 0.8845\n",
            "Epoch 33: early stopping\n",
            "With LSTM_units = 128, dense_layer = 50, dense_activation = sigmoid, lr = 5e-05, batch_size = 128 done!!!\n"
          ]
        }
      ],
      "source": [
        "# Hyper parameter tunng ~ 3 hrs\n",
        "# Neural Network architecture\n",
        "#lr = 5e-5\n",
        "#optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "# Class weights\n",
        "class_weights = { # Newly added \n",
        "    0: 2.45, # Class 0 has the fewest samples, so we weight it higher\n",
        "    1: 0.63   # Class 1 has the most samples, so we weight it lower}\n",
        "}\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "\n",
        "ls = []\n",
        "lstm_result_dict = {}\n",
        "best_valid_acc = float()\n",
        "best_valid_loss = float()\n",
        "iteration = 1\n",
        "\n",
        "for units in (16,64, 128): \n",
        "  for dense_layer in (1,10, 50):\n",
        "    for dense_activation in ('relu','sigmoid'):\n",
        "      for lr in (1e-5,3e-5,5e-5):\n",
        "        for batch in (64, 128):\n",
        "          try:\n",
        "            lstm_model = Sequential()\n",
        "            embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "            lstm_model.add(embedding_layer)\n",
        "            lstm_model.add(LSTM(units))\n",
        "            lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "            lstm_model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['acc'])\n",
        "            lstm_model_history = lstm_model.fit(X_train, y_train, batch_size=128, epochs=40, verbose=1, validation_split=0.2,class_weight=class_weights, callbacks=[early_stop])\n",
        "            for acc,loss in zip(lstm_model_history.history['val_acc'],lstm_model_history.history['val_loss']):\n",
        "              if acc > best_valid_acc or loss < best_valid_loss:\n",
        "                best_valid_acc = acc\n",
        "                best_valid_loss = loss\n",
        "            lstm_result_dict[iteration] = {'LSTM_units': units, 'dense_layer': dense_layer, 'dense_activation': dense_activation, 'lr': lr, 'batch_size': batch, 'Validation_acc': best_valid_acc, 'Validation_lss': best_valid_loss} \n",
        "            print(f\"With LSTM_units = {units}, dense_layer = {dense_layer}, dense_activation = {dense_activation}, lr = {lr}, batch_size = {batch} done!!!\")\n",
        "            keras.backend.clear_session()\n",
        "            iteration += 1\n",
        "          except:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wRp61ZJufMI"
      },
      "outputs": [],
      "source": [
        "#Create json file and move to drive\n",
        "import json\n",
        "\n",
        "file_path = \"lstm_result_dict.json\"\n",
        "\n",
        "with open(file_path, \"w\") as json_file:\n",
        "    json.dump(lstm_result_dict, json_file)\n",
        "\n",
        "!cp '/content/lstm_result_dict.json' '/content/drive/MyDrive/lstm_result_dict.json'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sU5KbJ4Cu4Th"
      },
      "outputs": [],
      "source": [
        "lr = 5e-5\n",
        "optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "# Class weights\n",
        "class_weights = { # Newly added \n",
        "    0: 2.45, # Class 0 has the fewest samples, so we weight it higher\n",
        "    1: 0.63   # Class 1 has the most samples, so we weight it lower}\n",
        "}\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMPTSDVQtdlk"
      },
      "outputs": [],
      "source": [
        "# Neural Network architecture\n",
        "\n",
        "lstm_model = Sequential()\n",
        "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "\n",
        "lstm_model.add(embedding_layer)\n",
        "lstm_model.add(LSTM(64))\n",
        "\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uMIrcJbRpBS",
        "outputId": "e67a4654-c285-4f8a-e4c7-186c2791668e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 100)          928100    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                42240     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 970,405\n",
            "Trainable params: 42,305\n",
            "Non-trainable params: 928,100\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Model compiling\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(lstm_model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EKbr5h5RsoH",
        "outputId": "55ffe9f7-e198-461c-9ee3-e7b67d2020e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "61/61 [==============================] - 9s 148ms/step - loss: 0.2222 - acc: 0.9265 - val_loss: 0.2814 - val_acc: 0.9025\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 9s 150ms/step - loss: 0.2217 - acc: 0.9237 - val_loss: 0.2327 - val_acc: 0.9304\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 9s 142ms/step - loss: 0.1529 - acc: 0.9488 - val_loss: 0.2299 - val_acc: 0.9278\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 8s 129ms/step - loss: 0.1275 - acc: 0.9620 - val_loss: 0.2288 - val_acc: 0.9350\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 9s 154ms/step - loss: 0.1156 - acc: 0.9678 - val_loss: 0.2116 - val_acc: 0.9360\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 9s 144ms/step - loss: 0.1142 - acc: 0.9696 - val_loss: 0.2029 - val_acc: 0.9412\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 8s 137ms/step - loss: 0.1167 - acc: 0.9672 - val_loss: 0.2134 - val_acc: 0.9391\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 9s 146ms/step - loss: 0.1182 - acc: 0.9667 - val_loss: 0.2209 - val_acc: 0.9391\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 8s 134ms/step - loss: 0.1089 - acc: 0.9701 - val_loss: 0.2048 - val_acc: 0.9448\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 8s 126ms/step - loss: 0.1100 - acc: 0.9693 - val_loss: 0.1992 - val_acc: 0.9422\n",
            "Epoch 11/40\n",
            "61/61 [==============================] - 9s 147ms/step - loss: 0.1184 - acc: 0.9653 - val_loss: 0.2497 - val_acc: 0.9247\n",
            "Epoch 12/40\n",
            "61/61 [==============================] - 8s 124ms/step - loss: 0.1232 - acc: 0.9658 - val_loss: 0.2550 - val_acc: 0.9299\n",
            "Epoch 13/40\n",
            "61/61 [==============================] - 9s 149ms/step - loss: 0.1107 - acc: 0.9714 - val_loss: 0.2275 - val_acc: 0.9381\n",
            "Epoch 14/40\n",
            "61/61 [==============================] - 9s 143ms/step - loss: 0.1440 - acc: 0.9537 - val_loss: 0.1776 - val_acc: 0.9422\n",
            "Epoch 15/40\n",
            "61/61 [==============================] - 7s 120ms/step - loss: 0.1822 - acc: 0.9439 - val_loss: 0.2070 - val_acc: 0.9350\n",
            "Epoch 16/40\n",
            "61/61 [==============================] - 9s 146ms/step - loss: 0.1689 - acc: 0.9420 - val_loss: 0.1962 - val_acc: 0.9458\n",
            "Epoch 17/40\n",
            "61/61 [==============================] - 9s 154ms/step - loss: 0.1036 - acc: 0.9707 - val_loss: 0.2060 - val_acc: 0.9448\n",
            "Epoch 18/40\n",
            "61/61 [==============================] - 8s 133ms/step - loss: 0.0918 - acc: 0.9754 - val_loss: 0.2587 - val_acc: 0.9293\n",
            "Epoch 19/40\n",
            "61/61 [==============================] - 9s 145ms/step - loss: 0.0971 - acc: 0.9723 - val_loss: 0.2013 - val_acc: 0.9469\n",
            "Epoch 19: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Model Training\n",
        "\n",
        "lstm_model_history = lstm_model.fit(X_train, y_train, batch_size=128, epochs=40, verbose=1, validation_split=0.2,class_weight=class_weights, callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01bG4gVdRqow",
        "outputId": "6c1400aa-6e77-414c-a9f6-3aa62a4a40f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "76/76 [==============================] - 4s 40ms/step - loss: 0.1780 - acc: 0.9625\n"
          ]
        }
      ],
      "source": [
        "# Predictions on the Test Set\n",
        "\n",
        "score = lstm_model.evaluate(X_test, y_test, verbose=1)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pirEwt4TEb7",
        "outputId": "c2651e1b-0abd-4765-b852-4fd59af8285b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Score: 0.17798708379268646\n",
            "Test Accuracy: 0.9624587297439575\n"
          ]
        }
      ],
      "source": [
        "# Model Performance\n",
        "\n",
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3qoptYnSOQ0",
        "outputId": "0072ad2f-280b-4c51-94d7-94805d195012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "76/76 [==============================] - 4s 52ms/step\n"
          ]
        }
      ],
      "source": [
        "Y_pred_prob = lstm_model.predict(X_test)\n",
        "\n",
        "y_pred = (Y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "C_M = confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "WT_-8XVqmvAf",
        "outputId": "337e7157-8469-4ae6-ca43-28f558d6aab2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "76/76 [==============================] - 2s 25ms/step\n",
            "test_accuracy: 0.950\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Y_pred_prob = lstm_model.predict(X_test)\n",
        "\n",
        "y_pred = (Y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "C_M = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Define labels\n",
        "labels = {0: \"Negative\", 1: \"Positive\"}\n",
        "\n",
        "# Plot confusion matrix\n",
        "sns.set(font_scale=1.5)\n",
        "ax = sns.heatmap(C_M, annot=True, fmt=\"d\", xticklabels=labels.values(), yticklabels=labels.values())\n",
        "ax.set_title(\"Confusion Matrix Sentiments\")\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('test_accuracy: %.3f' % (acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erdVwkbfmvWP",
        "outputId": "a4c8daec-61e4-4120-f203-609f094b0230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9624587458745875\n",
            "0.9383414475819539\n",
            "0.9623202722662944\n",
            "0.9624587458745875\n",
            "0.9623832538437331\n",
            "0.9624587458745875\n",
            "0.8987341772151899\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score,balanced_accuracy_score,confusion_matrix\n",
        "\n",
        "Accuracy_LSTM = accuracy_score(y_test, y_pred)\n",
        "Balanced_accuracy_LSTM = balanced_accuracy_score(y_test, y_pred)\n",
        "Precision_LSTM = precision_score(y_test, y_pred,average = 'weighted')\n",
        "Recall_LSTM = recall_score(y_test, y_pred,average = 'weighted')\n",
        "F1_score_LSTM = f1_score(y_test, y_pred,average = 'weighted') \n",
        "sensitivity_LSTM = Recall_LSTM\n",
        "specificity_LSTM =  C_M[0][0] / (C_M[0][0] + C_M[0][1])\n",
        " \n",
        "\n",
        "print(Accuracy_LSTM)\n",
        "print(Balanced_accuracy_LSTM)\n",
        "print(Precision_LSTM)\n",
        "print(Recall_LSTM)\n",
        "print(F1_score_LSTM)\n",
        "print(sensitivity_LSTM)\n",
        "print(specificity_LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        },
        "id": "j14BNkphTLRP",
        "outputId": "56c845f1-c806-43ee-dec6-44adef39d5eb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Model Performance Charts\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(lstm_model_history.history['acc'])\n",
        "plt.plot(lstm_model_history.history['val_acc'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(lstm_model_history.history['loss'])\n",
        "plt.plot(lstm_model_history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loYnp92lEzVC"
      },
      "outputs": [],
      "source": [
        "# Saving the model as a h5 file for possible use later\n",
        "lstm_model.save(f\"./drive/MyDrive/c1_lstm_model_acc_{round(score[1], 3)}.h5\", save_format='h5')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmd81HRe6ONn"
      },
      "source": [
        "# CNN-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seId5-lT6UWn"
      },
      "outputs": [],
      "source": [
        "from keras.layers import LSTM,Conv1D,MaxPooling1D\n",
        "import numpy as np\n",
        "np.random.seed(121)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0NcGFAM6VnK"
      },
      "outputs": [],
      "source": [
        "lr = 5e-5\n",
        "optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "# Class weights\n",
        "class_weights = { # Newly added \n",
        "    0: 2.45, # Class 0 has the fewest samples, so we weight it higher\n",
        "    1: 0.63   # Class 1 has the most samples, so we weight it lower}\n",
        "}\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHNJs0ns6YO1"
      },
      "outputs": [],
      "source": [
        "# Neural Network architecture\n",
        "\n",
        "cnn_lstm_model = Sequential()\n",
        "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
        "\n",
        "cnn_lstm_model.add(embedding_layer)\n",
        "cnn_lstm_model.add(Conv1D(128, 3, activation='relu'))\n",
        "cnn_lstm_model.add(MaxPooling1D(pool_size=2))\n",
        "#cnn_lstm_model.add(Flatten())\n",
        "cnn_lstm_model.add(LSTM(64))\n",
        "cnn_lstm_model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9sTVbFz7B1U",
        "outputId": "70e7021f-9cdb-48d8-f733-e9e97b833342"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_14 (Embedding)    (None, 100, 100)          928100    \n",
            "                                                                 \n",
            " conv1d_12 (Conv1D)          (None, 98, 128)           38528     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 49, 128)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,016,101\n",
            "Trainable params: 88,001\n",
            "Non-trainable params: 928,100\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Model compiling\n",
        "\n",
        "cnn_lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(cnn_lstm_model.summary())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5bt1CFr-HOZ",
        "outputId": "8f4a5f27-dca7-41a8-ac59-579905aa97d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "61/61 [==============================] - 1s 10ms/step - loss: 0.6235 - acc: 0.7471 - val_loss: 0.4003 - val_acc: 0.7849\n",
            "Epoch 2/40\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.3510 - acc: 0.8422 - val_loss: 0.2878 - val_acc: 0.9015\n",
            "Epoch 3/40\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.2326 - acc: 0.9177 - val_loss: 0.2922 - val_acc: 0.8969\n",
            "Epoch 4/40\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.1088 - acc: 0.9669 - val_loss: 0.2034 - val_acc: 0.9340\n",
            "Epoch 5/40\n",
            "61/61 [==============================] - 0s 7ms/step - loss: 0.0850 - acc: 0.9769 - val_loss: 0.1576 - val_acc: 0.9562\n",
            "Epoch 6/40\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0702 - acc: 0.9825 - val_loss: 0.2092 - val_acc: 0.9453\n",
            "Epoch 7/40\n",
            "61/61 [==============================] - 1s 8ms/step - loss: 0.0637 - acc: 0.9836 - val_loss: 0.1778 - val_acc: 0.9546\n",
            "Epoch 8/40\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0915 - acc: 0.9728 - val_loss: 0.1831 - val_acc: 0.9510\n",
            "Epoch 9/40\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0533 - acc: 0.9903 - val_loss: 0.1702 - val_acc: 0.9551\n",
            "Epoch 10/40\n",
            "61/61 [==============================] - 0s 8ms/step - loss: 0.0493 - acc: 0.9912 - val_loss: 0.1796 - val_acc: 0.9531\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Model training\n",
        "\n",
        "cnn_lstm_model_history = cnn_lstm_model.fit(X_train, y_train, batch_size=128, epochs=40, verbose=1, validation_split=0.2,class_weight=class_weights, callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyV2YzkO-uiG",
        "outputId": "bb29d87f-e01e-4800-a375-465a8b14865f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "76/76 [==============================] - 0s 4ms/step - loss: 0.1717 - acc: 0.9521\n"
          ]
        }
      ],
      "source": [
        "# Predictions on the Test Set\n",
        "\n",
        "score = cnn_lstm_model.evaluate(X_test, y_test, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGRmDENv_PgZ",
        "outputId": "7c9662fd-de37-4f35-de90-8ac7c53f6181"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Score: 0.17172713577747345\n",
            "Test Accuracy: 0.9521452188491821\n"
          ]
        }
      ],
      "source": [
        "# Model Performance\n",
        "\n",
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "IaXmKbQf_S3g",
        "outputId": "04f5d652-b4b4-4235-a768-dcba006bb155"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABq7UlEQVR4nO3dd3hUVf7H8fdk0juQAoGQhISq9CZVVBRFWQsCYqHYVgVbfhZQsK6y1kVBRXfFsjYUy6ooiqEJIigCCtISeiAVkpCezNzfH5cMxIQWJpkk83k9zzzM3Nw595sEmY/nnHuOxTAMAxERERE34uHqAkRERETqmgKQiIiIuB0FIBEREXE7CkAiIiLidhSARERExO0oAImIiIjbUQASERERt6MAJCIiIm5HAUhERETcjgKQiNSpXbt2YbFYePvtt0/7vUuXLsVisbB06VKn1yUi7kUBSERERNyOApCIiIi4HQUgEREXKygocHUJIm5HAUjEzTz22GNYLBa2bdvG9ddfT0hICOHh4UyfPh3DMNi7dy+XX345wcHBNG/enBdeeKFKGxkZGdx0001ERkbi6+tL165deeedd6qcl5OTw4QJEwgJCSE0NJTx48eTk5NTbV1btmzh6quvpmnTpvj6+tKrVy++/PLLGn2Pu3fv5o477qB9+/b4+fnRrFkzRo0axa5du6qt8d577yU2NhYfHx9atWrFuHHjyMrKcpxTXFzMY489Rrt27fD19aVFixZcddVVpKSkAMefm1TdfKcJEyYQGBhISkoKw4cPJygoiOuuuw6AH3/8kVGjRtG6dWt8fHyIjo7m3nvvpaioqNqf1+jRowkPD8fPz4/27dvz8MMPA7BkyRIsFguff/55lfd98MEHWCwWVq1adbo/VpFGxdPVBYiIa4wZM4aOHTvyz3/+kwULFvCPf/yDpk2b8vrrr3P++efzzDPP8P7773PffffRu3dvBg8eDEBRURFDhgwhOTmZyZMnExcXxyeffMKECRPIycnh7rvvBsAwDC6//HJWrFjBbbfdRseOHfn8888ZP358lVo2bdrEgAEDaNmyJVOmTCEgIICPP/6YK664gk8//ZQrr7zytL63X375hZ9++olrrrmGVq1asWvXLl577TWGDBnCn3/+ib+/PwD5+fkMGjSIzZs3c+ONN9KjRw+ysrL48ssv2bdvH2FhYdhsNi677DKSkpK45ppruPvuuzl8+DCLFi1i48aNxMfHn/bPvry8nGHDhjFw4ECef/55Rz2ffPIJhYWF3H777TRr1ow1a9Ywa9Ys9u3bxyeffOJ4/++//86gQYPw8vLi1ltvJTY2lpSUFL766iueeuophgwZQnR0NO+//36Vn937779PfHw8/fr1O+26RRoVQ0TcyqOPPmoAxq233uo4Vl5ebrRq1cqwWCzGP//5T8fxQ4cOGX5+fsb48eMdx2bOnGkAxnvvvec4VlpaavTr188IDAw08vLyDMMwjC+++MIAjGeffbbSdQYNGmQAxltvveU4fsEFFxidO3c2iouLHcfsdrvRv39/o23bto5jS5YsMQBjyZIlJ/weCwsLqxxbtWqVARjvvvuu49gjjzxiAMZnn31W5Xy73W4YhmHMnTvXAIwXX3zxuOccr66dO3dW+V7Hjx9vAMaUKVNOqe4ZM2YYFovF2L17t+PY4MGDjaCgoErHjq3HMAxj6tSpho+Pj5GTk+M4lpGRYXh6ehqPPvpoleuIuBsNgYm4qZtvvtnx3Gq10qtXLwzD4KabbnIcDw0NpX379uzYscNx7JtvvqF58+aMHTvWcczLy4u77rqL/Px8li1b5jjP09OT22+/vdJ17rzzzkp1HDx4kMWLFzN69GgOHz5MVlYWWVlZZGdnM2zYMLZv305qauppfW9+fn6O52VlZWRnZ5OQkEBoaCi//fab42uffvopXbt2rbaHyWKxOM4JCwurUvex59TEsT+X6uouKCggKyuL/v37YxgG69atAyAzM5Ply5dz44030rp16+PWM27cOEpKSpg/f77j2Lx58ygvL+f666+vcd0ijYUCkIib+uuHZ0hICL6+voSFhVU5fujQIcfr3bt307ZtWzw8Kv/z0bFjR8fXK/5s0aIFgYGBlc5r3759pdfJyckYhsH06dMJDw+v9Hj00UcBc87R6SgqKuKRRx4hOjoaHx8fwsLCCA8PJycnh9zcXMd5KSkpnH322SdsKyUlhfbt2+Pp6bwZA56enrRq1arK8T179jBhwgSaNm1KYGAg4eHhnHvuuQCOuivC6Mnq7tChA7179+b99993HHv//fc555xzSEhIcNa3ItJgaQ6QiJuyWq2ndAzM+Ty1xW63A3DfffcxbNiwas853Q/sO++8k7feeot77rmHfv36ERISgsVi4ZprrnFcz5mO1xNks9mqPe7j41MlQNpsNi688EIOHjzIgw8+SIcOHQgICCA1NZUJEybUqO5x48Zx9913s2/fPkpKSvj555+ZPXv2abcj0hgpAInIaYmJieH333/HbrdX+hDfsmWL4+sVfyYlJZGfn1+pF2jr1q2V2mvTpg1gDqMNHTrUKTXOnz+f8ePHV7qDrbi4uModaPHx8WzcuPGEbcXHx7N69WrKysrw8vKq9pwmTZoAVGm/ojfsVPzxxx9s27aNd955h3HjxjmOL1q0qNJ5FT+vk9UNcM0115CYmMiHH35IUVERXl5ejBkz5pRrEmnMNAQmIqdl+PDhpKWlMW/ePMex8vJyZs2aRWBgoGPIZvjw4ZSXl/Paa685zrPZbMyaNatSexEREQwZMoTXX3+dAwcOVLleZmbmaddotVqr9FrNmjWrSo/MyJEj2bBhQ7W3i1e8f+TIkWRlZVXbc1JxTkxMDFarleXLl1f6+quvvnpaNR/bZsXzl156qdJ54eHhDB48mLlz57Jnz55q66kQFhbGJZdcwnvvvcf777/PxRdfXGWIU8RdqQdIRE7Lrbfeyuuvv86ECRNYu3YtsbGxzJ8/n5UrVzJz5kyCgoIAGDFiBAMGDGDKlCns2rWLTp068dlnn1Wag1PhlVdeYeDAgXTu3JlbbrmFNm3akJ6ezqpVq9i3bx8bNmw4rRovu+wy/vvf/xISEkKnTp1YtWoVP/zwA82aNat03v3338/8+fMZNWoUN954Iz179uTgwYN8+eWXzJkzh65duzJu3DjeffddEhMTWbNmDYMGDaKgoIAffviBO+64g8svv5yQkBBGjRrFrFmzsFgsxMfH8/XXX5/W3KUOHToQHx/PfffdR2pqKsHBwXz66aeV5l9VePnllxk4cCA9evTg1ltvJS4ujl27drFgwQLWr19f6dxx48Zx9dVXA/Dkk0+e1s9RpFFz1e1nIuIaFbfBZ2ZmVjo+fvx4IyAgoMr55557rnHWWWdVOpaenm5MnDjRCAsLM7y9vY3OnTtXutW7QnZ2tnHDDTcYwcHBRkhIiHHDDTcY69atq3JruGEYRkpKijFu3DijefPmhpeXl9GyZUvjsssuM+bPn+8451Rvgz906JCjvsDAQGPYsGHGli1bjJiYmEq39FfUOHnyZKNly5aGt7e30apVK2P8+PFGVlaW45zCwkLj4YcfNuLi4gwvLy+jefPmxtVXX22kpKQ4zsnMzDRGjhxp+Pv7G02aNDH+/ve/Gxs3bqz2Nvjqfs6GYRh//vmnMXToUCMwMNAICwszbrnlFmPDhg3V/rw2btxoXHnllUZoaKjh6+trtG/f3pg+fXqVNktKSowmTZoYISEhRlFR0Ql/biLuxGIYtTi7UUREXKq8vJyoqChGjBjBm2++6epyROoNzQESEWnEvvjiCzIzMytNrBYRUA+QiEgjtHr1an7//XeefPJJwsLCKi0AKSLqARIRaZRee+01br/9diIiInj33XddXY5IvaMeIBEREXE76gESERERt6MAJCIiIm5HCyFWw263s3//foKCgs5ot2cRERGpO4ZhcPjwYaKioqrst/dXCkDV2L9/P9HR0a4uQ0RERGpg7969tGrV6oTnuDQALV++nOeee461a9dy4MABPv/8c6644ooTvmfp0qUkJiayadMmoqOjmTZtGhMmTKh0ziuvvMJzzz1HWloaXbt2ZdasWfTp0+eU66pYyn/v3r0EBwef7rclIiIiLpCXl0d0dLTjc/xEXBqACgoK6Nq1KzfeeCNXXXXVSc/fuXMnl156Kbfddhvvv/8+SUlJ3HzzzbRo0YJhw4YBMG/ePBITE5kzZw59+/Zl5syZDBs2jK1btxIREXFKdVUMewUHBysAiYiINDCnMn2l3twGb7FYTtoD9OCDD7JgwQI2btzoOHbNNdeQk5PDwoULAejbty+9e/d27Nxst9uJjo7mzjvvZMqUKadUS15eHiEhIeTm5ioAiYiINBCn8/ndoO4CW7VqFUOHDq10bNiwYaxatQqA0tJS1q5dW+kcDw8Phg4d6jinOiUlJeTl5VV6iIiISOPVoAJQWloakZGRlY5FRkaSl5dHUVERWVlZ2Gy2as9JS0s7brszZswgJCTE8dAEaBERkcZNd4EBU6dOJTEx0fG6YhLVydhsNsrKymqztEbL29v7pLcoioiI1JYGFYCaN29Oenp6pWPp6ekEBwfj5+eH1WrFarVWe07z5s2P266Pjw8+Pj6nXIdhGKSlpZGTk3Na9ctRHh4exMXF4e3t7epSRETEDTWoANSvXz+++eabSscWLVpEv379ALNXoWfPniQlJTkmU9vtdpKSkpg8ebLT6qgIPxEREfj7+2uxxNNUsdDkgQMHaN26tX5+IiJS51wagPLz80lOTna83rlzJ+vXr6dp06a0bt2aqVOnkpqa6tjJ+LbbbmP27Nk88MAD3HjjjSxevJiPP/6YBQsWONpITExk/Pjx9OrViz59+jBz5kwKCgqYOHGiU2q22WyO8NOsWTOntOmOwsPD2b9/P+Xl5Xh5ebm6HBERcTMuDUC//vor5513nuN1xTyc8ePH8/bbb3PgwAH27Nnj+HpcXBwLFizg3nvv5aWXXqJVq1b85z//cawBBDBmzBgyMzN55JFHSEtLo1u3bixcuLDKxOiaqpjz4+/v75T23FXF0JfNZlMAEhGROldv1gGqT060jkBxcTE7d+4kLi4OX19fF1XY8OnnKCIiztZo1wESERERcQYFIKmR2NhYZs6c6eoyREREaqRB3QUmZ2bIkCF069bNKcHll19+ISAg4MyLEhERcQEFIHEwDAObzYan58n/WoSHh9dBRSIi0tAZhkGZzaDMZqe03G7+abMT6ONJqL/r1oJTAHITEyZMYNmyZSxbtoyXXnoJgLfeeouJEyfyzTffMG3aNP744w++//57oqOjSUxM5Oeff6agoICOHTsyY8aMSnusxcbGcs8993DPPfcA5ma2//73v1mwYAHfffcdLVu25IUXXuBvf/ubK75dERG3YbcblNrMYFFmMxwho6S84pgZPEr/8vVK5/zl66WVjtkpLTccxyoCzLFhpqzcqNTe0XPN91XnzvMT+L+L2tfxT+soBSAnMAyDojJbnV/Xz8t6yosIvvTSS2zbto2zzz6bJ554AoBNmzYBMGXKFJ5//nnatGlDkyZN2Lt3L8OHD+epp57Cx8eHd999lxEjRrB161Zat2593Gs8/vjjPPvsszz33HPMmjWL6667jt27d9O0adMz/2ZFRNzY/pwi3li+g6Qt6RSV2iv1ppTbG9bN3B4W8Pb0wNVL4CoAOUFRmY1Oj3xX59f984lh+Huf2q8wJCQEb29v/P39HduCbNmyBYAnnniCCy+80HFu06ZN6dq1q+P1k08+yeeff86XX355whW1J0yYwNixYwF4+umnefnll1mzZg0XX3zxaX9vIiICu7IKmLMshU9/20eZ7dSCjpfVgpfVAy+rB96eHnhbPfCyWvD29Djhce8jxyufY3E897J64OXpgY/VAy9PC95Wq3ktx7Fj2/nL+6we+Bx5bvVwdfQxKQAJvXr1qvQ6Pz+fxx57jAULFnDgwAHKy8spKiqqtChldbp06eJ4HhAQQHBwMBkZGbVSs4hIY7Yt/TCvLEnmqw37qejg6demGbcMjiMq1K9KYDH/tODl4YFHPQkY9Z0CkBP4eVn584lhJz+xFq7rDH+9m+u+++5j0aJFPP/88yQkJODn58fVV19NaWnpCdv564rOFosFu736sV8REanqj325zF6yne82Hd3U+7z24Uw+P4GeMZpO4EwKQE5gsVhOeSjKlby9vbHZTj5XaeXKlUyYMIErr7wSMHuEdu3aVcvViYi4r192HWT24mSWbcsEwGKBi89qzqTzEji7ZYiLq2uc6v+ntjhNbGwsq1evZteuXQQGBh63d6Zt27Z89tlnjBgxAovFwvTp09WTIyLiZIZhsCI5i1mLk1mz8yAAVg8Ll3eN4o7z4kmICHJxhY2bApAbue+++xg/fjydOnWiqKiIt956q9rzXnzxRW688Ub69+9PWFgYDz74IHl5eXVcrYhI42S3GyRtyWD24u1s2JcLmBOXr+4Zze3nxtO6mTbbrgvaDLUa2gy19unnKCLuxmY3WPDHAV5dksyWtMMA+Hp5MLZPa24d3IYWIX4urrDhO53NUNUDJCIiUovKbHY+X5fKa0tT2JlVAECgjyc39IvhpoFxhAX6uLhC96QAJCLSSFRsOVBSbqO4zE5JuY2ScjslxzwvLjtyrNxOyTHPjx63HTnffB7g7cngduEMTAjDz9s5d566i+IyG5/8upc5y3aQmlMEQKi/FzcOiGN8v1hC/L1O0oLUJgUgEREns9kN8ovLqwaRY8JFpcBxTEg5peBygnZqY1LDf3/ejY+nB/3jm3F+x0jO7xBBy1AN1xxPQUk576/ezb9/3Enm4RIAwgJ9uHVwHNf1jSHARx+99YF+CyIiNZRbWEZKVj47MgvYkXnkz6x8dmUXUlru+jsnvT098PX0wMfLio+nx5GHFR8vD3yP/Ok45unxl+PmsdScIpI2Z5CaU8SSrZks2ZrJdKBji2Au6BDB+R0j6NoqtN6s7utKuUVlvPPTLuau3ElOYRkALUP9+Pu5bRjdKxpfJ63dJs6hACQicgJlNjt7DhZWCTk7MgvILjjx4qAWC/h6WvH1Oho8jg0cvl5Hg4cjhFQ6XjW4VN/OX75+ZJsDZ60I/PjfDLal55O0JZ3FmzP4bc8hNh/IY/OBPGYvSaZZgDdD2kdwQccIBrUNI8jXvYZ2svNLeHPFTt5dtZv8knIA4sICuH1IPFd0a4m3p4eLK5TqKACJiNszDIPsgtKjISfraNjZc7DwhJtNRgb70CYskDbhAbQJN/+MDwukeYgvXlbLKW9YXJ9ZLBbaNw+iffMg7hiSwMGCUpZty+CHzRks35pJdkEpn/62j09/24eX1ULfuGac38EMRDHNAk5+gQbqQK65QemHa/ZQXGb2+LWPDGLS+Qlc2rmFesXqOQUgEXEbxWU2dmcXOkJOSubR4au84vLjvs/Py0pcWIAj5MSHB9AmLJC48AAC3XA+R9MAb67s3ooru7eizGbnl10HWbw5g6QtGezMKmBFchYrkrN44us/iQ8PYOiReUM9Y5rgaW34vSF7sgt5bVkK89fudWxQ2rVVCJPOS2Box0jtxdVAuN9/uSLSqBmGQXpeCTsy80nJqjxslXqoiON15lgsEBXiZ/bgHOnJqejZaR7sqw+14/CyetA/Poz+8WFMu6wTOzLzWbwlg6TNGfyy6yApmQWkZO7g9eU7CPb1dAyVndsunFB/b1eXf1qSMw7z6pIU/rdhP7Yjf5H6xDXlzvMTGJgQ1ih6+9yJApCINEiFpeVHgk3lkLMzs4CC0uPveRfk43l0uCrs6LBVXFiAJqk6gfnzDOTmQW3ILSrjx+2ZLN6cwZKtGRwqLOPLDfv5csN+rB4WesY04YIjQ2Xx4YH1NkBsTM3llSXJLNyU5rjL7tx25galvWO1QWlDpQAkIvWW3W6QmlNUJeTsyCzgQG7xcd9n9bAQ3cSvSshpEx5AeKBPvf2gbWxC/Ly4rEsUl3WJwmY3WLfnEElbMli8OYOt6YdZs/Mga3YeZMa3W2jd1J8LOkZwQYdI+sQ1rRcTh9fuNjcoXbI103Fs2FmRTDovgS6tQl1XmDiFtsKoRmPdCmPIkCF069aNmTNnOqW9CRMmkJOTwxdffHHa723IP0epHbmFZfyUksWm/XmOkLMzq4CSE9xO3sTfq0rIiQ8PoHXTgHrxASrHt/dgIUu2mhOpf07JptR29Pcc6OPJoLZhnN8hgvM6RNTpSsmGYfBTSjazFyezakc2AB4WGNE1ijuGJNC+uTYorc+0FYaI1HvlNjsb9uWyfFsmy7dnsmFvTrXzc7ysFmKaBVQJOW3CAmkS0LDmkMhR0U39GdcvlnH9YikoKWdFcpZjInVWfgnfbkzj241pWCzQLTrUXHOoQyQdWwTVSg+eYRgs3pLBrMXJrN+bA5h/967q3orbh8QTG9Z472ZzV+oBqkZj7AGaMGEC77zzTqVjO3fuJD8/n/vvv58ff/yRgIAALrroIv71r38RFhYGwPz583n88cdJTk7G39+f7t2787///Y/nnnuOxx9/vFJ7S5YsYciQIadUT0P9OcqZSc0pMgPPtkxWJmdVufMqISKQ3rFNKk1CbtXEr1HcOSSnxm432Lg/lx82Z7B4SzobU/MqfT0qxJfzjwyV9Ytvdsbztmx2g283HuCVJSlsPmBey8fz6AalUVrxukE5nR4gBaBqnHYAMgwoK6z7Qr38zVtXTkFubi6XXHIJZ599Nk888YT5di8vOnbsyM0338y4ceMoKiriwQcfpLy8nMWLF3PgwAFat27Ns88+y5VXXsnhw4f58ccfGTduHAA33XQTeXl5vPXWWwA0bdoUb+9T+z9yBSD3UFhazuodB1m2LZMft2eSkllQ6eshfl4MTAhjcLswBrUN14eNVJGWW8ySreZdZSuSMx3r7YC5k/rAhDDO72DeZt885NT/LSmz2fnf+v28ujSZHUf+XgZ4W7m+Xww3D2xDeJA2KG2INARW18oK4emour/uQ/vB+9S6ZUNCQvD29sbf35/mzZsD8I9//IPu3bvz9NNPO86bO3cu0dHRbNu2jfz8fMrLy7nqqquIiYkBoHPnzo5z/fz8KCkpcbQnYhgGmw8cZvl2M/D8svNQpbkdHhbo3roJg9qGMbhduLZQkJNqHuLL2D6tGdunNcVlNlalZDtWpN6fW8wPm815RABntwzm/A6RXNAhgs4tQ6pduqC4zMb8tfuYsyyFfYfMDUpD/LyY0D+WiQNiG9yt+VJzCkBubMOGDSxZsoTAwMAqX0tJSeGiiy7iggsuoHPnzgwbNoyLLrqIq6++miZNmrigWqmvsvJLWLE960joyXJs/lihZagfg9uFM7htGP0Twgjxc69tEsR5fL2snHdkYrRxucGWtMNH1hxKZ93eHDam5rExNY+Xk7YTFujD+R3CuaBj5JE1euCD1Xt4Y/kOMhwblHpz86A2XH9OjFsuaOnu9Bt3Bi9/szfGFdc9A/n5+YwYMYJnnnmmytdatGiB1Wpl0aJF/PTTT3z//ffMmjWLhx9+mNWrVxMXF3dG15aGq7Tcztrdh/hxuzl5+a9zNPy8rPSLb+bo5WkTFqDbzsXpLBYLHVsE07FFMJPOSyArv4SlWzNZvCWd5duyyMov4eNf9/Hxr/vwtpr7pVXMOWsR4svfB7dhTO/W+Hlr7Sd3pQDkDBbLKQ9FuZK3tzc229EF4nr06MGnn35KbGwsnp7V/1WwWCwMGDCAAQMG8MgjjxATE8Pnn39OYmJilfakcTIMg13ZhWbg2ZbJqpTsKgsNdmwRzOB2YZzbNpyesU3w8dSHitStsEAfru7Ziqt7tqK03NyeI2lzBklb0tmdXUipzU5MM39uPzeeq3q00jIJogDkTmJjY1m9ejW7du0iMDCQSZMm8e9//5uxY8fywAMP0LRpU5KTk/noo4/4z3/+w6+//kpSUhIXXXQRERERrF69mszMTDp27Oho77vvvmPr1q00a9aMkJAQvLw0vNEY5BWX8VNytqOXZ+/Bokpfbxbg7ejhGdg2jIggTWSX+sPb04MBCWEMSAhj+mUdScnMJyu/lF6NZC8ycQ4FIDdy3333MX78eDp16kRRURE7d+5k5cqVPPjgg1x00UWUlJQQExPDxRdfjIeHB8HBwSxfvpyZM2eSl5dHTEwML7zwApdccgkAt9xyC0uXLqVXr17k5+ef1m3wUr/Y7AZ/pOby45E1eX7bk+PY6wjM9VB6xjQ5MpcnnE4tgrU3ljQIFouFhIggEiJcXYnUN7oNvhqNcR2g+kY/R9dLyy1m+ZFhrRXJWeQUllX6elxYAIOP9PKc06YZAZokKiL1nG6DF5EqistsrNl50LHy8rb0/EpfD/LxpH9CM0cvT3TTM5tkLyJSnykAiTRShmGwPSOf5dsyWbYtkzU7D1baV8tigS6tQjm3Yk2e6FC8ND9CRNyEApBII3KooJQVyVks32auyZOWV3nH9ObBvgxuZwaeAfFh2ktLRNyWApBIA2cYBnNX7uLL9an8nprLsbP6fDw96NummWMuT9uIQK3JIyKCAlCNae74mdHPz3neXLGTfyzY7HjdPjLIsbdWn7imZ7xZpIhIY6QAdJoq1rkpLCzEz08bN9ZUaWkpAFarPpzPxPq9Ofzz2y0A3Hl+Atf1jTmtDSFFRNyVAtBpslqthIaGkpFhbr7n7++vIYXTZLfbyczMxN/f/7grUMvJ5RaVMfmD3yi3Gwzv3JzEC9vp76KIyCnSp08NVOx+XhGC5PR5eHjQunVrfWDXkGEYTP3sd/YdKiK6qR8zruqin6WIyGlQAKoBi8VCixYtiIiIoKys7ORvkCq8vb3x8NAt1zX13uo9fPNHGp4eFmaN7aEd1kVETpMC0BmwWq2awyJ1btP+XJ78+k8AplzSgW7Roa4tSESkAdL/gos0IAUl5dz5wTpKy+1c0CGCmwbGubokEZEGSQFIpIEwDINpX2xkR1YBzYN9eW5UV837ERGpIQUgkQZi/tp9fL4uFQ8LvDy2O021irOISI0pAIk0AMkZh3nkf5sASLywHX3imrq4IhGRhk0BSKSeKy6zMen9dRSV2RiQ0IzbhyS4uiQRkQZPAUiknnv8qz/Zmn6YsEBv/jWmG1YPzfsRETlTCkAi9dhXG/bz4Zo9WCwwc0x3IoK0zYWIiDMoAInUU7uzC5j62R8A3DEknoFtw1xckYhI46GFEEXqoZJyG5M/WEd+STm9Yppw79B2ri6p9mVug6VPQ3EuJAyFdhdDs3hXVyUijZQCkEg99My3W/kjNZdQfy9eHtsdT2sj7qwtLYQfn4eVL4P9yNYyKYvhu4egWYIZhNpdDK3PAau2/BA3YyuH/DTITYW8fVB4ELwDwScIfIPNP32CzYdvMHj6uLriBkMBSKSeWfRnOnNX7gTg+au7EhXq5+KKatHWb+GbByB3j/m67UUQdy4kL4JdKyE7GVbNNh8+IZBwgRmG2l4I/loKoNYUZMOuH81H3gEIDIegFhAYCUHNzUdgcwgIB6s+RmrMboeCTDPY5KZCXirk7jvy55HXh9PAsJ16m1bvI4GoIiAF/+V10DGvQ/7y+pivezT+bZ70N1ekHknNKeK+TzYAcNPAOIZ2inRxRbXk0G5YOAW2fmO+Dm4FlzwDHS4FiwX6T4biPLMnaNt3sP07KMyGTZ+ZD4sHtOoD7Y/0DoV3MN8nNVOUA7tXws4fYedyyNh0au+zeJghKDDSDEhBkdUHpcAI9+u9MwwoOnRMmDk25KRC7l44fABspSdvy8MTgqPM/04Cmpm9piWHoSTP/LM4D0oPm+faSqEwy3ycCa+AagJTxeuQUwtU3gH1+r9Li2EYhquLqG/y8vIICQkhNzeX4OBgV5cjbqLMZueaN35m7e5DdGkVwvzb+uPt2ciGvspLYdUsWPYclBeZ/7D3vxMG32/+Y3k8dhuk/gbbFpqP9I2Vvx7a+shQ2TCIHaRhgJMpOQy7V8Gu5WboObAB+MtHQXhHiBsMYW2hIMv8sM5PN/88nA4FGWDYT/GCFggIOxqIKgWlFkeOR5oPzwaywnnJ4eqDzbGvywpPoSGL+f0Ht4SQlmbICWl55HUr8xEQAR4n+bfAbjdDUEUgcgSkvL+8rvh63l9eH/l6ebFTfjzmt+ZxNDBVF6biL4COlznvepze57fLA9Arr7zCc889R1paGl27dmXWrFn06dOn2nPLysqYMWMG77zzDqmpqbRv355nnnmGiy++2HHOY489xuOPP17pfe3bt2fLli2nXJMCkLjCswu38OrSFIJ8PPn6roHENDtBIGiIdiyDb+6DrG3m69hBMPx5iOhw+m3l7DV7hbZ9Z7ZrKzn6Na8AiD/vyFDZReaHrbsrLYS9P5thZ9ePZpj867BKswQz8MQOMh+B4Sdu024zh28Op1UORo6glHb0a6czhOPfrPpeJMfzI8drM+SWFUHe/r8MR/0l6JTknuL3E1Z9sKkIPEEt6lfvWHlp5fBUKTAdNm9SqBKmqglbp/I7H5gIQx91avmn8/nt0iGwefPmkZiYyJw5c+jbty8zZ85k2LBhbN26lYiIiCrnT5s2jffee49///vfdOjQge+++44rr7ySn376ie7duzvOO+uss/jhhx8crz09NdIn9dvybZm8tiwFgBkjOzeu8HM4Db6fBn98Yr4OCIeLnoIuo2vePR4aDb1vNh+lBeawzdZvzUCUnwZbvjYfAFE9jvYOtehar7vknaa8BPb9Yv5cdv5oPq+YYF4hNMYMPHGDIXagOcRyOjysR0PJidjt5nDMX4NSftrRkFTxNXuZOdRZmF21l++v/JqcWlDy+sscOluZGW6qDTZHAk9h9qn9DHxD/hJs/hJ0gluCVwNbu8vTGzybmUNtNWUYZu9XpYCUWzUwte7nvLprwKU9QH379qV3797Mnj0bALvdTnR0NHfeeSdTpkypcn5UVBQPP/wwkyZNchwbOXIkfn5+vPfee4DZA/TFF1+wfv36GtelHiCpSxl5xQx/+Uey8ku5tm9rnr6ys6tLcg5bOfzyH1jylPmPncXDDCznPQx+obVzTcMwh3O2fWcOle3/rfLXg1qYQajdxeZka2//2qmjrtnKzF6dncvNYa29a6oOZQS3NHt24gZD3CBz2LA+sdvNOTOHDxwJR+lVh90qQtOpzJup4Bti/t69/M3gk59OleG+6nj5HzMMVV0PTpQ5lCP1SoPoASotLWXt2rVMnTrVcczDw4OhQ4eyatWqat9TUlKCr2/lNO3n58eKFSsqHdu+fTtRUVH4+vrSr18/ZsyYQevW9ew/dhHAZje4Z956svJL6dA8iEcu6+Tqkpxj7y+w4F5IMxdyJKoHXPYiRHU/8fvOlMUCUd3Mx5AHzQ/L7d+bgShliflBuvZt8+Hpa4aBdsOg7TCzV6mhsJVD2oajk5b3/AxlBZXPCYgwg07FsFbTNvW798vDw+x1CGgGnH388yomFx9OqyYopR1zPM0MgcW55uNYVu+jk4qP13vj16R+/7zkjLksAGVlZWGz2YiMrDw+HxkZedz5OsOGDePFF19k8ODBxMfHk5SUxGeffYbNdnSssW/fvrz99tu0b9+eAwcO8PjjjzNo0CA2btxIUFD1ab2kpISSkqNzCPLy8pzwHYqc3KtLkvkpJRs/Lyuzr+2Br1cDv/W08CD88Bj89o752jcEhj4GPca75rbaoObQY5z5KCuG3SvMMLR1oXnr/fbvzQf/B5Gdj/YOtexRv24DttvNIaFdP5qhZ/dKs1ftWH5NzaGsimGtsHaN8wPcYjGXQPBvCpEn+B8GwzCDT0UPUmmB2RMU0sqcl3OyScXS6DWoyTEvvfQSt9xyCx06dMBisRAfH8/EiROZO3eu45xLLrnE8bxLly707duXmJgYPv74Y2666aZq250xY0aVidMitW31jmz+9YM5IfjJK84mISLQxRWdAbsdNnwAix45On+i23Uw9PGTT6atK16+5grTCUPhkmchY/ORu8q+g31rIP0P8/Hj8+YHZNuLzEAUf755x0pdMgzI3HJk0vJy2LXC7PU4lk8IxA44Mqw1CCLO0of6sSwWc6jVLxTC27u6GqmHXBaAwsLCsFqtpKenVzqenp5O8+bVT6oLDw/niy++oLi4mOzsbKKiopgyZQpt2rQ57nVCQ0Np164dycnJxz1n6tSpJCYmOl7n5eURHd2AusOlwTlYUMpdH63DbsBVPVpydc9Wri6p5tI2woJE2LvafB3RCS59AWL6u7auE7FYzN6DyE4wKNFc+C/5BzMQJSeZk3Y3fGA+PLzMoFExkbrp8f+9qTHDgOyUo7el71ph3mZ+LO9Ac9Jo3JG7tFp0rV+9VCINjMsCkLe3Nz179iQpKYkrrrgCMCdBJyUlMXny5BO+19fXl5YtW1JWVsann37K6NGjj3tufn4+KSkp3HDDDcc9x8fHBx8frRsidcNuN7jvkw2k55XQJjyAJy8/wXyH+qzkMCyZAavnmLe8egXAeVOh723167beUxHQDLqOMR+2Mtiz6uhE6uxk2LHUfCycYg4ttRsG7S6B6L41Xwn50O4jk5aPDGsd3l/5656+5vYfFROXo7o3vJ+rSD3m0iGwxMRExo8fT69evejTpw8zZ86koKCAiRMnAjBu3DhatmzJjBkzAFi9ejWpqal069aN1NRUHnvsMex2Ow888ICjzfvuu48RI0YQExPD/v37efTRR7FarYwdO9Yl36PIX725YieLt2Tg7enBK9f2IMCnQY1Em70Vmz439+o6fMA81ulyGDbDnEDa0Fm9js6jGfYUZCWbaw5t/dYMRlnbzMdPs8w5TgkXmr1DCReceHuOvP1HJy3vWg45e/5yXW9zdeuKHp5WvbSgo0gtcum/vGPGjCEzM5NHHnmEtLQ0unXrxsKFCx0To/fs2YPHMWPaxcXFTJs2jR07dhAYGMjw4cP573//S2hoqOOcffv2MXbsWLKzswkPD2fgwIH8/PPPhIfXk3kI4tbW7TnEMwvNSf6PXNaJji0a2DILWcnmYoY7lpivm8SZixm2HeraumpTWIL56DfJ3DLCsT3H91B0EDbONx8WD4g+5+j2HH5NjvTuHBnWOphSuV0PT2jZ8+gcnui+VdesEZFa4/KVoOsjrQMktSG3qIxLX/6RfYeKuLRzC2Zf2x1LQ7lLp6wIfnwRVs4012Cx+phzZwbc0/AWenMWuw32/Xp0e46MP098vsXDnLcTNxhiB5vDWz4NeOK7SD3UINYBEnEnhmEw5dPf2XeoiOimfswY2bnhhJ9t35u9Pjm7zdcVd1E1i3dtXa7mYYXWfc3H0EfNOT3bvzfD0M7lZlCM7Hx04cHW/WpvAUgROW0KQCJ14L2fd/PtxjS8rBZmj+1BsG8DmMyas9ec9FuxpURwS7j4n9BxRONcX+ZMNYmBPreYj9JCMwAp8IjUWwpAIrVs0/5cnlywGYAHL+5A1+hQ1xZ0MuWl8POrsOwZcz8fD0845w4490EN2Zwqb3+gkWyzIdJIKQCJ1KL8knLu/GAdpeV2LugQwU0D41xd0ontWgEL/s9chA/MYZtLXzzxirsiIg2QApBILTEMg+lfbGRHVgEtQnx5flTX+jvvJz8Dvp8Ov39kvvYPg4uehK5jNdwlIo2SApBILZm/dh+fr0vF6mHh5bHdaRLg7eqSqrLb4Ne5kPQklOQCFuh1I1ww3byNW0SkkVIAEqkF29MP88j/NgFw79C29I49wQJ5rpK6Fr5OhAPrzdctupk7trfs6cqqRETqhAKQiJMVl9mY/ME6ispsDEwI4/YhCa4uqbKiQ2aPz69zAcPcVPOC6WbPj/aWEhE3oQAk4mSPf/UnW9MPExbow4tjumL1qCdzaAwDNnwE308zN/sE6HKNOdcnMMK1tYmI1DEFIBEn+mrDfj5csweLBWaO6UZEUD1ZJTn9T/Purj0/ma/DO5hbWMQNcm1dIiIuogAk4iS7swuY+tkfAEwaksDAtmEurggoyTfX8/n5VbCXg5e/uZ7POXeAZz2clC0iUkcUgEScoKTcnPeTX1JO79gm3DO0rWsLMgzY/JW5knNeqnmsw2XmSs6h0a6tTUSkHlAAEnGCf367hT9Scwn19+Llsd3xtHq4rpiDO+CbByB5kfk6NAaGPwfthrmuJhGRekYBSOQMLfoznbdW7gLg+au70iLEzzWFlBWbu7X/+CLYSsDqbe7WPigRvFxUk4hIPaUAJHIGUnOKuO+TDQDcPDCOoZ0iXVNIymJzkvPBHebrNufBpS9ox3YRkeNQABKpoTKbnbs+XEduURldW4XwwMUdXFPIuvfgf5PM50Et4OIZ0OkKbWEhInICCkAiNfSvRdtYu/sQQT6ezBrbA29PF8z72fAR/G+y+bz79TBsBvgG130dIiINjAKQSA0s25bJq0tTAPjnyC60buZf90X8MR++uB0woPfN5ro+6vURETklLrxVRaRhysgrJnHeegCu69uaS7u0qPsiNn0On90Khh16jIdLnlP4ERE5DQpAIqfBZje4Z956sgtK6dA8iOmXdar7IjZ/DZ/eDIYNul0Pl80ED/2nLCJyOvSvpshpeGVJMj+lZOPvbWX2tT3w9arjzUO3LoRPJpirOne5Bv72ssKPiEgN6F9OkVP0845sZv6wDYAnLz+bhIjAui1g+w/w8Q1gL4OzR8IVr2r3dhGRGlIAEjkF2fkl3P3ROuwGjOzRipE9W9VtASmL4aNrwVYKnS6HK99Q+BEROQMKQCInYbcb/N8nG0jPKyE+PIAnLj+rbgvYuRw+HGuu7tzhMhj5Jlh1A6eIyJlQABI5if+s2MHSrZl4e3ow+9oeBPjUYfjYtRI+GAPlxdDuYrj6LbB61d31RUQaKQUgkRNYt+cQzy7cCsCjIzrRsUUdLjK4ZzW8PwrKCiFhKIx+Fzy96+76IiKNmAKQyHHkFpYx+YN1lNsNLu3Sgmv7tK67i+/7Fd4bCWUF0GYIjHkPPH3q7voiIo2cApBINQzD4MFPfyc1p4jWTf2ZcVVnLHW10GDqb/Dfq6D0MMQOgms+1G7uIiJOpgAkUo33ft7Nwk1peFktzBrbnWDfOpp3c2AD/PdKKMmF1v1g7Efg7YJtNkREGjkFIJG/2LQ/lye/3gzAgxd3oGt0aN1cOH0TvHsFFOdAqz5w3SfgU8drDYmIuAkFIJFj5JeUM/mDdZTa7FzQIYKbBsbVzYUztsA7f4Oig9CyJ1w/H3yC6ubaIiJuSAFI5AjDMJj2+R/szCqgRYgvz4/qWjfzfrK2wzsjoDALWnSF6z8D35Dav66IiBtTABI54pO1+/hi/X6sHhZeHtudJgF1cMt5dooZfgoyILIz3PAF+IXW/nVFRNycApAIsD39MI/8byMAiRe2o3ds09q/6MGdZvg5fAAiOsG4/4F/HVxXREQUgESKSm1M/mAdxWV2BrUN4/Zz42v/ojl7zPCTlwph7WHclxDQrPavKyIigAKQCE98vYmt6YcJC/ThxdHd8PCo5Xk/ufvg7csgdy80S4DxX0JgeO1eU0REKlEAErf25Yb9fLhmLxYLzBzTjfCgWl5tOW+/2fOTsxuaxMH4ryCoee1eU0REqlAAEre1P6eIhz77A4DJ5yUwsG1Y7V7wcLoZfg7ugNAYmPA1BEfV7jVFRKRaCkDituYsSyG/pJzurUO5+4K2tXux/Ewz/GQnQ0i02fMT0qp2rykiIselACRuKSOvmI9+2QvA/cPa42mtxf8UCrLh3cshaysERZlzfprE1N71RETkpBSAxC39Z8VOSsvt9GgdSr82tXj3VeFB+O/lkLEJApubw15N29Te9URE5JQoAInbOVRQyns/7wZg8vkJtbfac1GOubFp2h8QEGEOezWrg1vsRUTkpBSAxO28tXInhaU2OrUI5rz2EbVzkeJceO8qOLAe/MPMYa/wdrVzLREROW0KQOJWDheX8fZPu4Ba7P0pOQzvXQ2pa8GvibnCc0RH519HRERqTAFI3Mp/f95NXnE58eEBXHxWLay/U1oA74+GfWvMDU3H/Q+an+3864iIyBlRABK3UVRq480fdwJwx5AE56/4XFoIH4yBPT+BT4i5sWmLrs69hoiIOIUCkLiND9fsIbuglOimfvytm5MXICwrho+uhV0/gncQ3PAZtOzh3GuIiIjTKACJWygpt/HG8h0A3HZuPF7OXPenvATmXQc7loBXAFw/H1r1cl77IiLidApA4hY++y2VtLxiIoN9uLqnE1dgLi+Fj8dB8g/g5Q/XfQKtz3Fe+yIiUisUgKTRK7fZeW1pCgC3Do7Hx9PqnIZtZTB/ImxbCJ6+MPYjiB3gnLZFRKRWKQBJo/fV7/vZc7CQpgHejO0T7ZxGbeXw6c2w5Wuw+sDYD6HNuc5pW0REap0CkDRqdrvBK0vM3p+bBsbh7+3phEZt8Pnf4c8vwOoN17wP8eefebsiIlJnFICkUftuUxrJGfkE+XpyQz8nbEBqt8EXd8DG+eDhCaPfhbYXnnm7IiJSpxSApNEyDIPZS5IBmNA/lmBfrzNr0G6HL++C3z8CixWufgvaX+KESkVEpK4pAEmjtXRbJpv25+HnZWXigLgza8xuhwX3wvr3wOIBI/8Dnf7mnEJFRKTOKQBJo2QYBrMXm70/15/TmqYB3mfSGHx7P6x92ww/V74BZ1/lnEJFRMQlFICkUfp5x0HW7j6Et6cHtwxqU/OGDAMWToVf/gNY4PJXocsop9UpIiKuoQAkjdIrR+b+jO7Viohg35o1YhiwaDqsfs18/bdZ0G2skyoUERFXcnkAeuWVV4iNjcXX15e+ffuyZs2a455bVlbGE088QXx8PL6+vnTt2pWFCxeeUZvS+Kzbc4gVyVl4elj4++D4mjViGJD0BPw0y3x92b+gxw3OK1JERFzKpQFo3rx5JCYm8uijj/Lbb7/RtWtXhg0bRkZGRrXnT5s2jddff51Zs2bx559/ctttt3HllVeybt26GrcpNVBWBIufgiVPw7r3YeePkLPHXBywHqjo/bmie0uim/rXrJGlM2DFi+bz4c9DrxudVJ2IiNQHFsMwDFddvG/fvvTu3ZvZs2cDYLfbiY6O5s4772TKlClVzo+KiuLhhx9m0qRJjmMjR47Ez8+P9957r0ZtVicvL4+QkBByc3MJDg4+02+z8fn5NVhYzc/SwxOCW0KTGAhtDaGxxzyPgcBI8KjdzL35QB6XvPQjFgv8kHgu8eGBp9/IsudgyT/M58NmQL87nFukiIjUitP5/HbCsrg1U1paytq1a5k6darjmIeHB0OHDmXVqlXVvqekpARf38rzOfz8/FixYkWN25Qa2Py1+WfMAPD0gUO7IXcv2EohZ7f5qI7VB0KjzTAU2vpIODryaBID/s3AYjmj0ip6f4Z3blGz8LNi5tHwc+ETCj8iIo2UywJQVlYWNpuNyMjISscjIyPZsmVLte8ZNmwYL774IoMHDyY+Pp6kpCQ+++wzbDZbjdsEM1iVlJQ4Xufl5dX022r8CrJhz0/m8yteM4MLmOvk5KeZYShntzkk5ni+G3JTwVYC2cnmozpeAccEo9ZHg1HFc7/QE5aWkpnPgj8OADD5vITT/95WvQI/PGo+P386DLj79NsQEZEGwWUBqCZeeuklbrnlFjp06IDFYiE+Pp6JEycyd+7cM2p3xowZPP74406qspHbthAMO0R2Php+wBzaCo4yHzH9qr7PVg55qWYYOnQkIB37/PABKCuAzM3mozq+IUfDkCMcVQSk1ry2NAXDgKEdI+jY4jSHLle/Dt89ZD4fMhUG33d67xcRkQbFZQEoLCwMq9VKenp6pePp6ek0b9682veEh4fzxRdfUFxcTHZ2NlFRUUyZMoU2bdrUuE2AqVOnkpiY6Hidl5dHdLSTdg1vbLYsMP/scOnpvc/qaQaWJjFQ3aLM5SWQs/doj9FfQ1JhFhTnQtof5qMaDxlBXO8dTgwdYVFC5ZAUEg1ex7kd/pc34dsHzOeD7oNzHzy9701ERBoclwUgb29vevbsSVJSEldccQVgTlhOSkpi8uTJJ3yvr68vLVu2pKysjE8//ZTRo0efUZs+Pj74+Pg45ftq1EoLIWWx+fx0A9DJePpAWIL5qPbaBUcC0V+G1iqeF+fS1HKYppbDsHMH7KymjaAWx/QgHRlqK8iCpCO9f/3vgvOnnfE8JBERqf9cOgSWmJjI+PHj6dWrF3369GHmzJkUFBQwceJEAMaNG0fLli2ZMWMGAKtXryY1NZVu3bqRmprKY489ht1u54EHHjjlNuUMpCyG8iIIaQ3NO9fttb0DIKKj+fiLjLxiLnn2ayJt6fzroia09z1UtQeprMAcZjt8APaurtr+OXeYk54VfkRE3IJLA9CYMWPIzMzkkUceIS0tjW7durFw4ULHJOY9e/bgccxt08XFxUybNo0dO3YQGBjI8OHD+e9//0toaOgptylnYOs35p8dLq1XQeHfP+4gu9yP2JjutBvSr2pthgGFByFnV+VglLMHDqdBp8th8P316nsSEZHa5dJ1gOorrQNUDVs5PN8Wig7C+K8hbpCrKwLgYEEpA59ZTGGpjbcm9ua89hGuLklERFzkdD6/Xb4VhjQQe382w49fE2hdzV1eLvLWyp0Ulto4u2UwQ9qFu7ocERFpIBSA5NRU3P3V7hLzjq56IK+4jLd/2gXApCEJWDSEJSIip0gBSE7OMGDLkdWfnX331xn476rdHC4uJyEikGFnHX+ZAxERkb9SAJKTS99oThj29IP4811dDQCFpeW8ucK8133SefF4eKj3R0RETp0CkJxcxfBX/PngXcPd1Z3swzV7OVhQSuum/ozoEuXqckREpIFRAJKTq2fDXyXlNt5YngLA7UPi8bTqr7GIiJwefXLIiR3abW49YfGAdhe7uhoA5q/dR3peCc2DfbmqR0tXlyMiIg1QjQLQkiVLnF2H1FcVix+27g8BzVxbC1BuszNnmdn7c+vgNvh4Wl1ckYiINEQ1CkAXX3wx8fHx/OMf/2Dv3r3Orknqk5puflpLvtywn70Hi2gW4M3YPq1dXY6IiDRQNQpAqampTJ48mfnz59OmTRuGDRvGxx9/TGlpqbPrE1cqPAi7V5rPOwx3bS2A3W7wypJkAG4aFIeft3p/RESkZmoUgMLCwrj33ntZv349q1evpl27dtxxxx1ERUVx1113sWHDBmfXKa6wbSEYdojsDE1iXV0NCzelkZJZQLCvJzecE+PqckREpAE740nQPXr0YOrUqUyePJn8/Hzmzp1Lz549GTRoEJs2bXJGjeIq9Wj4yzCO9v5M6B9LkK+XiysSEZGGrMYBqKysjPnz5zN8+HBiYmL47rvvmD17Nunp6SQnJxMTE8OoUaOcWavUpdJCSE4yn9eDALR0ayab9ufh721l4oA4V5cjIiINXI02dbrzzjv58MMPMQyDG264gWeffZazzz7b8fWAgACef/55oqK0QF2DtWMJlBdBSGto3tmlpRiGwazF2wG4/pwYmgR4u7QeERFp+GoUgP78809mzZrFVVddhY+PT7XnhIWF6Xb5hswx/DUcXLzJ6Kod2fy2JwdvTw9uHqjeHxEROXM1CkBJSUknb9jTk3PPPbcmzYur2cph67fm83ow/FUx9+ea3tFEBPu6uBoREWkMajQHaMaMGcydO7fK8blz5/LMM8+ccVHiYntXQ9FB8A01F0B0od/2HGJlcjaeHhb+fm68S2sREZHGo0YB6PXXX6dDhw5Vjp911lnMmTPnjIsSF6sY/mp/CVhr1EnoNK8sNnt/ruzekpahfi6tRUREGo8aBaC0tDRatGhR5Xh4eDgHDhw446LEhQyj3mx+uml/LklbMvCwmJueioiIOEuNAlB0dDQrV66scnzlypW686uhS98EObvB0xfiz3dpKa8uMff8urRLFG3CA11ai4iINC41Gt+45ZZbuOeeeygrK+P8880PyaSkJB544AH+7//+z6kFSh2rGP6KPx+8A1xWRnJGPt9sNHsTJ52n3h8REXGuGgWg+++/n+zsbO644w7H/l++vr48+OCDTJ061akFSh2rJ8Nfry1NwTDgwk6RdGge7NJaRESk8alRALJYLDzzzDNMnz6dzZs34+fnR9u2bY+7JpA0EDl7IO13sHhAu4tdVsbeg4V8sT4VgMnnJbisDhERabzO6BafwMBAevfu7axaxNW2fGP+2bofBIS5rIw5y1Kw2Q0GtQ2ja3Soy+oQEZHGq8YB6Ndff+Xjjz9mz549jmGwCp999tkZFyYuUA+Gv9Lzivnk130ATFLvj4iI1JIa3QX20Ucf0b9/fzZv3sznn39OWVkZmzZtYvHixYSEhDi7RqkLhQdh90/m8/bDXVbGv5fvoNRmp3dsE/rGNXVZHSIi0rjVKAA9/fTT/Otf/+Krr77C29ubl156iS1btjB69Ghat27t7BqlLmz7DgwbRJ4NTV2z39bBglLeX70HMHt/LC7eg0xERBqvGgWglJQULr3UHCbx9vamoKAAi8XCvffeyxtvvOHUAqWO1IPhr7krdlJUZqNzyxDObRfusjpERKTxq1EAatKkCYcPHwagZcuWbNy4EYCcnBwKCwudV53UjdJCSD6ywa2LAlBuURnv/LQLUO+PiIjUvhpNgh48eDCLFi2ic+fOjBo1irvvvpvFixezaNEiLrjgAmfXKLVtx1IoL4KQaGjexSUl/HfVLg6XlNMuMpCLOkW6pAYREXEfNQpAs2fPpri4GICHH34YLy8vfvrpJ0aOHMm0adOcWqDUgYrVnztcCi7oeSksLefNFTsBuGNIAh4e6v0REZHaddoBqLy8nK+//pphw4YB4OHhwZQpU5xemNQRWzlsPbL+j4vu/vpg9R4OFZYR08yfy7pU3WRXRETE2U57DpCnpye33XabowdIGri9q6HoIPiGQkz/Or98cZmNN5bvAOD2c+PxtNZoWpqIiMhpqdGnTZ8+fVi/fr2TSxGXqOj9aXcxWL3q/PLz1+4j43AJLUJ8uapHqzq/voiIuKcazQG64447SExMZO/evfTs2ZOAgMq7hnfp4pqJtHKaDMOlt7+X2ezMWZYCwN8Ht8HbU70/IiJSN2oUgK655hoA7rrrLscxi8WCYRhYLBZsNptzqpPalfEnHNoFnr6QUPd37325fj/7DhURFujNNX20gKaIiNSdGgWgnTt3OrsOcYWKu7/anAfeASc+18lsdoNXliYDcNPANvh6Wev0+iIi4t5qFIBiYmKcXYe4gguHvxZuTGNHZgEhfl5cf456f0REpG7VKAC9++67J/z6uHHjalSM1KGcvXBgA1g8oP0ldXppwzCYvcTs/ZnQP5Yg37qffC0iIu6tRgHo7rvvrvS6rKyMwsJCvL298ff3VwBqCCru/oo+BwLC6vTSi7dksPlAHgHeViYOiK3Ta4uIiEANb4M/dOhQpUd+fj5bt25l4MCBfPjhh86uUWqDi4a/ju39uf6cGEL9vev0+iIiIlDDAFSdtm3b8s9//rNK75DUQ4UHYddK83mHul39eVVKNuv25ODj6cFNg+Lq9NoiIiIVnLrwiqenJ/v373dmk1Ibtn8Phg0izoKmber00rMWm70/1/SOJiLIt06vLSIiUqFGc4C+/PLLSq8Nw+DAgQPMnj2bAQMGOKUwqUUuGv5au/sQq3Zk4+lh4dZz4+v02iIiIseqUQC64oorKr22WCyEh4dz/vnn88ILLzijLqktZUWQnGQ+r+MA9MqRuT8je7SiZahfnV5bRETkWDUKQHa73dl1SF3ZsRTKCiG4FbToWmeX3Ziay+ItGXhY4PYh6v0RERHX0uZL7ubY4S+Lpc4u++qRVZ8v6xJFbFjdrjotIiLyVzUKQCNHjuSZZ56pcvzZZ59l1KhRZ1yU1BK7DbZ+az6vw+Gv5IzDfLsxDYBJ5yXU2XVFRESOp0YBaPny5QwfXvX26UsuuYTly5efcVFSS/auhsJs8A2FmP51dtlXl6ZgGHBRp0jaNw+qs+uKiIgcT40CUH5+Pt7eVRew8/LyIi8v74yLklpSsflpu2FgrZvtJ/ZkF/K/9ebSCJPPV++PiIjUDzUKQJ07d2bevHlVjn/00Ud06tTpjIuSWmAYRwNQHQ5/zVmegs1uMLhdOF1ahdbZdUVERE6kRneBTZ8+nauuuoqUlBTOP/98AJKSkvjwww/55JNPnFqgOEnGZji0E6w+EH9BnVwyLbeY+b/uA2Cy5v6IiEg9UqMANGLECL744guefvpp5s+fj5+fH126dOGHH37g3HPPdXaN4gwVvT/x54FPYJ1c8o3lOyi12ekT25Q+cU3r5JoiIiKnokYBCODSSy/l0kvrdiE9OQN1vPpzdn4JH6zZDWjuj4iI1D81mgP0yy+/sHr16irHV69eza+//nrGRYmT5e6DA+sBC7S7pE4uOXflTorL7HRpFcKgtmF1ck0REZFTVaMANGnSJPbu3VvleGpqKpMmTTrjosTJtnxj/tn6HAgMr/XL5RaV8e5PZu/PpPMSsNThgosiIiKnokYB6M8//6RHjx5Vjnfv3p0///zzjIsSJ6vj4a93f9rF4ZJy2kUGcmHHyDq5poiIyOmoUQDy8fEhPT29yvEDBw7g6VnjaUVSG4oOwa4V5vP2VRevdLaCknLmrtwJmL0/Hh7q/RERkfqnRgHooosuYurUqeTm5jqO5eTk8NBDD3HhhReeVluvvPIKsbGx+Pr60rdvX9asWXPC82fOnEn79u3x8/MjOjqae++9l+LiYsfXH3vsMSwWS6VHhw4dTu8bbEy2fQ+GDSI6QbPa34T0wzV7OFRYRmwzfy7rElXr1xMREamJGnXXPP/88wwePJiYmBi6d+8OwPr164mMjOS///3vKbczb948EhMTmTNnDn379mXmzJkMGzaMrVu3EhERUeX8Dz74gClTpjB37lz69+/Ptm3bmDBhAhaLhRdffNFx3llnncUPP/xw9Jt0516pOhz+Ki6z8fryHYC547tVvT8iIlJP1SgZtGzZkt9//53333+fDRs24Ofnx8SJExk7dixeXqe+xcKLL77ILbfcwsSJEwGYM2cOCxYsYO7cuUyZMqXK+T/99BMDBgzg2muvBSA2NpaxY8dWuSPN09OT5s2b1+Rba1zKiiA5yXxeBwHok7X7yDxcQlSIL1d2b1Xr1xMREampGg2BAQQEBDBw4EBGjBjB4MGDCQ0N5dtvv+XLL788pfeXlpaydu1ahg4derQYDw+GDh3KqlWrqn1P//79Wbt2rWOYbMeOHXzzzTdVNmbdvn07UVFRtGnThuuuu449e/acsJaSkhLy8vIqPRqFHcugrACCW0KLbrV6qTKbnTlLUwD4+7nxeHvW+K+WiIhIratRD9COHTu48sor+eOPP7BYLBiGUelWZ5vNdtI2srKysNlsREZWvksoMjKSLVu2VPuea6+9lqysLAYOHIhhGJSXl3Pbbbfx0EMPOc7p27cvb7/9Nu3bt+fAgQM8/vjjDBo0iI0bNxIUVP1O5DNmzODxxx8/lW+9YTl2+KuWb0X/Yl0qqTlFhAX6MKZ3dK1eS0RE5EzV6H/T7777buLi4sjIyMDf35+NGzeybNkyevXqxdKlS51c4lFLly7l6aef5tVXX+W3337js88+Y8GCBTz55JOOcy655BJGjRpFly5dGDZsGN988w05OTl8/PHHx223YkJ3xaO6NY4aHLsNtn5rPq/l4S+b3eC1I70/twyKw9fLWqvXExEROVM16gFatWoVixcvJiwsDA8PD6xWKwMHDmTGjBncddddrFu37qRthIWFYbVaq9xOn56eftz5O9OnT+eGG27g5ptvBsxd6QsKCrj11lt5+OGH8fComudCQ0Np164dycnJx63Fx8cHHx+fk9bcoOxdA4VZ4BsCMQNq9VLfbjzAjqwCQvy8uO6cmFq9loiIiDPUqAfIZrM5hpPCwsLYv38/ADExMWzduvWU2vD29qZnz54kJSU5jtntdpKSkujXr1+17yksLKwScqxWs7fBMIxq35Ofn09KSgotWrQ4pboajYrhr3YXg/XUJ6afLsMwmL3YDJcTB8QS6OPGd9yJiEiDUaNPq7PPPpsNGzYQFxdH3759efbZZ/H29uaNN96gTZs2p9xOYmIi48ePp1evXvTp04eZM2dSUFDguCts3LhxtGzZkhkzZgDmLvQvvvgi3bt3p2/fviQnJzN9+nRGjBjhCEL33XcfI0aMICYmhv379/Poo49itVoZO3ZsTb7Vhskwju7+XsvDX0mbM9iSdphAH08m9I+t1WuJiIg4S40C0LRp0ygoKADgiSee4LLLLmPQoEE0a9aMefPmnXI7Y8aMITMzk0ceeYS0tDS6devGwoULHROj9+zZU6nHZ9q0aVgsFqZNm0Zqairh4eGMGDGCp556ynHOvn37GDt2LNnZ2YSHhzNw4EB+/vlnwsNrfw+seiNzCxzaCVYfiL+g1i5jGAazl5i9P9efE0Oov3etXUtERMSZLMbxxo5O08GDB2nSpEmj2PgyLy+PkJAQcnNzCQ4OdnU5p2/5c7D4H9B2GFx3/MnfZ2rF9iyuf3M1Pp4erHjwfMKDGtk8KhERaVBO5/PbaRM2mjZt6qym5EzV0fDX7CXbARjbp7XCj4iINChara6xyd0H+9cBFmh/Sa1dZu3ug/y84yBeVgu3Dj71eV8iIiL1gQJQY1Ox9k90Xwisup+as1Tc+TWyRyuiQv1q7ToiIiK1QQGosamDzU837c9lydZMPCxw27m1v8O8iIiIsykANSZFh2DXCvN5LQagD1abe6sN79yC2LCAWruOiIhIbVEAaky2LwJ7OYR3hGa10zNTVGrjy/XmwpfX9m1dK9cQERGpbQpAjUkdDH8t3HSAwyXlRDf145y4ZrV2HRERkdqkANRYlBXD9h/M57UYgD7+ZR8Ao3pG4+HR8Nd8EhER96QA1FjsXAZlBRAUBVHda+USe7ILWbUjG4sFRvZsVSvXEBERqQsKQI3FscNftbQa9/y1ewEYmBBGS936LiIiDZgCUGNgtx1d/6eWhr9sdoP5a83hr9G9omvlGiIiInVFAagx2PcLFGSCTwjEDqyVS6xMzmJ/bjEhfl5c2CmyVq4hIiJSVxSAGoOK4a92w8DqVSuX+PhXc/jrim5R+HpZa+UaIiIidUUBqKEzDNhcu7e/5xSW8v2mdABGafhLREQaAQWghi5zCxzaCVYfSLigVi7xv/X7KbXZ6dQimLNbhtTKNUREROqSAlBDt2WB+WebIeATVCuXqBj+Gt1Lt76LiEjjoADU0FUEoA7Da6X5jam5bNqfh7fVg8u7tayVa4iIiNQ1BaCGLDcV9v8GWKDdJbVyiYpb3y88K5ImAd61cg0REZG6pgDUkG39xvwzug8EOf/W9OIyG5+vSwW09o+IiDQuCkANmWP4q3bu/vphczq5RWW0CPFlYEJYrVxDRETEFRSAGqqiHNj1o/m8w2W1comPfzWHv67u2QqrNj4VEZFGRAGoodq+COzlEN4BmsU7vfn9OUX8uD0TMAOQiIhIY6IA1FBtqd3FDz9duw/DgHPaNCWmWUCtXENERMRVFIAaorJiSP7BfF4LAchuN/jkyN1fY3pr8rOIiDQ+CkAN0c7lUJoPQVHQorvTm1+98yB7DhYS5OPJxWe1cHr7IiIirqYA1BA5hr+Gg4fzf4UVKz+P6BaFn7c2PhURkcZHAaihsduOrv9TC8NfecVlfPPHAUBr/4iISOOlANTQ7PsVCjLBJwRiBjq9+a827Kek3E67yEC6ttLGpyIi0jgpADU0FcNf7S4CT+dvTVGx9s/oXtFYLFr7R0REGicFoIbEMGr19vetaYfZsDcHTw8LV3TXxqciItJ4KQA1JJlb4eAOsHpDwlCnN//JkcnPF3SMICzQx+nti4iI1BcKQA1JRe9PmyHgE+TUpkvL7dr4VERE3IYCUENSi3d/Ld6SQXZBKeFBPpzbLtzp7YuIiNQnCkANRd5+SF0LWKDdJU5vvmL4a2SPVnha9ddCREQaN33SNRQVvT/RfSAo0qlNp+cVs2RrBgCjemnjUxERafwUgBqKLQvMP9sPd3rTn/2Wit2AXjFNiA8PdHr7IiIi9Y0CUENQlGPu/wXQ4TKnNm0YhmP4S5OfRUTEXSgANQTJP4C9HMLaQ1iCU5teu/sQO7IK8Pe2MryLNj4VERH3oADUENTi4ocVG59e2rkFgT6eTm9fRESkPlIAqu/KS2D7IvO5k4e/CkrK+fr3Ixuf9tbwl4iIuA8FoPpu53IozYegFhDV3alNL/jjAIWlNuLCAugV08SpbYuIiNRnCkD1XcXwV/vh4OHcX1fF5OdRvVpp41MREXErCkD1md0OW2pn9ecdmfn8susQVg8LV/fQ2j8iIuJeFIDqs9RfoSADfIIhdpBTm/5k7T4AhrQLJyLY16lti4iI1HcKQPVZxfBX24vA09tpzZbb7Hx6JACN0to/IiLihhSA6ivDgM21c/v7sm2ZZBwuoVmAN+d3iHBq2yIiIg2BAlB9lbUNDqaA1RsShjq16Yq1f67s3hJvT/0VEBER96NPv/qqYvgr7lzwDXZas1n5JSRtrtj4VMNfIiLinhSA6quKzU+dPPz1xbpUyu0GXaNDad88yKlti4iINBQKQPVR3gFIXQtYnLr7u2EYzPulYuNT3fouIiLuSwGoPtp6ZO2fVr0hKNJpzW7Yl8v2jHx8PD0Y0TXKae2KiIg0NApA9VEtDX9VTH4e3rkFwb5eTm1bRESkIVEAqm+Kc839v8Cpm58Wldr4av1+wNz6QkRExJ0pANU32xeBvQzC2kFYgtOaXbjpAIdLyolu6sc5cc2c1q6IiEhDpABU39TW8NcvR1Z+7hmNh4c2PhUREfemAFSflJeYPUDg1OGvPdmFrNqRjcUCI3tq+EtEREQBqD7Z+SOUHobA5hDVw2nNzl9rTn4emBBGy1A/p7UrIiLSUCkA1ScVqz93GA4ezvnV2OwG849sfDpaKz+LiIgA9SAAvfLKK8TGxuLr60vfvn1Zs2bNCc+fOXMm7du3x8/Pj+joaO69916Ki4vPqM16wW4/uv6PE+f/rEzOYn9uMSF+XlzYyXlrComIiDRkLg1A8+bNIzExkUcffZTffvuNrl27MmzYMDIyMqo9/4MPPmDKlCk8+uijbN68mTfffJN58+bx0EMP1bjNeiN1LeSng08wxA52WrMVa/9c0S0KXy+r09oVERFpyFwagF588UVuueUWJk6cSKdOnZgzZw7+/v7MnTu32vN/+uknBgwYwLXXXktsbCwXXXQRY8eOrdTDc7pt1hsVw19tLwRPb6c0mVNYyveb0gFtfCoiInIslwWg0tJS1q5dy9ChQ48W4+HB0KFDWbVqVbXv6d+/P2vXrnUEnh07dvDNN98wfPjwGrcJUFJSQl5eXqVHnauF29//t34/pTY7Z0UFc3bLEKe1KyIi0tB5uurCWVlZ2Gw2IiMrz0uJjIxky5Yt1b7n2muvJSsri4EDB2IYBuXl5dx2222OIbCatAkwY8YMHn/88TP8js5A5jbI3g4eXpBwodOarRj+0uRnERGRylw+Cfp0LF26lKeffppXX32V3377jc8++4wFCxbw5JNPnlG7U6dOJTc31/HYu3evkyo+RRXDX23OBd9gpzS5MTWXTfvz8LZ6cHk3bXwqIiJyLJf1AIWFhWG1WklPT690PD09nebNm1f7nunTp3PDDTdw8803A9C5c2cKCgq49dZbefjhh2vUJoCPjw8+Pj5n+B2dgVoY/vrkSO/PRWdFEurvnDlFIiIijYXLeoC8vb3p2bMnSUlJjmN2u52kpCT69etX7XsKCwvx+Mv6OFareWeTYRg1atPl8g5A6q/m8/bDndJkcZmNL45sfKrhLxERkapc1gMEkJiYyPjx4+nVqxd9+vRh5syZFBQUMHHiRADGjRtHy5YtmTFjBgAjRozgxRdfpHv37vTt25fk5GSmT5/OiBEjHEHoZG3WOxVr/7TqDUHH76U6HYv+TCe3qIyoEF8GJIQ5pU0REZHGxKUBaMyYMWRmZvLII4+QlpZGt27dWLhwoWMS8549eyr1+EybNg2LxcK0adNITU0lPDycESNG8NRTT51ym/VOLSx+WDH5+eqerbBq41MREZEqLIZhGK4uor7Jy8sjJCSE3NxcgoOdMym5WsV58GwbsJfB5F8hrO0ZN5maU8TAZxZjGLD8/vNo3czfCYWKiIjUf6fz+d2g7gJrdJIXmeEnrJ1Twg/Ap2v3YRjQr00zhR8REZHjUAByJSff/WW3G3xyZOf30b1bOaVNERGRxkgByFXKS2Db9+bz9s4JQD/vzGbvwSKCfDy5+KwWTmlTRESkMVIAcpVdP0LpYQiMhJY9ndLkJ7/uA2BEtyj8vLXxqYiIyPEoALlKxfBX++Hgcea/hrziMr754wCgtX9ERERORgHIFex22FJx+/tlTmnyqw37KSm30y4ykK6ttPGpiIjIiSgAucL+3yA/DbyDIG6QU5r8+Mjw1+he0VgsWvtHRETkRBSAXKFi89O2F4Lnme9BtjXtMBv25uDpYeGK7i3PuD0REZHGTgHIFZx8+3vFxqcXdIwgLNCFm7qKiIg0EApAdS1zG2RtAw8vswfoDJWW2/l8XSqgyc8iIiKnSgGorm090vsTNxh8z3yy8uItGWQXlBIR5MO57cLPuD0RERF3oABU12pp+Gtkz1Z4WvXrFBERORX6xKxLh9Ng3y/m8/bDz7i59LxilmzNAGBUT219ISIicqoUgOrS1iNr/7TsBcFnvlXFZ7+lYjegd2wT2oQHnnF7IiIi7kIBqC6VFoJvqFOGvwzDcAx/jdLkZxERkdPi6eoC3Er/ydD372ArPeOmft19iB1ZBfh7W7m0szY+FREROR0KQHXN6mU+ztDHv5i9P5d1aUGAj36NIiIip0NDYA1Qfkk5C7TxqYiISI0pADVA3/x+gMJSG23CAugZ08TV5YiIiDQ4CkAN0MfHTH7WxqciIiKnTwGogUnJzOfX3YewelgY2UMbn4qIiNSEAlAD88mv+wAY0i6ciGBfF1cjIiLSMCkANSDlNjuf/mYGIK39IyIiUnMKQA3Ism2ZZB4uoVmAN+d3iHB1OSIiIg2WAlADUjH5+cruLfH21K9ORESkpvQp2kBk5ZeQtPnIxqca/hIRETkjCkANxBfrUim3G3SNDqV98yBXlyMiItKgKQA1AIZhMO/I1heje7VycTUiIiINnwJQA7BhXy7bM/Lx8fRgRNcoV5cjIiLS4CkANQAVk5+Hd25BsO+Zb6QqIiLi7hSA6rmiUhtfrd8PaONTERERZ1EAqucWbjrA4ZJyWjf1p29cU1eXIyIi0igoANVzH/9yZOXnnq3w8NDGpyIiIs6gAFSP7c4uYNWObCwWGNlTd3+JiIg4iwJQPTZ/rdn7M6htOFGhfi6uRkREpPFQAKqnbHbDEYC09o+IiIhzKQDVUyuSsziQW0yovxcXdop0dTkiIiKNigJQPVWx9s8V3Vri42l1cTUiIiKNiwJQPXSooJRFm9IBGKXhLxEREadTAKqH/rc+lVKbnbOigjkrKsTV5YiIiDQ6CkD10Me/Vkx+1srPIiIitUEBqJ7ZmJrLnwfy8LZ6cHk3bXwqIiJSGxSA6plPjkx+vuisSEL9vV1cjYiISOOkAFSPFJfZ+EIbn4qIiNQ6BaB6ZNGf6eQWlREV4suAhDBXlyMiItJoKQDVIxVr/1zdsxVWbXwqIiJSaxSA6onUnCJWJGcBcHVPDX+JiIjUJgWgeuLTtfswDOjXphmtm/m7uhwREZFGTQGoHrDbDT5Zaw5/je6tlZ9FRERqmwJQPfDzzmz2HiwiyNeTS85u4epyREREGj0FoHrgkyMrP/+taxS+Xtr4VEREpLYpALlYXnEZ3/xxANDaPyIiInVFAcjFvly/n5JyO+0jg+jSShufioiI1AUFIBer2PpiVK9WWCxa+0dERKQuKAC50Ja0PDbsy8XTw8KV3Vu6uhwRERG3oQDkQhWTn4d2jKRZoI+LqxEREXEfCkAuUlpu5/N1qYDW/hEREalrCkAusnhLOgcLSokI8mFw23BXlyMiIuJW6kUAeuWVV4iNjcXX15e+ffuyZs2a4547ZMgQLBZLlcell17qOGfChAlVvn7xxRfXxbdyyj4+Mvw1smcrPK314tcgIiLiNjxdXcC8efNITExkzpw59O3bl5kzZzJs2DC2bt1KRERElfM/++wzSktLHa+zs7Pp2rUro0aNqnTexRdfzFtvveV47eNTf+bYpOcVs3RrBgCjemr4S0REpK65vOvhxRdf5JZbbmHixIl06tSJOXPm4O/vz9y5c6s9v2nTpjRv3tzxWLRoEf7+/lUCkI+PT6XzmjRpUhffzin59Ld92A3oHduENuGBri5HRETE7bg0AJWWlrJ27VqGDh3qOObh4cHQoUNZtWrVKbXx5ptvcs011xAQEFDp+NKlS4mIiKB9+/bcfvvtZGdnH7eNkpIS8vLyKj1qi2EYjru/RmnlZxEREZdwaQDKysrCZrMRGRlZ6XhkZCRpaWknff+aNWvYuHEjN998c6XjF198Me+++y5JSUk888wzLFu2jEsuuQSbzVZtOzNmzCAkJMTxiI6uvWDy6+5D7MwqwN/byqWdtfGpiIiIK7h8DtCZePPNN+ncuTN9+vSpdPyaa65xPO/cuTNdunQhPj6epUuXcsEFF1RpZ+rUqSQmJjpe5+Xl1VoI+vgXc+Xny7q0IMCnQf/4RUREGiyX9gCFhYVhtVpJT0+vdDw9PZ3mzZuf8L0FBQV89NFH3HTTTSe9Tps2bQgLCyM5Obnar/v4+BAcHFzpURvyS8pZoI1PRUREXM6lAcjb25uePXuSlJTkOGa320lKSqJfv34nfO8nn3xCSUkJ119//Umvs2/fPrKzs2nRwrVDTt/8foDCUhttwgLoGVN/JmWLiIi4G5ffBZaYmMi///1v3nnnHTZv3sztt99OQUEBEydOBGDcuHFMnTq1yvvefPNNrrjiCpo1a1bpeH5+Pvfffz8///wzu3btIikpicsvv5yEhASGDRtWJ9/T8WQVlODnZWVUr2htfCoiIuJCLp+EMmbMGDIzM3nkkUdIS0ujW7duLFy40DExes+ePXh4VM5pW7duZcWKFXz//fdV2rNarfz++++888475OTkEBUVxUUXXcSTTz7p8rWA7hiSwA3nxLi0BhEREQGLYRiGq4uob/Ly8ggJCSE3N7fW5gOJiIiIc53O57fLh8BERERE6poCkIiIiLgdBSARERFxOwpAIiIi4nYUgERERMTtKACJiIiI21EAEhEREbejACQiIiJuRwFIRERE3I4CkIiIiLgdBSARERFxOwpAIiIi4nYUgERERMTteLq6gPrIMAzA3FVWREREGoaKz+2Kz/ETUQCqxuHDhwGIjo52cSUiIiJyug4fPkxISMgJz7EYpxKT3Izdbmf//v0EBQVhsVic2nZeXh7R0dHs3buX4OBgp7Ytp0+/j/pFv4/6Rb+P+kW/j5MzDIPDhw8TFRWFh8eJZ/moB6gaHh4etGrVqlavERwcrL/A9Yh+H/WLfh/1i34f9Yt+Hyd2sp6fCpoELSIiIm5HAUhERETcjgJQHfPx8eHRRx/Fx8fH1aUI+n3UN/p91C/6fdQv+n04lyZBi4iIiNtRD5CIiIi4HQUgERERcTsKQCIiIuJ2FIBERETE7SgA1aFXXnmF2NhYfH196du3L2vWrHF1SW5pxowZ9O7dm6CgICIiIrjiiivYunWrq8uSI/75z39isVi45557XF2KW0tNTeX666+nWbNm+Pn50blzZ3799VdXl+WWbDYb06dPJy4uDj8/P+Lj43nyySdPab8rOT4FoDoyb948EhMTefTRR/ntt9/o2rUrw4YNIyMjw9WluZ1ly5YxadIkfv75ZxYtWkRZWRkXXXQRBQUFri7N7f3yyy+8/vrrdOnSxdWluLVDhw4xYMAAvLy8+Pbbb/nzzz954YUXaNKkiatLc0vPPPMMr732GrNnz2bz5s0888wzPPvss8yaNcvVpTVoug2+jvTt25fevXsze/ZswNxvLDo6mjvvvJMpU6a4uDr3lpmZSUREBMuWLWPw4MGuLsdt5efn06NHD1599VX+8Y9/0K1bN2bOnOnqstzSlClTWLlyJT/++KOrSxHgsssuIzIykjfffNNxbOTIkfj5+fHee++5sLKGTT1AdaC0tJS1a9cydOhQxzEPDw+GDh3KqlWrXFiZAOTm5gLQtGlTF1fi3iZNmsSll15a6b8TcY0vv/ySXr16MWrUKCIiIujevTv//ve/XV2W2+rfvz9JSUls27YNgA0bNrBixQouueQSF1fWsGkz1DqQlZWFzWYjMjKy0vHIyEi2bNnioqoEzJ64e+65hwEDBnD22We7uhy39dFHH/Hbb7/xyy+/uLoUAXbs2MFrr71GYmIiDz30EL/88gt33XUX3t7ejB8/3tXluZ0pU6aQl5dHhw4dsFqt2Gw2nnrqKa677jpXl9agKQCJW5s0aRIbN25kxYoVri7Fbe3du5e7776bRYsW4evr6+pyBPN/DHr16sXTTz8NQPfu3dm4cSNz5sxRAHKBjz/+mPfff58PPviAs846i/Xr13PPPfcQFRWl38cZUACqA2FhYVitVtLT0ysdT09Pp3nz5i6qSiZPnszXX3/N8uXLadWqlavLcVtr164lIyODHj16OI7ZbDaWL1/O7NmzKSkpwWq1urBC99OiRQs6depU6VjHjh359NNPXVSRe7v//vuZMmUK11xzDQCdO3dm9+7dzJgxQwHoDGgOUB3w9vamZ8+eJCUlOY7Z7XaSkpLo16+fCytzT4ZhMHnyZD7//HMWL15MXFycq0tyaxdccAF//PEH69evdzx69erFddddx/r16xV+XGDAgAFVlobYtm0bMTExLqrIvRUWFuLhUfnj2mq1YrfbXVRR46AeoDqSmJjI+PHj6dWrF3369GHmzJkUFBQwceJEV5fmdiZNmsQHH3zA//73P4KCgkhLSwMgJCQEPz8/F1fnfoKCgqrMvwoICKBZs2aal+Ui9957L/379+fpp59m9OjRrFmzhjfeeIM33njD1aW5pREjRvDUU0/RunVrzjrrLNatW8eLL77IjTfe6OrSGjTdBl+HZs+ezXPPPUdaWhrdunXj5Zdfpm/fvq4uy+1YLJZqj7/11ltMmDChbouRag0ZMkS3wbvY119/zdSpU9m+fTtxcXEkJiZyyy23uLost3T48GGmT5/O559/TkZGBlFRUYwdO5ZHHnkEb29vV5fXYCkAiYiIiNvRHCARERFxOwpAIiIi4nYUgERERMTtKACJiIiI21EAEhEREbejACQiIiJuRwFIRERE3I4CkIjIKVi6dCkWi4WcnBxXlyIiTqAAJCIiIm5HAUhERETcjgKQiDQIdrudGTNmEBcXh5+fH127dmX+/PnA0eGpBQsW0KVLF3x9fTnnnHPYuHFjpTY+/fRTzjrrLHx8fIiNjeWFF16o9PWSkhIefPBBoqOj8fHxISEhgTfffLPSOWvXrqVXr174+/vTv3//Krumi0jDoAAkIg3CjBkzePfdd5kzZw6bNm3i3nvv5frrr2fZsmWOc+6//35eeOEFfvnlF8LDwxkxYgRlZWWAGVxGjx7NNddcwx9//MFjjz3G9OnTefvttx3vHzduHB9++CEvv/wymzdv5vXXXycwMLBSHQ8//DAvvPACv/76K56entqRW6SB0maoIlLvlZSU0LRpU3744Qf69evnOH7zzTdTWFjIrbfeynnnncdHH33EmDFjADh48CCtWrXi7bffZvTo0Vx33XVkZmby/fffO97/wAMPsGDBAjZt2sS2bdto3749ixYtYujQoVVqWLp0Keeddx4//PADF1xwAQDffPMNl156KUVFRfj6+tbyT0FEnEk9QCJS7yUnJ1NYWMiFF15IYGCg4/Huu++SkpLiOO/YcNS0aVPat2/P5s2bAdi8eTMDBgyo1O6AAQPYvn07NpuN9evXY7VaOffcc09YS5cuXRzPW7RoAUBGRsYZf48iUrc8XV2AiMjJ5OfnA7BgwQJatmxZ6Ws+Pj6VQlBN+fn5ndJ5Xl5ejucWiwUw5yeJSMOiHiARqfc6deqEj48Pe/bsISEhodIjOjracd7PP//seH7o0CG2bdtGx44dAejYsSMrV66s1O7KlStp164dVquVzp07Y7fbK80pEpHGSz1AIlLvBQUFcd9993Hvvfdit9sZOHAgubm5rFy5kuDgYGJiYgB44oknaNasGZGRkTz88MOEhYVxxRVXAPB///d/9O7dmyeffJIxY8awatUqZs+ezauvvgpAbGws48eP58Ybb+Tll1+ma9eu7N69m4yMDEaPHu2qb11EaokCkIg0CE8++STh4eHMmDGDHTt2EBoaSo8ePXjooYccQ1D//Oc/ufvuu9m+fTvdunXjq6++wtvbG4AePXrw8ccf88gjj/Dkk0/SokULnnjiCSZMmOC4xmuvvcZDDz3EHXfcQXZ2Nq1bt+ahhx5yxbcrIrVMd4GJSINXcYfWoUOHCA0NdXU5ItIAaA6QiIiIuB0FIBEREXE7GgITERERt6MeIBEREXE7CkAiIiLidhSARERExO0oAImIiIjbUQASERERt6MAJCIiIm5HAUhERETcjgKQiIiIuB0FIBEREXE7/w+rc2fEra4/nQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Model Performance Charts\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(cnn_lstm_model_history.history['acc'])\n",
        "plt.plot(cnn_lstm_model_history.history['val_acc'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(cnn_lstm_model_history.history['loss'])\n",
        "plt.plot(cnn_lstm_model_history.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc = 'upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvHuOL94_VeV"
      },
      "outputs": [],
      "source": [
        "# Saving the model as a h5 file for possible use later\n",
        "cnn_lstm_model.save(f\"./drive/MyDrive/c1_cnn_lstm_model_acc_{round(score[1], 3)}.h5\", save_format='h5')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CK9e4Uz5AYTT"
      },
      "source": [
        "# Testing CNN-LSTM model on New Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rL9knIAlAePQ"
      },
      "outputs": [],
      "source": [
        "#Loading LSTM Model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "cnn_lstm_model = load_model('/content/drive/MyDrive/c1_cnn_lstm_model_acc_0.952.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "slhOGXpRAs7F",
        "outputId": "21a0b463-5410-448a-fe6d-d1fe5100e04d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-558ae3e9-4977-4a79-95db-098652e642a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dateAdded</th>\n",
              "      <th>dateUpdated</th>\n",
              "      <th>name</th>\n",
              "      <th>asins</th>\n",
              "      <th>brand</th>\n",
              "      <th>categories</th>\n",
              "      <th>primaryCategories</th>\n",
              "      <th>imageURLs</th>\n",
              "      <th>keys</th>\n",
              "      <th>...</th>\n",
              "      <th>reviews.doRecommend</th>\n",
              "      <th>reviews.id</th>\n",
              "      <th>reviews.numHelpful</th>\n",
              "      <th>reviews.rating</th>\n",
              "      <th>reviews.sourceURLs</th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>reviews.title</th>\n",
              "      <th>reviews.username</th>\n",
              "      <th>sourceURLs</th>\n",
              "      <th>Srn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>I order 3 of them and one of the item is bad q...</td>\n",
              "      <td>... 3 of them and one of the item is bad quali...</td>\n",
              "      <td>Byger yang</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>Bulk is always the less expensive way to go fo...</td>\n",
              "      <td>... always the less expensive way to go for pr...</td>\n",
              "      <td>ByMG</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>Well they are not Duracell but for the price i...</td>\n",
              "      <td>... are not Duracell but for the price i am ha...</td>\n",
              "      <td>BySharon Lambert</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>Seem to work as well as name brand batteries a...</td>\n",
              "      <td>... as well as name brand batteries at a much ...</td>\n",
              "      <td>Bymark sexson</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>These batteries are very long lasting the pric...</td>\n",
              "      <td>... batteries are very long lasting the price ...</td>\n",
              "      <td>Bylinda</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>Bought a lot of batteries for Christmas and th...</td>\n",
              "      <td>... batteries for Christmas and the AmazonBasi...</td>\n",
              "      <td>ByPainter Marlow</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-558ae3e9-4977-4a79-95db-098652e642a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-558ae3e9-4977-4a79-95db-098652e642a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-558ae3e9-4977-4a79-95db-098652e642a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                     id             dateAdded           dateUpdated  \\\n",
              "0  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "1  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "2  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "3  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "4  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "5  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "\n",
              "                                                name                  asins  \\\n",
              "0  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "1  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "2  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "3  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "4  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "5  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "\n",
              "          brand                                         categories  \\\n",
              "0  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "1  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "2  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "3  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "4  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "5  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "\n",
              "  primaryCategories                                          imageURLs  \\\n",
              "0   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "1   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "2   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "3   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "4   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "5   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "\n",
              "                                                keys  ... reviews.doRecommend  \\\n",
              "0  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "1  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "2  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "3  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "4  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "5  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "\n",
              "  reviews.id reviews.numHelpful reviews.rating  \\\n",
              "0        NaN                NaN              3   \n",
              "1        NaN                NaN              4   \n",
              "2        NaN                NaN              5   \n",
              "3        NaN                NaN              5   \n",
              "4        NaN                NaN              5   \n",
              "5        NaN                NaN              5   \n",
              "\n",
              "                                  reviews.sourceURLs  \\\n",
              "0  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "1  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "2  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "3  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "4  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "5  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "\n",
              "                                        reviews.text  \\\n",
              "0  I order 3 of them and one of the item is bad q...   \n",
              "1  Bulk is always the less expensive way to go fo...   \n",
              "2  Well they are not Duracell but for the price i...   \n",
              "3  Seem to work as well as name brand batteries a...   \n",
              "4  These batteries are very long lasting the pric...   \n",
              "5  Bought a lot of batteries for Christmas and th...   \n",
              "\n",
              "                                       reviews.title  reviews.username  \\\n",
              "0  ... 3 of them and one of the item is bad quali...        Byger yang   \n",
              "1  ... always the less expensive way to go for pr...              ByMG   \n",
              "2  ... are not Duracell but for the price i am ha...  BySharon Lambert   \n",
              "3  ... as well as name brand batteries at a much ...     Bymark sexson   \n",
              "4  ... batteries are very long lasting the price ...           Bylinda   \n",
              "5  ... batteries for Christmas and the AmazonBasi...  ByPainter Marlow   \n",
              "\n",
              "                                          sourceURLs Srn  \n",
              "0  https://www.barcodable.com/upc/841710106442,ht...   0  \n",
              "1  https://www.barcodable.com/upc/841710106442,ht...   1  \n",
              "2  https://www.barcodable.com/upc/841710106442,ht...   2  \n",
              "3  https://www.barcodable.com/upc/841710106442,ht...   3  \n",
              "4  https://www.barcodable.com/upc/841710106442,ht...   4  \n",
              "5  https://www.barcodable.com/upc/841710106442,ht...   5  \n",
              "\n",
              "[6 rows x 25 columns]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_reviews = pd.read_csv(\"/content/drive/MyDrive/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\")\n",
        "\n",
        "sample_reviews['Srn'] = np.arange(sample_reviews.shape[0])\n",
        "\n",
        "sample_reviews.head(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_owzmmNA0vm"
      },
      "outputs": [],
      "source": [
        "# Pre-processing text\n",
        "\n",
        "unseen_reviews = sample_reviews['reviews.text'] + sample_reviews['reviews.title']\n",
        "\n",
        "unseen_processed = []\n",
        "for review in unseen_reviews:\n",
        "  review = preprocess_text(review)\n",
        "  unseen_processed.append(review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juUMYrLtBPpw"
      },
      "outputs": [],
      "source": [
        "# Tokenising instance with earlier trained tokeniser\n",
        "unseen_tokenized = word_tokenizer.texts_to_sequences(unseen_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAYUc9k4BSPW"
      },
      "outputs": [],
      "source": [
        "# Pooling instance to have maxlength of 100 tokens\n",
        "unseen_padded = pad_sequences(unseen_tokenized, padding='post', maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "8jlt6YMHBXQx",
        "outputId": "0767672a-911b-4553-c2a3-ccd1ed4c85ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "886/886 [==============================] - 3s 3ms/step\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4c2b81b3-ccbe-4a30-85a3-ce721afbeedb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Srn</th>\n",
              "      <th>name</th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>reviews.rating</th>\n",
              "      <th>Predicted Sentiments_cnn_lstm</th>\n",
              "      <th>reviews.rating_sentiment</th>\n",
              "      <th>cnn_lstm_Predicted.rating_sentiment</th>\n",
              "      <th>cnn_lstm_vs_actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>I order 3 of them and one of the item is bad q...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Bulk is always the less expensive way to go fo...</td>\n",
              "      <td>4</td>\n",
              "      <td>4.4</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Well they are not Duracell but for the price i...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Seem to work as well as name brand batteries a...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>These batteries are very long lasting the pric...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c2b81b3-ccbe-4a30-85a3-ce721afbeedb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c2b81b3-ccbe-4a30-85a3-ce721afbeedb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c2b81b3-ccbe-4a30-85a3-ce721afbeedb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Srn                                               name  \\\n",
              "0    0  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "1    1  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "2    2  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "3    3  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "4    4  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "\n",
              "                                        reviews.text  reviews.rating  \\\n",
              "0  I order 3 of them and one of the item is bad q...               3   \n",
              "1  Bulk is always the less expensive way to go fo...               4   \n",
              "2  Well they are not Duracell but for the price i...               5   \n",
              "3  Seem to work as well as name brand batteries a...               5   \n",
              "4  These batteries are very long lasting the pric...               5   \n",
              "\n",
              "   Predicted Sentiments_cnn_lstm reviews.rating_sentiment  \\\n",
              "0                            0.0                 positive   \n",
              "1                            4.4                 positive   \n",
              "2                            5.0                 positive   \n",
              "3                            5.0                 positive   \n",
              "4                            5.0                 positive   \n",
              "\n",
              "  cnn_lstm_Predicted.rating_sentiment  cnn_lstm_vs_actual  \n",
              "0                            negative               False  \n",
              "1                            positive                True  \n",
              "2                            positive                True  \n",
              "3                            positive                True  \n",
              "4                            positive                True  "
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Passing tokenised instance to the CNN model for predictions\n",
        "unseen_sentiments = cnn_lstm_model.predict(unseen_padded)\n",
        "\n",
        "sample_reviews['Predicted Sentiments_cnn_lstm'] = np.round((unseen_sentiments*10)/2,1)\n",
        "\n",
        "\n",
        "df_cnn_lstm_prediction = sample_reviews[['Srn','name','reviews.text','reviews.rating','Predicted Sentiments_cnn_lstm']]\n",
        "\n",
        "df_cnn_lstm_prediction.head(10)\n",
        "\n",
        "df_cnn_lstm_prediction['reviews.rating_sentiment'] = df_cnn_lstm_prediction['reviews.rating'].apply(lambda x: 'positive' if x >=3  else 'negative')\n",
        "df_cnn_lstm_prediction['cnn_lstm_Predicted.rating_sentiment'] = df_cnn_lstm_prediction['Predicted Sentiments_cnn_lstm'].apply(lambda x: 'positive' if x >=3  else 'negative')\n",
        "df_cnn_lstm_prediction['cnn_lstm_vs_actual'] = df_cnn_lstm_prediction['reviews.rating_sentiment'] == df_cnn_lstm_prediction['cnn_lstm_Predicted.rating_sentiment']\n",
        "\n",
        "df_cnn_lstm_prediction.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "UxAJHkj0BaAz",
        "outputId": "cf4bf6fb-7c98-481e-a73c-0b37cef74ead"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_cnn_lstm_prediction.groupby('cnn_lstm_vs_actual').size().plot(kind='pie', autopct='%1.0f%%')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iOmJRfEM_jV5"
      },
      "source": [
        "\n",
        "\n",
        "# Testing LSTM model on New Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzuYP3WJDb_v"
      },
      "outputs": [],
      "source": [
        "#Loading LSTM Model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "lstm_model = load_model('/content/drive/MyDrive/c1_lstm_model_acc_0.962.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "dlzNCBgG_tW-",
        "outputId": "5b65f579-00be-478e-8e4b-432f5decccd8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c64c9f78-53b9-4c4d-ab83-6bed053f7baa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dateAdded</th>\n",
              "      <th>dateUpdated</th>\n",
              "      <th>name</th>\n",
              "      <th>asins</th>\n",
              "      <th>brand</th>\n",
              "      <th>categories</th>\n",
              "      <th>primaryCategories</th>\n",
              "      <th>imageURLs</th>\n",
              "      <th>keys</th>\n",
              "      <th>...</th>\n",
              "      <th>reviews.doRecommend</th>\n",
              "      <th>reviews.id</th>\n",
              "      <th>reviews.numHelpful</th>\n",
              "      <th>reviews.rating</th>\n",
              "      <th>reviews.sourceURLs</th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>reviews.title</th>\n",
              "      <th>reviews.username</th>\n",
              "      <th>sourceURLs</th>\n",
              "      <th>Srn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>I order 3 of them and one of the item is bad q...</td>\n",
              "      <td>... 3 of them and one of the item is bad quali...</td>\n",
              "      <td>Byger yang</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>Bulk is always the less expensive way to go fo...</td>\n",
              "      <td>... always the less expensive way to go for pr...</td>\n",
              "      <td>ByMG</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>Well they are not Duracell but for the price i...</td>\n",
              "      <td>... are not Duracell but for the price i am ha...</td>\n",
              "      <td>BySharon Lambert</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>Seem to work as well as name brand batteries a...</td>\n",
              "      <td>... as well as name brand batteries at a much ...</td>\n",
              "      <td>Bymark sexson</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>These batteries are very long lasting the pric...</td>\n",
              "      <td>... batteries are very long lasting the price ...</td>\n",
              "      <td>Bylinda</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>Bought a lot of batteries for Christmas and th...</td>\n",
              "      <td>... batteries for Christmas and the AmazonBasi...</td>\n",
              "      <td>ByPainter Marlow</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c64c9f78-53b9-4c4d-ab83-6bed053f7baa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c64c9f78-53b9-4c4d-ab83-6bed053f7baa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c64c9f78-53b9-4c4d-ab83-6bed053f7baa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                     id             dateAdded           dateUpdated  \\\n",
              "0  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "1  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "2  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "3  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "4  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "5  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "\n",
              "                                                name                  asins  \\\n",
              "0  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "1  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "2  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "3  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "4  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "5  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "\n",
              "          brand                                         categories  \\\n",
              "0  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "1  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "2  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "3  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "4  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "5  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "\n",
              "  primaryCategories                                          imageURLs  \\\n",
              "0   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "1   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "2   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "3   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "4   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "5   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "\n",
              "                                                keys  ... reviews.doRecommend  \\\n",
              "0  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "1  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "2  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "3  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "4  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "5  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "\n",
              "  reviews.id reviews.numHelpful reviews.rating  \\\n",
              "0        NaN                NaN              3   \n",
              "1        NaN                NaN              4   \n",
              "2        NaN                NaN              5   \n",
              "3        NaN                NaN              5   \n",
              "4        NaN                NaN              5   \n",
              "5        NaN                NaN              5   \n",
              "\n",
              "                                  reviews.sourceURLs  \\\n",
              "0  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "1  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "2  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "3  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "4  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "5  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "\n",
              "                                        reviews.text  \\\n",
              "0  I order 3 of them and one of the item is bad q...   \n",
              "1  Bulk is always the less expensive way to go fo...   \n",
              "2  Well they are not Duracell but for the price i...   \n",
              "3  Seem to work as well as name brand batteries a...   \n",
              "4  These batteries are very long lasting the pric...   \n",
              "5  Bought a lot of batteries for Christmas and th...   \n",
              "\n",
              "                                       reviews.title  reviews.username  \\\n",
              "0  ... 3 of them and one of the item is bad quali...        Byger yang   \n",
              "1  ... always the less expensive way to go for pr...              ByMG   \n",
              "2  ... are not Duracell but for the price i am ha...  BySharon Lambert   \n",
              "3  ... as well as name brand batteries at a much ...     Bymark sexson   \n",
              "4  ... batteries are very long lasting the price ...           Bylinda   \n",
              "5  ... batteries for Christmas and the AmazonBasi...  ByPainter Marlow   \n",
              "\n",
              "                                          sourceURLs Srn  \n",
              "0  https://www.barcodable.com/upc/841710106442,ht...   0  \n",
              "1  https://www.barcodable.com/upc/841710106442,ht...   1  \n",
              "2  https://www.barcodable.com/upc/841710106442,ht...   2  \n",
              "3  https://www.barcodable.com/upc/841710106442,ht...   3  \n",
              "4  https://www.barcodable.com/upc/841710106442,ht...   4  \n",
              "5  https://www.barcodable.com/upc/841710106442,ht...   5  \n",
              "\n",
              "[6 rows x 25 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_reviews = pd.read_csv(\"/content/drive/MyDrive/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\")\n",
        "\n",
        "sample_reviews['Srn'] = np.arange(sample_reviews.shape[0])\n",
        "\n",
        "sample_reviews.head(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bN_bE9WV_wfO"
      },
      "outputs": [],
      "source": [
        "# Pre-processing text\n",
        "\n",
        "unseen_reviews = sample_reviews['reviews.text'] + sample_reviews['reviews.title']\n",
        "\n",
        "unseen_processed = []\n",
        "for review in unseen_reviews:\n",
        "  review = preprocess_text(review)\n",
        "  unseen_processed.append(review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEk7BAcb_y6f"
      },
      "outputs": [],
      "source": [
        "# Tokenising instance with earlier trained tokeniser\n",
        "unseen_tokenized = word_tokenizer.texts_to_sequences(unseen_processed)\n",
        "\n",
        "# Pooling instance to have maxlength of 100 tokens\n",
        "unseen_padded = pad_sequences(unseen_tokenized, padding='post', maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49k8xUDP_7Ar",
        "outputId": "0c58eef5-7285-4834-a860-16d1c27b98ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "886/886 [==============================] - 35s 39ms/step\n"
          ]
        }
      ],
      "source": [
        "# Passing tokenised instance to the CNN model for predictions\n",
        "unseen_sentiments = lstm_model.predict(unseen_padded)\n",
        "\n",
        "sample_reviews['Predicted Sentiments_lstm'] = np.round((unseen_sentiments*10)/2,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "pi3MBEWXAAP4",
        "outputId": "130b8987-6077-468d-f43b-f4a27f641506"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-35495567-c7d0-4aea-996d-f095748440cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Srn</th>\n",
              "      <th>name</th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>reviews.rating</th>\n",
              "      <th>Predicted Sentiments_lstm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>I order 3 of them and one of the item is bad q...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Bulk is always the less expensive way to go fo...</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Well they are not Duracell but for the price i...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Seem to work as well as name brand batteries a...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>These batteries are very long lasting the pric...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Bought a lot of batteries for Christmas and th...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>ive not had any problame with these batteries ...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Well if you are looking for cheap non-recharge...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>These do not hold the amount of high power jui...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>AmazonBasics AA AAA batteries have done well b...</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35495567-c7d0-4aea-996d-f095748440cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35495567-c7d0-4aea-996d-f095748440cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35495567-c7d0-4aea-996d-f095748440cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Srn                                               name  \\\n",
              "0    0  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "1    1  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "2    2  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "3    3  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "4    4  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "5    5  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "6    6  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "7    7  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "8    8  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "9    9  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "\n",
              "                                        reviews.text  reviews.rating  \\\n",
              "0  I order 3 of them and one of the item is bad q...               3   \n",
              "1  Bulk is always the less expensive way to go fo...               4   \n",
              "2  Well they are not Duracell but for the price i...               5   \n",
              "3  Seem to work as well as name brand batteries a...               5   \n",
              "4  These batteries are very long lasting the pric...               5   \n",
              "5  Bought a lot of batteries for Christmas and th...               5   \n",
              "6  ive not had any problame with these batteries ...               5   \n",
              "7  Well if you are looking for cheap non-recharge...               5   \n",
              "8  These do not hold the amount of high power jui...               3   \n",
              "9  AmazonBasics AA AAA batteries have done well b...               4   \n",
              "\n",
              "   Predicted Sentiments_lstm  \n",
              "0                        0.0  \n",
              "1                        5.0  \n",
              "2                        5.0  \n",
              "3                        5.0  \n",
              "4                        5.0  \n",
              "5                        5.0  \n",
              "6                        5.0  \n",
              "7                        5.0  \n",
              "8                        5.0  \n",
              "9                        5.0  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_lstm_prediction = sample_reviews[['Srn','name','reviews.text','reviews.rating','Predicted Sentiments_lstm']]\n",
        "\n",
        "df_lstm_prediction.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "hkXojauI_8Ko",
        "outputId": "1c44abf2-a1e4-4300-b4c5-7a1733013541"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bfde7f49-b541-4e84-995a-8470287d2b02\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Srn</th>\n",
              "      <th>name</th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>reviews.rating</th>\n",
              "      <th>Predicted Sentiments_lstm</th>\n",
              "      <th>reviews.rating_sentiment</th>\n",
              "      <th>LSTM_Predicted.rating_sentiment</th>\n",
              "      <th>lstm_vs_actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>I order 3 of them and one of the item is bad q...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Bulk is always the less expensive way to go fo...</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Well they are not Duracell but for the price i...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Seem to work as well as name brand batteries a...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>These batteries are very long lasting the pric...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfde7f49-b541-4e84-995a-8470287d2b02')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bfde7f49-b541-4e84-995a-8470287d2b02 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bfde7f49-b541-4e84-995a-8470287d2b02');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Srn                                               name  \\\n",
              "0    0  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "1    1  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "2    2  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "3    3  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "4    4  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "\n",
              "                                        reviews.text  reviews.rating  \\\n",
              "0  I order 3 of them and one of the item is bad q...               3   \n",
              "1  Bulk is always the less expensive way to go fo...               4   \n",
              "2  Well they are not Duracell but for the price i...               5   \n",
              "3  Seem to work as well as name brand batteries a...               5   \n",
              "4  These batteries are very long lasting the pric...               5   \n",
              "\n",
              "   Predicted Sentiments_lstm reviews.rating_sentiment  \\\n",
              "0                        0.0                 positive   \n",
              "1                        5.0                 positive   \n",
              "2                        5.0                 positive   \n",
              "3                        5.0                 positive   \n",
              "4                        5.0                 positive   \n",
              "\n",
              "  LSTM_Predicted.rating_sentiment  lstm_vs_actual  \n",
              "0                        negative           False  \n",
              "1                        positive            True  \n",
              "2                        positive            True  \n",
              "3                        positive            True  \n",
              "4                        positive            True  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_lstm_prediction['reviews.rating_sentiment'] = df_lstm_prediction['reviews.rating'].apply(lambda x: 'positive' if x >=3  else 'negative')\n",
        "df_lstm_prediction['LSTM_Predicted.rating_sentiment'] = df_lstm_prediction['Predicted Sentiments_lstm'].apply(lambda x: 'positive' if x >=3  else 'negative')\n",
        "df_lstm_prediction['lstm_vs_actual'] = df_lstm_prediction['reviews.rating_sentiment'] == df_lstm_prediction['LSTM_Predicted.rating_sentiment']\n",
        "\n",
        "df_lstm_prediction.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "d4e8t60xAxCu",
        "outputId": "91d6dd22-db5a-4206-dc3b-c3dfb2272f18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_lstm_prediction.groupby('lstm_vs_actual').size().plot(kind='pie', autopct='%1.0f%%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "A-Zu-O_qqWtH",
        "outputId": "d993b69e-c552-4ff3-c1b9-8fc48c94e2ec"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "C_M = confusion_matrix(df_lstm_prediction['reviews.rating_sentiment'], df_lstm_prediction['LSTM_Predicted.rating_sentiment'])\n",
        "\n",
        "# Define labels\n",
        "labels = {0: \"Negative\", 1: \"Positive\"}\n",
        "\n",
        "# Plot confusion matrix\n",
        "sns.set(font_scale=1.5)\n",
        "ax = sns.heatmap(C_M, annot=True, fmt=\"d\", xticklabels=labels.values(), yticklabels=labels.values())\n",
        "ax.set_title(\"Confusion Matrix Sentiments\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0dr-ON1ouMJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score,balanced_accuracy_score,confusion_matrix\n",
        "\n",
        "Accuracy_LSTM_newdata = accuracy_score(df_lstm_prediction['reviews.rating_sentiment'], df_lstm_prediction['LSTM_Predicted.rating_sentiment'])\n",
        "Balanced_accuracy_LSTM_newdata = balanced_accuracy_score(df_lstm_prediction['reviews.rating_sentiment'], df_lstm_prediction['LSTM_Predicted.rating_sentiment'])\n",
        "Precision_LSTM_newdata = precision_score(df_lstm_prediction['reviews.rating_sentiment'], df_lstm_prediction['LSTM_Predicted.rating_sentiment'],average = 'weighted')\n",
        "Recall_LSTM_newdata = recall_score(df_lstm_prediction['reviews.rating_sentiment'], df_lstm_prediction['LSTM_Predicted.rating_sentiment'],average = 'weighted')\n",
        "F1_score_LSTM_newdata = f1_score(df_lstm_prediction['reviews.rating_sentiment'], df_lstm_prediction['LSTM_Predicted.rating_sentiment'],average = 'weighted') #, average='macro'\n",
        "sensitivity_LSTM_newdata = Recall_LSTM_newdata\n",
        "specificity_LSTM_newdata =  C_M[0][0] / (C_M[0][0] + C_M[0][1]) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDInI0egpe6B",
        "outputId": "2ee5f08b-1f21-497f-b832-65fdd8c70d88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9404913172384582\n",
            "0.8107778978203444\n",
            "0.9516162481356331\n",
            "0.9404913172384582\n",
            "0.9450562191325741\n",
            "0.9404913172384582\n",
            "0.6647691334598356\n"
          ]
        }
      ],
      "source": [
        "print(Accuracy_LSTM_newdata)\n",
        "print(Balanced_accuracy_LSTM_newdata)\n",
        "print(Precision_LSTM_newdata)\n",
        "print(Recall_LSTM_newdata)\n",
        "print(F1_score_LSTM_newdata)\n",
        "print(sensitivity_LSTM_newdata)\n",
        "print(specificity_LSTM_newdata)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "i6S-VzQtMilJ"
      },
      "source": [
        "# Testing CNN model on New Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ycwl1XxeOXh_"
      },
      "outputs": [],
      "source": [
        "#Loading CNN Model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "cnn_model = load_model('/content/drive/MyDrive/c1_cnn_model_acc_0.97.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "iPAK-DF2MhpL",
        "outputId": "28275c71-30fd-44d3-da68-5b83784909bf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c647f9fa-ccc4-4677-8308-890e51fcfbaa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dateAdded</th>\n",
              "      <th>dateUpdated</th>\n",
              "      <th>name</th>\n",
              "      <th>asins</th>\n",
              "      <th>brand</th>\n",
              "      <th>categories</th>\n",
              "      <th>primaryCategories</th>\n",
              "      <th>imageURLs</th>\n",
              "      <th>keys</th>\n",
              "      <th>...</th>\n",
              "      <th>reviews.doRecommend</th>\n",
              "      <th>reviews.id</th>\n",
              "      <th>reviews.numHelpful</th>\n",
              "      <th>reviews.rating</th>\n",
              "      <th>reviews.sourceURLs</th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>reviews.title</th>\n",
              "      <th>reviews.username</th>\n",
              "      <th>sourceURLs</th>\n",
              "      <th>Srn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>I order 3 of them and one of the item is bad q...</td>\n",
              "      <td>... 3 of them and one of the item is bad quali...</td>\n",
              "      <td>Byger yang</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>Bulk is always the less expensive way to go fo...</td>\n",
              "      <td>... always the less expensive way to go for pr...</td>\n",
              "      <td>ByMG</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>Well they are not Duracell but for the price i...</td>\n",
              "      <td>... are not Duracell but for the price i am ha...</td>\n",
              "      <td>BySharon Lambert</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>Seem to work as well as name brand batteries a...</td>\n",
              "      <td>... as well as name brand batteries at a much ...</td>\n",
              "      <td>Bymark sexson</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>These batteries are very long lasting the pric...</td>\n",
              "      <td>... batteries are very long lasting the price ...</td>\n",
              "      <td>Bylinda</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AVpgNzjwLJeJML43Kpxn</td>\n",
              "      <td>2015-10-30T08:59:32Z</td>\n",
              "      <td>2019-04-25T09:08:16Z</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>B00QWO9P0O,B00LH3DMUO</td>\n",
              "      <td>Amazonbasics</td>\n",
              "      <td>AA,AAA,Health,Electronics,Health &amp; Household,C...</td>\n",
              "      <td>Health &amp; Beauty</td>\n",
              "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
              "      <td>amazonbasics/hl002619,amazonbasicsaaaperforman...</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>https://www.amazon.com/product-reviews/B00QWO9...</td>\n",
              "      <td>Bought a lot of batteries for Christmas and th...</td>\n",
              "      <td>... batteries for Christmas and the AmazonBasi...</td>\n",
              "      <td>ByPainter Marlow</td>\n",
              "      <td>https://www.barcodable.com/upc/841710106442,ht...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c647f9fa-ccc4-4677-8308-890e51fcfbaa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c647f9fa-ccc4-4677-8308-890e51fcfbaa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c647f9fa-ccc4-4677-8308-890e51fcfbaa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                     id             dateAdded           dateUpdated  \\\n",
              "0  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "1  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "2  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "3  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "4  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "5  AVpgNzjwLJeJML43Kpxn  2015-10-30T08:59:32Z  2019-04-25T09:08:16Z   \n",
              "\n",
              "                                                name                  asins  \\\n",
              "0  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "1  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "2  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "3  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "4  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "5  AmazonBasics AAA Performance Alkaline Batterie...  B00QWO9P0O,B00LH3DMUO   \n",
              "\n",
              "          brand                                         categories  \\\n",
              "0  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "1  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "2  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "3  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "4  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "5  Amazonbasics  AA,AAA,Health,Electronics,Health & Household,C...   \n",
              "\n",
              "  primaryCategories                                          imageURLs  \\\n",
              "0   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "1   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "2   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "3   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "4   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "5   Health & Beauty  https://images-na.ssl-images-amazon.com/images...   \n",
              "\n",
              "                                                keys  ... reviews.doRecommend  \\\n",
              "0  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "1  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "2  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "3  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "4  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "5  amazonbasics/hl002619,amazonbasicsaaaperforman...  ...                 NaN   \n",
              "\n",
              "  reviews.id reviews.numHelpful reviews.rating  \\\n",
              "0        NaN                NaN              3   \n",
              "1        NaN                NaN              4   \n",
              "2        NaN                NaN              5   \n",
              "3        NaN                NaN              5   \n",
              "4        NaN                NaN              5   \n",
              "5        NaN                NaN              5   \n",
              "\n",
              "                                  reviews.sourceURLs  \\\n",
              "0  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "1  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "2  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "3  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "4  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "5  https://www.amazon.com/product-reviews/B00QWO9...   \n",
              "\n",
              "                                        reviews.text  \\\n",
              "0  I order 3 of them and one of the item is bad q...   \n",
              "1  Bulk is always the less expensive way to go fo...   \n",
              "2  Well they are not Duracell but for the price i...   \n",
              "3  Seem to work as well as name brand batteries a...   \n",
              "4  These batteries are very long lasting the pric...   \n",
              "5  Bought a lot of batteries for Christmas and th...   \n",
              "\n",
              "                                       reviews.title  reviews.username  \\\n",
              "0  ... 3 of them and one of the item is bad quali...        Byger yang   \n",
              "1  ... always the less expensive way to go for pr...              ByMG   \n",
              "2  ... are not Duracell but for the price i am ha...  BySharon Lambert   \n",
              "3  ... as well as name brand batteries at a much ...     Bymark sexson   \n",
              "4  ... batteries are very long lasting the price ...           Bylinda   \n",
              "5  ... batteries for Christmas and the AmazonBasi...  ByPainter Marlow   \n",
              "\n",
              "                                          sourceURLs Srn  \n",
              "0  https://www.barcodable.com/upc/841710106442,ht...   0  \n",
              "1  https://www.barcodable.com/upc/841710106442,ht...   1  \n",
              "2  https://www.barcodable.com/upc/841710106442,ht...   2  \n",
              "3  https://www.barcodable.com/upc/841710106442,ht...   3  \n",
              "4  https://www.barcodable.com/upc/841710106442,ht...   4  \n",
              "5  https://www.barcodable.com/upc/841710106442,ht...   5  \n",
              "\n",
              "[6 rows x 25 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_reviews = pd.read_csv(\"/content/drive/MyDrive/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\")\n",
        "\n",
        "sample_reviews['Srn'] = np.arange(sample_reviews.shape[0])\n",
        "\n",
        "sample_reviews.head(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VzwiRy3Mo6W"
      },
      "outputs": [],
      "source": [
        "# Pre-processing text\n",
        "\n",
        "unseen_reviews = sample_reviews['reviews.text'] + sample_reviews['reviews.title']\n",
        "\n",
        "unseen_processed = []\n",
        "for review in unseen_reviews:\n",
        "  review = preprocess_text(review)\n",
        "  unseen_processed.append(review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sIFwrbfMrWn"
      },
      "outputs": [],
      "source": [
        "# Tokenising instance with earlier trained tokeniser\n",
        "unseen_tokenized = word_tokenizer.texts_to_sequences(unseen_processed)\n",
        "\n",
        "# Pooling instance to have maxlength of 100 tokens\n",
        "unseen_padded = pad_sequences(unseen_tokenized, padding='post', maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHOAlCe4Ms23",
        "outputId": "d36f94bc-d93c-48ba-b009-8d92803d55cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "886/886 [==============================] - 7s 8ms/step\n"
          ]
        }
      ],
      "source": [
        "# Passing tokenised instance to the CNN model for predictions\n",
        "unseen_sentiments = cnn_model.predict(unseen_padded)\n",
        "\n",
        "sample_reviews['Predicted Sentiments_cnn'] = np.round((unseen_sentiments*10)/2,1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iRuOu2XYMu93",
        "outputId": "15a182e7-53f5-4c26-f534-5048150a5cd3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2f5afca4-c12a-4091-8655-f84d78215ae7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Srn</th>\n",
              "      <th>name</th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>reviews.rating</th>\n",
              "      <th>Predicted Sentiments_cnn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>I order 3 of them and one of the item is bad q...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Bulk is always the less expensive way to go fo...</td>\n",
              "      <td>4</td>\n",
              "      <td>4.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Well they are not Duracell but for the price i...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Seem to work as well as name brand batteries a...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>These batteries are very long lasting the pric...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f5afca4-c12a-4091-8655-f84d78215ae7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f5afca4-c12a-4091-8655-f84d78215ae7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f5afca4-c12a-4091-8655-f84d78215ae7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Srn                                               name  \\\n",
              "0    0  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "1    1  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "2    2  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "3    3  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "4    4  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "\n",
              "                                        reviews.text  reviews.rating  \\\n",
              "0  I order 3 of them and one of the item is bad q...               3   \n",
              "1  Bulk is always the less expensive way to go fo...               4   \n",
              "2  Well they are not Duracell but for the price i...               5   \n",
              "3  Seem to work as well as name brand batteries a...               5   \n",
              "4  These batteries are very long lasting the pric...               5   \n",
              "\n",
              "   Predicted Sentiments_cnn  \n",
              "0                       0.5  \n",
              "1                       4.9  \n",
              "2                       5.0  \n",
              "3                       5.0  \n",
              "4                       5.0  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cnn_prediction = sample_reviews[['Srn','name','reviews.text','reviews.rating','Predicted Sentiments_cnn']]\n",
        "\n",
        "df_cnn_prediction.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "IhutkYk8NEvk",
        "outputId": "425f8545-8b19-4e61-e93a-d85f8b8e09bb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f93d3ded-142d-472c-a03b-55738dea88cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Srn</th>\n",
              "      <th>name</th>\n",
              "      <th>reviews.text</th>\n",
              "      <th>reviews.rating</th>\n",
              "      <th>Predicted Sentiments_cnn</th>\n",
              "      <th>reviews.rating_sentiment</th>\n",
              "      <th>CNN_Predicted.rating_sentiment</th>\n",
              "      <th>cnn_vs_actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>I order 3 of them and one of the item is bad q...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Bulk is always the less expensive way to go fo...</td>\n",
              "      <td>4</td>\n",
              "      <td>4.9</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Well they are not Duracell but for the price i...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>Seem to work as well as name brand batteries a...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
              "      <td>These batteries are very long lasting the pric...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f93d3ded-142d-472c-a03b-55738dea88cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f93d3ded-142d-472c-a03b-55738dea88cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f93d3ded-142d-472c-a03b-55738dea88cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Srn                                               name  \\\n",
              "0    0  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "1    1  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "2    2  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "3    3  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "4    4  AmazonBasics AAA Performance Alkaline Batterie...   \n",
              "\n",
              "                                        reviews.text  reviews.rating  \\\n",
              "0  I order 3 of them and one of the item is bad q...               3   \n",
              "1  Bulk is always the less expensive way to go fo...               4   \n",
              "2  Well they are not Duracell but for the price i...               5   \n",
              "3  Seem to work as well as name brand batteries a...               5   \n",
              "4  These batteries are very long lasting the pric...               5   \n",
              "\n",
              "   Predicted Sentiments_cnn reviews.rating_sentiment  \\\n",
              "0                       0.5                 positive   \n",
              "1                       4.9                 positive   \n",
              "2                       5.0                 positive   \n",
              "3                       5.0                 positive   \n",
              "4                       5.0                 positive   \n",
              "\n",
              "  CNN_Predicted.rating_sentiment  cnn_vs_actual  \n",
              "0                       negative          False  \n",
              "1                       positive           True  \n",
              "2                       positive           True  \n",
              "3                       positive           True  \n",
              "4                       positive           True  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cnn_prediction['reviews.rating_sentiment'] = df_cnn_prediction['reviews.rating'].apply(lambda x: 'positive' if x >=3  else 'negative')\n",
        "df_cnn_prediction['CNN_Predicted.rating_sentiment'] = df_cnn_prediction['Predicted Sentiments_cnn'].apply(lambda x: 'positive' if x >=3  else 'negative')\n",
        "df_cnn_prediction['cnn_vs_actual'] = df_cnn_prediction['reviews.rating_sentiment'] == df_cnn_prediction['CNN_Predicted.rating_sentiment']\n",
        "\n",
        "df_cnn_prediction.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "KN9IPuofOuxm",
        "outputId": "fc2edacf-bece-4a6c-c847-fa43df342900"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_cnn_prediction.groupby('cnn_vs_actual').size().plot(kind='pie', autopct='%1.0f%%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "u2Wz9ZtnsAIE",
        "outputId": "0d26e2d4-1cd1-4f35-90ba-04d366240d7c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkYAAAHFCAYAAAAXETaHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACBx0lEQVR4nO3ddVzU9x8H8NfRICACggIq1ok5AzsRO7A2Y3b3bJ1ubrbut6kzZszAmDFb7MIWG3XWLFpFFOmG7+8PuO847w6B+yJ4vp573GPw/X7qjhPe90mZIAgCiIiIiAh6+d0AIiIiooKCgRERERFRBgZGRERERBkYGBERERFlYGBERERElIGBEREREVEGBkZEREREGRgYEREREWVgYERERESUgYGRjvn3338xbtw4NGrUCJUqVUKFChXQqVOnfGvPtWvXUKFCBVSoUCHf2kDqBQcHiz+b4ODg/G6OTlmxYgUqVKiAvn375ndTiCiHDPK7AQVRamoqTpw4gXPnzuHu3bt49+4dEhISYGFhAWdnZ7i6uqJjx46Qy+X53VQlQUFB6NWrF2JjYwEAVlZWMDAwQJEiRfK5ZZ+nzMFcmTJlcOzYsSzT37t3D9988434fZcuXbBo0SLJ2vPo0SOcPn0aFhYWGDBggGTl5pe7d+9i165duH37Nl6/fo3k5GTY2NjAxsYGFSpUQO3atVG/fn0UL148v5sq0rWfQV5YsWIFgPT3v5OTUz63hijnGBh94M6dO5g2bRr8/f3Fa4aGhihUqBAiIiJw+/Zt3L59G3/++SdatWqFxYsXw8jIKP8anMnff/+N2NhYlCpVClu3boW9vX1+NwmmpqYoXbp0fjdDay9evICvry9q1KihMc3evXvztA2PHj3CypUr4ejoKMkfZUNDQ/FnY2hoqHV52SUIAhYsWIAtW7aI12QyGSwtLREeHo7Xr1/jwYMH2Ldvn+TBpbay+zMoUqQISpcuXaCCuk9l5cqVAIA6deowMKLPEgOjTLy9vTFu3DgkJSXBysoKgwcPRqtWreDs7AwgvSfp4cOHOHnyJLZv346TJ08iISGhwARGT548AQC4u7sXiKAIAKpVq4bjx4/ndzO04ujoiJCQEOzbt09jYJSYmIijR49CJpPBwcEBISEhn7iVOWdvb58vP5tNmzaJQZG7uzuGDh2KypUri/+OgoKCcO3aNRw/fhx6ep/naH+fPn3Qp0+f/G4GEeUCA6MM/v7+mDJlCpKSklCuXDls2LABxYoVU0qjr6+PqlWromrVqhg8eDBmzJiRT61VLz4+HgBgZmaWzy3RLZ07d8aqVatw9OhRzJgxA6ampippTp48iaioKNSpUwcAPovAKD8IggBPT08AQOPGjbFq1SqVNCVKlECJEiXw9ddfIyEh4VM3kYi+cAyMMvz++++IiYmBsbExVq5cqRIUfcjKygqrVq2CIAgq98LCwrBx40ZcuHBB/APp6OiIpk2bYtCgQbC1tVXJExwcDHd3dwDAmTNnYGJigjVr1sDb2xthYWGwsLBA3bp1MWbMGJQtW1Ypb/PmzZX+EK9cuVLszgaALVu2oG7dulixYgVWrlyJOnXqYOvWrWqf17Vr19CvXz8A6RO5P3T37l1s2bIFvr6+CAsLg76+PooUKQJHR0fUr18f3bp1U3rtPlZefrxeOeXk5ITatWvj+vXrOHHiBDp37qySRjGM1q1btyyH1OLj43HmzBlcuHAB//77L0JDQxETEwMrKytUq1YNPXr0QNOmTVXyZZ7vFBISojKZfcyYMRg7diwA4Pvvv8f+/fvRpUsXLFy4EHv27MG+ffvw4sULREREYOHChejatavKa6gY9nj//j06deqE0NBQuLu7qw1eUlJS0KdPH/j6+kIul2PPnj0wNjb+yCuZXnZoaCiA9Pftx5iYmGi8Fx4ejs2bN+P8+fMICgpCUlIS7OzsULduXQwcOBDly5dXyfPh+zEgIABr1qzBlStX8O7dO1hbW6NJkyYYO3asSq9rTn4GWf1by/zzWbRoEfbt24e///4bz549g56eHipXrozRo0ejdu3aANJf6x07dmD//v3w9/eHTCZDzZo1MX78eFSuXFnj65OWlobDhw/j0KFDePDgAaKiomBubo5KlSqha9euaN++PWQymUo+xe+ThQsXokOHDtiyZQu8vLwQGBgIfX19VK5cGUOGDEGTJk3UPi8Fxeus4OjoCG9vb/H7169fY+PGjbh8+TJCQkKQkpICKysr2NnZwdXVFR06dEC1atU0Pj+ivMLACMDbt29x4sQJAEDHjh1zNCfmw18s169fx+jRoxEVFQXgv96bZ8+e4dmzZ9izZw9WrVoFV1dXjWU+e/YMM2bMwLt378TeiXfv3uHo0aO4cOECtm3bBhcXFzF9kSJFkJiYiMjISCQnJ8PMzEyp10iq+SP79+/H9OnTxWDQyMgI+vr6ePnyJV6+fIkbN26gePHi6Nq1a7bLzI/XKze6deuG69evY9++fSqBUUhICK5evYpChQqhdevWWQZGx44dw/Tp0wGkv3fMzc1hYGCAsLAwnDlzBmfOnMGgQYMwbdo0pXy2trZISEhATEwM9PT0YG1trXRfXS+hIAgYN24cTpw4AT09PVhYWGRraKpIkSL47bff0L9/f5w5cwbbtm1D7969ldKsWLECvr6+MDExwdKlS7MVFH1IESDlxpUrVzBu3DjxfWNoaAhDQ0MEBwcjODgYXl5emDdvntogVuHq1asYOXIk4uLiUKhQIQiCgNDQUOzevRvnz5/Hnj17lIKj3PwMPkYRTBgYGMDY2BhRUVHw8fHBjRs3sHLlSjRs2BAjR47EpUuXxOcYGxuLCxcu4MaNG/jrr79QpUoVlXIjIiIwZswY3LhxQ7xmYWGB9+/f4/Lly7h8+TKOHDmCZcuWaZwKEBcXhz59+uDu3bti3TExMbh27RquX7+OefPm4euvvxbTm5ubw9bWFm/fvgUAFC5cWOl3T+ZFII8fP0a/fv0QGRkJIL033tzcHG/fvkVYWJgYyDEwonwhkHD48GFBLpcLcrlcOHv2bK7LefnypeDq6irI5XKhXbt2ws2bN8V7N27cEFq3bi3I5XKhTp06wuvXr5XyBgUFiW2oXbu20LNnT+HevXuCIAhCcnKycPnyZaFhw4aCXC4Xvv32W7X19+nTR5DL5cLy5cvV3l++fLkgl8uFPn36aHwOV69eFduRWVxcnFCjRg1BLpcLkydPFgICAsR7sbGxwj///CP88ssvwrlz57JVXkF4vT5GUf7evXvF51+hQgUhMDBQKd2KFSsEuVwu/PDDD4Ig/PdzmDZtmkqZp06dEhYtWiTcvHlTiIuLE6+HhoYKK1asECpXrizI5XLh9OnTKnn37t0ryOVywc3NLct2T5s2TZDL5UL16tWFSpUqCRs2bBCio6MFQRCEmJgYITQ0VBAE5dcwKChIpZzff/9dkMvlQtWqVYXHjx+L169evSq4uLgIcrlc2LFjR5ZtUad58+aCXC4XatSoIVy6dCnH+R8/fixUq1ZNkMvlwo8//ig8e/ZMSElJEQRBEEJCQoRZs2YJcrlcqFSpkvieyNz2zO+bESNGCM+ePRMEQRASExOFI0eOiO/zKVOmqNSd3Z9BVv/WFD8fV1dXoVq1asLOnTuF+Ph4QRAE4fnz50KXLl3EOubMmSPUqVNHOHr0qJCUlCSkpaUJ//zzj9CiRQtBLpcLPXv2VCk/JSVFfA926tRJ8Pb2Ft9rsbGxwv79+4X69esLcrlcmD9/vkp+Nzc38fVp3LixcOrUKSEpKUlsX/fu3cX3V1RUlEp+xet79epVja9P//79BblcLnTp0kXw9fUV0tLSBEFI/xn4+fkJGzZsENatW5fla0yUVz7PmY0Se/r0qfh1xYoVc13OmjVrEBUVhcKFC2PTpk2oVauWeM/V1RWbNm2Cubk5IiIisHbtWo3l2NjYwNPTE1WrVgUAGBgYoEGDBpgzZw4A4ObNm3j9+nWu25kbT58+RWxsLMzMzLBw4UKULFlSvGdmZoYqVapg6tSpaoeBNPmcXi9TU1O0a9cOgiAoDRcIgoB9+/YBQLZ6ylq0aIFp06ahVq1aSnOV7OzsMGbMGEyYMAEANA515kRcXBy+//57DBo0CObm5gCAQoUKwc7OLlv5x4wZg5o1ayIxMRETJ05EQkIC3r9/jylTpiAtLQ2tWrVCz549c9yucePGAQBiY2MxaNAgNG/eHFOnTsXmzZtx+/ZtJCUlZZl/wYIFSEhIwPDhwzF37lyULVsW+vr6AAAHBwf8/PPP6Nu3L1JSUrB69WqN5bi4uOCPP/4Qh1qNjIzQrl078Wdw4sQJpKSk5Pj5ZVdUVBTmzp2LHj16iEOGZcqUwe+//w4gvSfyr7/+wh9//IG2bdvC0NAQMpkMVapUEd/biq0OMjt06BCuX7+OMmXKYOvWrXBzcxPfa2ZmZujcuTP+/PNPyGQybN++He/evVPbvvj4eHh6eqJFixZiz0+ZMmWwevVqGBsbIy4uDmfPns3Vc/f19QUAzJw5E9WrVxd73o2MjODs7IxBgwZhyJAhuSqbSFsMjJDe7axgZWWVqzIEQRBX+PTs2RNFixZVSVOsWDHxD8mRI0c0ljVo0CC1cyuaNGki/oLSNF8nr1hYWAAAkpOTlV6v3PocX69u3boBAA4cOCAOJ169ehUhISEoXbo0atasqXUdzZo1A5C+bURqaqpWZRUuXBg9evTIdX59fX0sXrwYhQsXxrNnzzB//nzMmDEDoaGhKF68OObNm5ercj08PLB06VJxLlpISAgOHjyIBQsWoFevXqhduzYmTJiAx48fq+QNDg7G1atXYWBggEGDBmmsQzGE5uPjo/F1HDFihNqhRcW8q4SEBAQEBOT06WWbg4MDOnbsqHK9ZMmSKFWqFID0DwjqhpHr1KkjDoF9+N5WDOX26tVL/Hf7oSpVqqB8+fJITk7GtWvX1KZp3bq12vl51tbWqF69utq6s0vRrrCwsFzlJ8pLnGMkkeDgYDFgqF+/vsZ0DRs2xPr16xEREYGgoCCUKFFCJY2mcXUDAwNYW1sjNDRUHJv/VEqWLIkyZcrgxYsX6N69O3r27InGjRtDLpeLn9Zz4nN8vWrUqCG+Bj4+PmjQoIH4Rygn86revn2L7du34/Lly/D390d0dLTKH+/4+HhERkaqzGPJiapVq2q9lYSDgwPmzp2L7777Drt27QKQHjD9+uuvKFy4cK7LbdeuHVq2bIkrV67Ax8cH9+7dw+PHjxEbG4uEhAQcPXoUJ0+exM8//4zu3buL+W7fvg0gfWJx+/btNZaveD3j4uIQEREBGxsblTSa3jeZe9Sk+BCgSZUqVdROfgbSe0EDAgLEXtAPKRY9fPjeTk1NxZ07dwCkL8LIqqdVkU/TCsqvvvpKY17Fa5Tbf1dubm7YtWsXpk2bhtu3b6N58+aoWrWq2hWfRJ8aAyMo9xJFRETkag+gzN3RWeXPfC88PFztH/pChQppzG9gkP4jy8sufnX09fWxdOlSjB49GsHBwVi8eDEWL14MU1NT1KhRAy1btkSXLl2y/Yvtc329unbtit9++w179+5FtWrVcOrUKejr62c5yTczX19fDBs2TJw0DKQPb5iamkImkyE1NRXv378H8N/2C7mlTVCVWevWrdG6dWtxgcKgQYPEFVPaMDQ0RNOmTcXh17S0NDx+/Bj79+/H9u3bkZKSglmzZqFatWri5Pk3b96IaRWTfD9G0+uoGF78kOI9A+Ttv7PsvG9z+t6OjIwUhyKzG7Ro2hIhL/9dTZkyBQEBAbh27Ro8PT3h6ekJfX19uLi4oFmzZujRo0eB2YuNvjwMjAClZb2PHj3iP0gNXFxccOzYMZw7dw6XLl2Cr68vnj59iitXruDKlSv4888/sXbtWp0+F61Tp05YunQpTp8+DRcXFyQkJKBZs2bZmreTkpKCSZMmISoqChUrVsSECRNQq1YtpT/QgYGBaNmyJQCo3QoiJ3LTk6dOcHAwrly5In5/+/ZtpKamSla+gp6eHipVqoRKlSrBxcUFM2bMQGpqKvbu3YsffvgBQHpABKSvELt8+bKk9euCzD2P69atU1lSX1BYWlpiy5YtuHnzJs6ePYvbt2/j/v37ePDgAR48eIANGzZg/vz56NChQ343lb5AnGMEoG7duuJcg1OnTuWqjMxd9VktQ858T6pP9Nml+EOWmJioMU10dHSWZRgZGaFVq1aYM2cODh06BB8fH8yePRtWVlZ49eoVvv/++2y15XN4vdSxs7ND48aNkZCQgGXLlgHI/jDanTt3EBISAn19faxduxZNmzZV6bUoaHMuFMFcdHQ0nJ2dYWRkhFu3bqnd20hKnTt3FueN+fn5idcVe1q9f/8ecXFxedqGz5HifEQAePnyZT635uNcXV0xZcoU7NixAzdv3sSqVasgl8uRkJCAGTNmZLtXkEhKDIyQ/su2VatWAIDDhw8r/SL+GMWneicnJ3FIzsfHR2N6xSdvKysrtcNCeUkxJ+TVq1ca09y7dy9HZRYpUgQ9e/bE5MmTAQAPHz4Uh4Ky8jm8XpooJmEnJyejSJEi2dqoEPjvdbe2ttbYK5nVa6EI3rXtScqJFStW4M6dOzA1NcWqVavEn/Pq1atx8+bNPKtXX19f3Bsp8zwpxQT31NRUXLhwIc/q1yQ/fgY5YWhoKM5Lyu2KMW0p5k3l9DUyNjaGu7u7uDltYmIibt26JXn7iD6GgVGG8ePHw8zMDAkJCRg7duxHN5+LjIzE2LFjxR4WmUyGtm3bAkg/zFXdJ//Q0FD8/fffAJAvXcSKIa43b97g7t27KvffvXsnTrD90MeWUGfe4C87mwh+Dq+XJm5ubhg8eDAGDRqEGTNmZHsDTcVKnLdv36r9JPz69essl+krepcyz0/KS1evXsWff/4JAJg+fTrKli2L/v37o1mzZkhNTcWUKVNyPPk2KSkJV69e/Wg6b29vsexKlSqJ152dncVjV5YuXfrRHk6pJ09/6p9BbihWIp4/fx7nz5/PMm1eTC5XvEaafjYpKSnikKg6mVeYfq5n5dHnje+6DKVLl8avv/4KQ0NDPH36FJ06dcKff/6ptFxXcYjssmXL0KJFC5w8eVKpjBEjRsDS0hIREREYOHCguIIGAG7duoWBAwciKioKVlZWGDZs2Cd7bgo1a9aEo6MjAGDatGn4559/IAgC0tLScO3aNfTt21fjp7wjR46gZ8+e2LlzJ4KCgsTrqampuHjxIhYvXgwgfeVWdlcrFfTXSxNDQ0NMnToV06ZNg4eHR7bz1apVC2ZmZhAEAePHjxd7JhWvYd++fbPMr5gLFxMTg6NHj+b+CWTD+/fvMXXqVHG/oszL/hcuXIiiRYvi5cuXmDlzZo7KTU5ORv/+/dGlSxd4enri8ePH4ryYtLQ0hISEYOXKlZg4cSKA9D+y33zzjVIZM2fOhJmZGfz9/dG9e3ecPn1aaXg4NDQUBw4cQP/+/fHbb7/l9iVQ61P+DHLLw8MDDRo0gCAIGD16NFatWqX0QS8uLg5Xr17F7Nmz0aJFC8nrV7xGhw4dUjvx/fXr12jVqhVWrVqFhw8fKk3gfvz4sdgraWZmJskkf6Kc4uTrTFq0aIHNmzdj+vTpCAgIEFdeGRoaolChQoiKihI/6chkMnTo0EFpFVaxYsXwxx9/YNSoUXj69Cl69eolHhOgmA9haWmJP/74I18meOvp6WH27NkYOXIk/Pz88PXXX8PU1BRpaWlITEyEs7MzfvrpJ/GPUmaCIMDX11fcmM3IyAhmZmZKr4mdnR3mz5+f7fYU9NdLahYWFpg6dSpmzZqFGzduoE2bNjAzM0NqaioSExNRpEgRLFy4ECNHjlSbv1SpUqhfvz58fHwwYcIE/Pjjj+JwZL9+/TBgwADJ2prVfkXW1tb43//+h0GDBuHEiRPYtWuX0pL6rOjp6UFfXx8PHz7Ew4cPAaQPm1lYWCA2NhbJycliWhsbGyxfvlzlZy+Xy7F+/XqMGzcOL168wOjRo8UyEhISlFZZST38+il/Brmlr6+PFStWYPLkyTh79iyWLVuGZcuWwdzcHHp6eoiOjhY/AGVegSeVnj174vbt2zhx4gS8vb1hbW0NAwMD2NvbY8eOHQCAoKAgsV3qfv6GhoZYuHBhrveVI9IGA6MP1KpVC8eOHcPx48dx9uxZ3Lt3D+/evUNsbCwKFy6MMmXKoHbt2ujUqRPKlCmjkr9OnTo4evQoPD09cf78eYSEhEAmk6Fs2bLioajqNjP8VBo3boxt27Zh9erVuH37NuLj4+Hg4IBWrVph+PDhePDggdp8zZs3xy+//IJr167h4cOHCAsLQ2RkJAoVKoTSpUvDzc0Nffr0gaWlZY7aU9BfL6n16tULDg4OWL9+Pe7fv4/U1FTY29ujadOmGDp0qFJgoM7y5cvxxx9/4Ny5c3j16pW4B83HhpRyYtu2bfD29oaenp7G/YoaNGiAwYMHY/369ViwYAFq1aqVrcN6TU1NcfnyZZw/fx43b97Ew4cPERISgujoaBgYGKBYsWIoV64cmjZtiq5du2pcUl+rVi0cP34cu3btgre3N54+fYro6GgYGxujbNmyqFy5Mpo0aSJu1iilT/Ez0Ja5uTnWrFmD8+fP48CBA7hz5w7evn0LQRBgb2+PcuXKoW7duuJwtpQ6deoEIH2I/MmTJwgLC1MaOrO3t8fq1atx7do13LlzB69fv8a7d+9gYGCAUqVKoW7duujXrx+cnZ0lbxtRdsiEgjqLkIiIiOgT4xwjIiIiogwMjIiIiIgyMDAiIiIiysDAiIiIiCgDAyMiIiKiDFyuT0REpCMUe855e3vj1q1bePHiBWJiYmBhYYFKlSqhc+fO6Nixo3h0S2YfOwD8Y4c3P3z4EH/++Sdu3LiBqKgo2NnZwc3NDaNGjcryrMvk5GRs3rwZXl5eCAwMhKGhIVxcXNC3b1/xuC6p68wKl+sTERHpCB8fH6WNRkuUKAFLS0uEhISIR8A0a9YMK1asUDqHEPgvMKpSpYrKPSD9zMrVq1errffkyZOYOHEikpOTYWNjg2LFisHPzw9xcXEoWrQoduzYoXbD1cTERAwcOBC3bt2Cvr4+ypUrh/j4eAQGBgIAhg4dKu6GLlWdH/PZBkbGJgXjQFGigiY1i3OoiL5UKUkheV5H8tsXkpRjaKu6eXB2XblyBTNnzkT//v3Rvn172NjYiPcOHDiAmTNnIikpCUOGDMGUKVOU8ioCozNnzsDJySnbdYaGhqJ169aIj4/HqFGjMHr0aBgYGCA6OhoTJkzAxYsXUaVKFezZs0elp2revHnYunUrnJycsG7dOnHj5DNnzmD8+PFISkrC6tWrVQ7r1qbOj+EcIyIiIh1RrVo1HD9+HP369VMKigCgc+fOGD16NABgz549WR7mmxPr169HfHw8ateujXHjxolHzVhYWGDx4sWwsLDA/fv3cfbsWaV8b9++xc6dOwEA8+fPVzpNwt3dHUOGDAEArFy5UrI6s4OBERERkRTSUqV5aMHc3ByGhoYa7zdp0gQAEBERgfDwcK3qUjhx4gQAqD0zsXDhwmjTpg0A4NixY0r3vL29kZycDGdnZ9SrV08lb8+ePQEADx48EIfWtK0zOzj5moiISApCwR/GznzIsomJido0q1atwps3b8SzHOvVq4d27dqpnXf06tUrhIaGAgBq166ttjxXV1fs3r0bd+/eVbp+584dAOlnH6pjb28PJycnBAcH486dOyhZsqTWdWYHAyMiIqIvxJEjRwAALi4uGg9p3rt3r9L3+/fvx/Lly7FixQpUrlxZ6Z6/vz8AwNDQEMWKFVNbnmICdFBQEJKTk8UeLUVeRcCjTsmSJREcHAw/Pz9J6swOBkZERERSkGjOjru7e5b3z5w5k6ty79+/L87pGTZsmNp6O3XqBBcXFxQrVgyxsbHw8fHB0qVLERQUhEGDBuHAgQMoXry4mEex0q1w4cIaJzlbWVkBANLS0hATE4MiRYoAACIjI8W8mijuRUVFSVJndnCOERERkQQEIU2SR154+/Ytxo4di5SUFLRs2RLt27dXSbNq1Sq0bt0apUqVgrGxMaytrdG+fXvs2rULDg4OiIiIUJkInZiYCABZ9shkHoJTpM9p3sxDgNrUmR3sMSIiIpKCRD1Gue0R0iQ6OhpDhw7Fy5cvUblyZSxatChH+a2trTFs2DDMmjULp0+fxrx588SeGmNjYwDpmzRqkpSUJH6tSJ/TvJnnQ2lTZ3awx4iIiEhHxcbGYsiQIXj48CHKly+PDRs2aJxblJUaNWoASB/GUgxlAf8NdUVGRkLTtoiK9Hp6ekp1W1paink1UdxTpNW2zuxgYERERCQFIU2ah0Ti4+MxfPhw3LlzB87OzvD09MzRXJvMMg9bpab+t6WAs7MzgPTem1evXqnNGxQUBABwcnJSKkeRNyAgQGO9imX6irTa1pkdDIyIiIikUAD2MVJITEzEyJEjcePGDTg6OmLTpk0oWrRorst7+vQpgPRhKcXEZgBwcHCAnZ0dAODmzZtq8yquV69eXem64vvbt2+rzRcaGorg4GCVvNrUmR0MjIiIiHRIcnIyxo4dCx8fH9jb22Pz5s1KK8lyKiUlBZ6engCAevXqibtMK7Ru3RoAsGvXLpW8kZGROH78OACImy4quLu7w9DQEP7+/rh69apKXsUKukqVKqFUqVKS1JkdDIyIiIikUACG0lJTUzFp0iScP38eRYsWxebNm7N1kOpvv/2G/fv3IyYmRun6q1ev8N133+HOnTswMDAQjxTJbPDgwTAxMcGNGzewbNkycagtOjoakyZNQnR0NCpVqqRy3pmtrS169OgBAPjhhx/w4sV/Z815e3tj/fr1ACBpndnBQ2SJdAwPkSVS9SkOkU16cV2ScozK1Ml13sOHD2PSpEkAAEdHR9jb22tMO3PmTFSqVAkAMGrUKJw5cwb6+vooUaIEChcujOjoaPj5+UEQBBgbG2PevHnw8PBQW9bx48cxadIkpKSkqJx0b2tri+3bt6v0+gDpy/AHDBgAX19f6Ovro3z58oiLixPnFg0aNAjTpk2TtM6P4XJ9IiIiHZF5mXpISAhCQjQHhNHR0eLXvXr1gq2tLe7fv483b94gJCQEhoaGKF++POrXr48+ffpkuUN1mzZtUKJECaxduxY3b97EkydPYGdnh65du2LUqFEqB9oqmJiYYMuWLdi0aRMOHToEf39/GBoaok6dOujTp484ZCZlnR/DHiMiHcMeIyJVn6LHKPG56jyZ3DAuq3qgKn067DEiIiKSAj+U6AROviYiIiLKwB4jIiIiKeTROWf0aTEwIiIikoJEmzNS/mJgREREJAX2GOkEzjEiIiIiysAeIyIiIilwVZpOYGBEREQkBQ6l6QQOpRERERFlYI8RERGRFDiUphMYGBEREUlAELhcXxdwKI2IiIgoA3uMiIiIpMDJ1zqBgREREZEUOMdIJ3AojYiIiCgDe4yIiIikwKE0ncDAiIiISAo8RFYnMDAiIiKSAnuMdALnGBERERFlYI8RERGRFLgqTScwMCIiIpICh9J0AofSiIiIiDKwx4iIiEgKHErTCQyMiIiIpMDASCdwKI2IiIgoA3uMiIiIJCAI3OBRFzAwIiIikgKH0nQCh9KIiIiIMrDHiIiISArcx0gnMDAiIiKSAofSdILkgVFYWBhev36NhIQE1K5dW+riiYiICib2GOkEyQKjPXv2YP369QgICAAAyGQyPHz4ULz/v//9D/fv38evv/4Ke3t7qaolIiIikowkk69nzJiBmTNnwt/fH/r6+jAwMIAgCEppKlSogOvXr+P06dNSVElERFSwpKVJ86B8pXVgdPjwYezbtw+2trZYvXo17t69i6pVq6qka968OWQyGby9vbWtkoiIqOAR0qR5UL7Seijt77//hkwmw9KlS+Hq6qoxnYWFBRwdHfHkyRNtqyQiIiLKE1r3GD1+/Bh2dnZZBkUK1tbWeP/+vbZVEhERFTwcStMJWvcYJSYmwsnJKVtpk5KSYGRkpG2VREREBQ+DGp2gdY9R0aJFERQU9NF0CQkJePHiBRwdHbWtkoiIiChPaB0Y1alTB7Gxsdi/f3+W6bZt24akpCQ0aNBA2yqJiIgKHk6+1glaB0aDBg2Cvr4+5s6diwMHDiAlJUXpflJSEjw9PbF06VKYmJigb9++2lZJRERU8HCOkU6QCR9uOJQLu3btwqxZsyAIAkxMTACkD52VK1cOQUFBSExMhJ6eHhYuXAgPDw+tGw0AxiYlJCmHSNek8hcrkYqUpJA8ryPe6zdJyjH1mCxJOZQ7kmzw2L17d2zcuBFVqlRBfHw84uPjIQgCnj59ioSEBFSsWBEbNmyQLCgiIiIqcDiUphMkOxKkXr162L17N0JDQ/H48WNERUXBzMwMcrkcJUqwd4eIiHQce2t1guSHyNrb2/MsNCIi+vKwt0cnaD2U9ssvv+Dx48dStIWIiIgoX2kdGHl6eqJLly7o2LEj1q9fj9DQUCnaRURE9HnhqjSdoHVg5OHhAVNTUzx9+hSLFy+Gm5sb+vfvj3379iEmJkaKNhIRERV8DIx0giTL9RMSEnD69Gl4eXnhypUrSElJgUwmg7GxMdzc3ODh4YEmTZpAX19fijYD4HJ9Ik24XJ9I1SdZrr9rjiTlmHb/SZJyKHckCYwyCw8Px5EjR3Do0CHcu3cvvRKZDFZWVmjXrh06duyI6tWra10PAyMi9RgYEan6JIHR37MlKce0x8+SlEO5I3lglFlgYCAOHjyIQ4cOITAwEDKZDDKZDA8fPtS6bAZGROoxMCJS9UkCox3SBDSmvaQJsCh3JNngUZOSJUti7Nix2LBhA5o1awZBEJCHcRgRERGRViTfx0ghIiICR48ehZeXF+7evStet7a2zqsqiYiI8g97a3WCpIFRUlKSOAn70qVLSE1NFc9Pc3d3h4eHBxo1aiRllURERAUDN3jUCZIERj4+PvDy8sKpU6cQGxsLQRCgp6eHevXqwcPDA61atUKhQoWkqIqIiIgoz2gdGDVp0gRhYWHi3KEKFSrAw8MDHTp04NEgRET05eBQmk7QOjB68+YNihUrhvbt26NTp06Qy+VStIuIiOjzwsVFOkHrwGjTpk2oW7cuZDKZFO0hIiL6PLHHSCdoHRjVq1dPinYQERGRlgRBgK+vL7y9vXHr1i28ePECMTExsLCwQKVKldC5c2d07NhRY2dGbGws/vzzT5w4cQIvX76EmZkZvvrqKwwaNAh169bNsu6rV6/C09MTd+/eRVxcHBwcHNCmTRsMGzYMZmZmGvPlR51ZydMNHvMSN3gkUo8bPBKp+iQbPG6YLEk5poN/y3VeHx8fDBgwQPy+RIkSsLS0REhICCIiIgAAzZo1w4oVK2BkZKSUNzw8HN9++y38/PxgZGSEcuXKITw8HK9fv4ZMJsPMmTPRu3dvtfVu3boV8+fPhyAIKFasGKytrfHs2TMkJSWhbNmy2L59O6ysrFTy5UedH5OjwKhfv34AAEdHRyxcuFDpWrYrlMmwefPmHOVRh4ERkXoMjIhUfZLAaP1EScoxHbIk13mvXLmCmTNnon///mjfvj1sbGzEewcOHMDMmTORlJSEIUOGYMqUKUp5R44cCW9vb1SuXBmrV6+Gvb09BEHArl278NNPP0FfXx979+5FxYoVlfLdv38f33zzDQRBwOzZs9G9e3fIZDKEhoZi5MiRePDgAVq1aoUVK1aotDc/6vyYHAVGLi4uAIAyZcrg6NGjSteyXaFMhkePHuUojzoMjIjUY2BEpOpLCYxiYmJgbGwMQ0NDtffXrFmDpUuXwsrKCj4+PtDTSz8A4+HDh+jSpQv09PRw/PhxlCpVSinf1KlTcfDgQbXBxqhRo3DmzBl07twZv/zyi9I9f39/tG3bFmlpaTh48KBSzJAfdWZHjuYYbdmyBQBgYmKico2IiOhLJqTl/8wUc3PzLO83adIES5cuRUREBMLDw2FrawsAOHHiBID0ecMfBigA0KNHDxw8eBDnz59HXFycOH8nNjYWFy9eBAB0795dJZ+zszPq1auHK1eu4Pjx40pBSn7UmR05Cozq1KmTrWtERERfnM+gtzYhIUH8OnMnx507dwAArq6uavNVq1YNRkZGSExMxKNHj1CrVi0AwKNHj5CUlAQjIyNUq1ZNbd5atWrhypUrSseD5Ved2aH1IbIvX77Eu3fvspX23bt3ePnypbZVEhERUS4cOXIEQPo0mMy9S/7+/gDSD39Xx9DQEMWLFwcA+Pn5idcVXzs4OGgcvlOUmTlfftWZHVov12/evDlcXV3x119/fTTt+PHjcevWLTx8+FDbaomIiAoWic5Kc3d3z/L+mTNnclXu/fv3sXPnTgDAsGHDlO5FRkYCAAoXLqwxv+JeVFRUrvIp0uZnndkhyVlpOVnx/5nuDkBERJS1AjDHSJO3b99i7NixSElJQcuWLdG+fXul+4mJiQCgsQcGgLi8P/NwXE7yKdLmZ53ZIUlglF2xsbFZPhH6dBo2rIORIwagfn1XFC1qjcjIaPzzz0Ns2rwLu3YdVJvnxx8nYOaPH191UalSYzx/4a/2npGREYYM/hZff9MRlSrKYWpqgtehYfD2voRly9bh8eOn2jwtIklYWJhjxPB+8OjYGuXKlYalpTnCwsLx7JkfLlz0wbLl6xEZ+d8nWGvrIujYoSWaN2+EGjWqolRJJxgY6CMsLBy3bt/Flq27cfDgcY31aZufCgiJ5hjltkdIk+joaAwdOhQvX75E5cqVsWjRIpU0xsbGiI+PR3JyssZykpKSACjPTTI2NgaAbOVTpM3POrPjkwRGSUlJuH79Ov799184OTl9iiopC/Pmfo8pU0aL379/HwErK0u4uzeBu3sTdOvaHt/2HonU1FS1+ZOSkhAeHqGx/JTUFLXX7e2L4uCBzahRo6pYTkxMHJxLlcCggb3wba8uGDZ8Cv7++0CunxuRtpo1bYC/tv6BYsXsAKR/4oyLi4eTU3E4ORVHs2YNcNDrBO7efSDmCQnyVfrQl/7LPkXM08mjDY4dO4PuPYchPj5BpU5t8xNpEhsbiyFDhuDhw4coX748NmzYoHblmqWlJeLj47McelLcs7S0FK9lZ8hK09BXftSZHTmefL1y5UpUrFhRfADA7du3la59+Pjqq68wdOhQpKWloXnz5jluJElnyJDeYlD0966DKFO2NooVrwob24oYPGQCYmJi0blzWyxc8IPGMnyu3kIp51oaHwEBwWrz7dy5FjVqVEVcXDxGjJwC26KVUNyhKko518LWv3bDxMQE69ctFgMnok+tQX1XeB3cgmLF7LBv/xHUrdcWhSzKoKh9ZVgULot69dthwcJlSr1FQHqX/vXrtzF6zHSUr1AfFoXLwcpajrLl62LDxu0AgLZt3bF61f/U1qttfiog0tKkeUgkPj4ew4cPx507d+Ds7AxPT08UKVJEbVpnZ2cAQEBAgNr7ycnJ4uIpRdrMX798+VJjD05gYKBKvvyqMztytSpNEATxIZPJlL7X9DAzM8M333yDcePG5aZKkoC+vr44FHb79j307z8WISGvAaT33vz11x58//08AMCoUQNQurT6lQK50a6tOxrUrw0AmDlzETw9d4pjv69fv8GQIRNx9eotGBkZYeGCGZLVS5RdpqYm8Ny4DGZmplixcgO69xiGW7fviffj4xNw89Zd/PTz/+DvH6SUt0XLb9CgUUes/XML/PwCxesBAcEYPmIK1v65FQDQp3c3ODk5qNStbX4qIARBmocEEhMTMXLkSNy4cQOOjo7YtGkTihYtqjF99erVAQC3bt1Se//evXtITk6GsbGx0i7UFStWhKGhIZKSknDv3j21eRVlKurIzzqzI8eBUf/+/XHmzBmcOXMGp0+fhiAIqFq1qnjtw4e3tzeuXLmCW7duYc6cOUrjhPRp1axZVRwe+H3ZOrUT4Tds3I737yNgaGiIXr26SFZ327bpqyxiYmKxZq36TUGXLF0DAHBza4QSJfjLnz6tPr2/Rtmyznj1KhTfT5+fo7znzl/J8r6n5w7x61q1VPdd0TY/UWbJyckYO3YsfHx8YG9vj82bN4vL3jVp3bo1AODatWtqe3D+/vtvAOkbRBYqVEi8bm5ujkaNGgEAdu3apZLP398fV69eBQC0adMm3+vMjhwHRhYWFnB0dISjoyOcnJzQpUsXtGzZUrz24cPBwQHW1tY5bhhJr2TJ/+Z3PXr0RG2atLQ0PH2avu9DixZNJKzbEQDw/Lk/UlLUz0H69/Ez8Wsp6ybKjr59vgYA7Nl7OFcrWbKSkKk8fX39T56fPpECMJSWmpqKSZMm4fz58yhatCg2b96MEiU+foRW5cqV4ebmhtTUVEyYMAFv3rwBkD5C9Pfff+PgwYPQ09PDyJEjVfKOGjUKMpkMBw8exN9//y1+6H7z5g0mTpyItLQ0tGjRQmUH6vyoMzu0nnytOEyWPi9Z/XJV3KtcqYLa+5UqynH71mmULl0SaWlpePnyNS5euoa1a7coTUjNab16me5VqZzzNzNRbhkZGYk9Mbd9/0GJEg6YMX0c2rRuDnt7W7x/H4kbN+/gzz+34uixnK8Yatqkvvj1/fuPP3l++kQKwHL9Y8eOiUdtGBkZYcYMzVMTZs6ciUqVKonfL1iwAL169cKDBw/g7u6OcuXK4f3793j16hVkMhlmzJiBypUrq5RTrVo1fP/991i0aBF++uknrF69GkWKFBFPui9dujTmzp2rtg35UefHfNLl+pS/Mk+Krly5Anx9/1FJY2hoiHLlnAEAVlaFYWZmiri4eKU0RYvawNraChERUbC0NIdcXhZyeVkMHNATv/xvJWbN+lVj3WXLOsPY2FjtJ/LKlf8LxIoXt8/VcyTKDWfnEuKy3jKlS2LZ0rmwtLRAYmIiYmPjYG9fFB3at0SH9i2xfsM2jBg5NdtlFy5siWlTxwAALl68iidPnueobdrmpy+LYpk6AISEhCAkRPPhudHR0UrfW1tbY+/evVi3bh2OHz+OZ8+ewczMDE2aNMHgwYNRr149jWUNGDAAFSpUwMaNG3Hv3j28e/cODg4OaNOmDYYNG6Y0FJbfdX6MTJBox8WEhAScPXsWjx49QkREhMaZ4jKZDAsWLNC6PmOTj3cNkjJ9fX28eH4dxYrZ4dGjJ6jl2kplSf74ccPwyy8zxe9LOdfC69fp3Zs9e3aGQ3F7HDp0En7+QUhJSYGhoSGaNq2PObOniZ+4p02bi9+X/alUbru27ti/fxMA4Kef/4dfflE+KVlPTw9XfY7iq6/SPxmcOnUeHTr2kfT5fylSP4PzmgqaunVq4vKlQwDShyIiIqIwcvQ0eHmdQEpKCkqUcMD/fvkJ33zdEQAwecpslfe4OjKZDPv3eaJD+5aIj49Hg0Yd8c8/j7LdLm3z039SkjQHCFKJ+3WQJOWYTdkoSTmUO5IERmfOnMGMGTOUtuxWFCuTyZSuyWQyPHqk/T9sBka5M3xYPyxfnj6x9OTJc5j50y948OBfWFtbofe3XTF7dvonYcWuoSVK1sCbN28/Wq6xsTHOnN6D2rWrIzo6BmXK1kFUlPKnkQvnD6Ju3ZpITk7GnLlLsGXLLrx9G46KFctjzuypaNeuhXgw4IkTZ+HRqZ/Ez/7LwMAo5+rXc8XFC/9tbNr160Hw8jqhlEYmk+HG9ROo/lVlvH0bDscS1TXu9aXw+9K5GDM6/Y/lkKETsWnz3zlql7b56T+fJDD6ZaAk5ZhN85SkHModrQ+RffjwIcaNG4ekpCQMHz5cPLht/vz5mDJlClq2bAl9fX0YGxtj4sSJkvQWUe6t/XMLlixJX/3VqlUzXLt6DDHRLxAYcBsLF/6IgIBgLM64DwDv32fvnJnExET89PMvANJ3DXZza6iSpkfPYbh79wEMDQ0xd840BPjfQmyMH27eOIl27Vpg9epNuHcvPWh+H5Hz822Icis6Jkb8+snTFypBEZD+wU6xctLW1hq1ama9Oux/i2aKQc3EST/nOKjRNj8R5Y7Wc4w2bNiA1NRULFmyBK1atcL169cRGBiIbt26iWmeP3+OkSNHYseOHdi7d6+2VZKWps+YD69DJzBwYC+41voKFpbmeP3qDQ4fOYUVK9Zj0qT0FQD+AUFZbrn+oatX/9uLokzpUir3X70KRaPGHujX7xt08miDsmWdAQCPHj3Fxo3bceToaTx54gMAePr0hRbPkChnFPt5AcC//z7TmO7Rw/9Wc5Ys5YTrN3zVplu08AdMnDgCADBl6hwsX7E+R+3RNj/lD4G9tTpB68Do1q1bsLS0RKtWrTSmKVu2LJYvX47OnTtj1apV+PHHH7WtlrTk43MTPj431d5TfBLOHOhIJSkpCevXb8P69dtU7hUtaoNSGVsK5EXdRJq8fx+B4OBXcHLKeq+XD6cGqPPLwh/FDxfTvp+Lpb+vzVFbtM1P+agArEoj7Wk9lPbu3Ts4OjqK3xsYpMdamU/CBQAXFxeULl0a586d07ZKykN2drZo3jx946xtf+Wsd69u3Zri137+gVmkVK9Xz/QNJYODX+Hs2cs5zk+kjVOnzwMAXCqU15imYiW5+LW/n+p7/H+LZioFNZmHpbND2/yUz4Q0aR6Ur7QOjMzNzZUmICoObFOcb5KZkZGRuIETFTx6enpYuWIhjI2Ncf26L06eOpftvEZGRpg9K33idkxMbI4DmzJlSmH69PTjYn799Y+PTmolktrmjDk85cuXhodHa5X7MpkMEyekD28FB7/C7Q+2u/jfoplKw1+5CYq0yU9E0tA6MCpWrBjCwsLE78uXT/+0dfmy8h/GsLAw+Pn55XpfAZJG6dIlMXv2VFSvXkXct0Umk6F+fVccPbINnTq1wfv3ERg6dKJSvsaN6+HY0e349tuucHQsJl43MDCAm1tDeJ/ZK/YYLVjwu8ohmwDQu3c3DBrUC46OxcQhCUtLCwwY0APnzu6HtbUVTpw4izVrN+fV0yfS6NLl69iz9zAA4M81v6FLl3bihqQlSjhg21+r8FW19M3wZv78i9JQWuY5QZMmz8rx8Je2+amASBOkeVC+0nq5/rx587Bt2zacO3cO9vb2ePLkCTp16gRjY2NMmzYNrq6uCAsLw5IlS/DgwQO0a9cOixcv1rrhXK6fO9WqVcKN6/+tuAkPj4C5uZm4PD8gMBjduw/FnTv3lfI1aVIPp07uFr+Pi4tHbGwcChe2EPOmpqbi199W4eef1Z8A/tuvP2Ps2CEA0ucapee3hJ5eeny+d+9hDBw0XvLjGL40XK6fe2ZmpjjstRVNMnaaTkhIQFxcPKyt/zuRfM7cxZgzd4n4fYkSDvB7fgNA+r+BsLB3WdaxZOkaLFn6X+CjbX7Knk+xXD92Vi9Jyik0a8fHE1Ge0XrydfPmzbFjxw6cO3cOPXr0gFwux4ABA+Dp6Yk5c+aI6QRBgI2NDSZOnJhFaZTXAgKCMW/+UjRpUh9lyzjD1rYIoqJi8O+TZzh44Dj+XLcV8fEJKvnu33+MadPmom7dmqhSxQU2NtawsrJEXFw8Hj16isuXr2P9hu148EDzcQW79xyCmZkp6tatBQeHYjAzM0FwyCtc9bmFLVt2iXM8iPJLXFw83Ft+g4EDeqJP726oXNkFFhaFEBz8CpcuX8Mff3jC56ryogVFYA+kb6KqOKhZE3Nz5V5zbfMTkbQk2/n6Q4cOHcLBgwcRHBwMU1NTuLq6YsiQIbC3l+aoB/YYEanHHiMiVZ+kx+innpKUU2jOTknKodzJs7PSOnbsiI4dO+ZV8URERAULV5TpBK0nXxMRERHpijzrMSIiIvqicEWZTtA6MJo+fXq20+rr68Pc3ByOjo5wdXVFxYoVta2eiIioQOCRILpB68Bo//79AP7bKl/dXO4P7ym+r169OhYsWIDSpUtr2wwiIiIirWkdGC1cuBDBwcFYu3YtTExM0KJFC7i4uKBQoUKIjY3Fv//+i9OnTyMhIQHDhg2DtbU1nj9/jpMnT8LX1xf9+/fHgQMHYG1tLcXzISIiyh8cStMJWi/Xf/36Nbp06QK5XI7ff/8dRYoUUUkTERGBcePG4cmTJ9i7dy8cHBwQGxuLUaNG4fr16xg8eDAmT56co3q5XJ9IPS7XJ1L1KZbrx0zpIkk55r/ul6Qcyh2tV6UtW7YMsbGxWLp0qdqgCACsrKywZMkSxMTEYPny5QCAQoUKYcGCBQDAg2WJiOjzx0NkdYLWgdGlS5dQvnz5jw6F2djYoHz58kpnqDk6OsLZ2RkhIXkfyRMRERF9jNaBUWRkJOLj47OVNiEhAZGRkUrXLC0t1U7YJiIi+qzwEFmdoHVgVLx4cfj5+eH+/ftZpvvnn3/w4sULFC9eXOl6WFgYrKystG0GERFRvhLSBEkelL+0Dow6duwIQRAwYsQIjXOFzp8/j1GjRkEmkykdExIcHIyXL1+ibNmy2jaDiIiISGtaL9cfNmwYLl26hDt37mDkyJGwsbGBXC4Xl+s/efIE7969gyAIqFmzJoYNGybm3bt3L0xNTeHm5qZtM4iIiPIXe3t0gtbL9YH0uUPLli3Dzp071c43MjU1Rc+ePTFu3DiYmJhoWx0ALtcn0oTL9YlUfYrl+tFj2klSjsXKo5KUQ7kjSWCkEBsbi5s3b8Lf3x9xcXEwMzODs7MzXF1dUahQIamqAcDAiEgTBkZEqhgYUXZJeohsoUKF0LRpUzRt2lTKYomIiAo+DqXpBEkDIyIioi8WAyOdIFlg9Pz5c2zevBnXr19HaGgoEhMT8fDhQ/H+nj178Pr1awwcOFDyYTUiIiIiKUgSGO3btw+zZs1CcnKyuFmjTCZTShMVFYU//vgDZcqUQbt20ozDEhERFRTcrFg3aL2P0b179zBz5kykpqaif//++Ouvv1C5cmWVdG3atIEgCDhz5oy2VRIRERU83PlaJ2jdY7R+/XqkpaVh1qxZ6NGjBwDA2NhYJZ2DgwNsbW1x7949baskIiIqeBjU6ASte4xu374NS0tLMSjKir29Pd68eaNtlURERER5Quseo4iICMjl8myl/XDeERERka7gOWe6QevAyMrKCqGhodlKGxQUBBsbG22rJCIiKngYGOkErYfSqlativDwcNy6dSvLdKdPn0ZkZCRq1aqlbZVEREREeULrwKhHjx4QBAE//vgj/Pz81Ka5f/8+fv75Z8hkMvTs2VPbKomIiAqeNIkelK+0Hkpr1qwZunTpgv3796Nz585wdXVFUFAQAGDu3Ll48uQJbt26hbS0NPTp04c9RkREpJM4x0g3SHKIrCAI+OOPP7BhwwbEx8er3Dc2NsbQoUMxZswYbav6r0weIkukFg+RJVL1KQ6RjejdXJJyrLZ5S1IO5Y4kgZFCREQEzp8/j3///RfR0dEwMzND+fLl4ebmJvmkawZGROoxMCJS9UkCo15ukpRjteOsJOVQ7kh6iKyVlRU6deokZZFERESfB34m0QlaT74mIiIi0hU57jFyd3fXqkKZTIbTp09rVQYREVFBw8nXuiHHgVFIiHbjtNz9moiIdBKH0nRCjgOjNWvW5LiSEydOwMvLC6mpqTnOS0RE9Dlgj5FuyHFg1KxZs2ynvXz5Mn7//Xfcv38fgiDA3t4eo0aNymmVRERERJ+EpKvSFG7fvo2lS5fi5s2bEAQBRYoUwbBhw9C7d28YGRnlRZVERET5i0NpOkHSwOjx48dYunQpLly4AEEQYG5ujgEDBmDgwIEoVKiQlFUREREVKAIDI50gSWDk7++PZcuW4cSJE0hLS4OJiQm+/fZbDBs2DFZWVlJUQURERJTntAqMXr9+jRUrVuDgwYNISUmBgYEBunfvjlGjRsHOzk6qNhIRERV87DHSCbkKjMLDw7F69Wr8/fffSEpKgp6eHjp16oQxY8agRAke1UFERF8eDqXphhwHRkuXLsXWrVsRHx8PQRDQqlUrjBs3DmXLls2L9hERERF9Mjk+RNbFxQUAYGBggI4dO6JKlSo5rrR37945zvMhHiJLpB4PkSVS9SkOkX3buqkk5dieOC9JOZQ7uQqMZDIZBEHI9S7Wjx49ylW+zBgYEanHwIhI1acIjMJaShMYFT3FwCg/5XgorXbt2nnRDiIiIqJ8l+PAaOvWrXnRDiIios8aJ1/rhjzZ+ZqIiOhLw8BINzAwIiIikoKQu3m3UgsLC8Ply5dx//59/PPPP3j06BESExNRp06dLEd9mjdvjpCQrOdi3bt3D8bGxmrvBQUFYdWqVbh8+TLCw8NhY2ODhg0bYuTIkVlu5SMIAvbs2YPdu3fj2bNnAIBy5crhm2++wddff53lfObc1pkVBkZEREQ65MiRI1i4cGGu88vlcpibm6u9pylI8fX1xaBBgxAXF4fChQtDLpcjKCgIe/fuxfHjx7Fp0yZUq1ZNJV9aWhomTJiA48ePA0gPiADg7t27uHv3Lnx8fLB48WK19ea2zo9hYERERCSBgjKUZm5ujgYNGqBq1aqoWrUqHj58iFWrVmU7/48//oi6detmO31cXBzGjh2LuLg4dOvWDT///DOMjY2RmJiIWbNmYd++fRg7dixOnDgBExMTpbxbtmzB8ePHYWVlhTVr1qBGjRoA0oOeESNG4MiRI6hRowb69u0rWZ0fo5ej1ERERKSWkCaT5KGtr7/+Gp6enpg4cSJatmwJGxsbCZ6dZrt27UJYWBhKlSqF2bNni0NtxsbGmD17NkqWLInXr19j9+7dSvmSk5OxZs0aAMDUqVPFoAgAatSogSlTpgAAVq9ejZSUFEnqzA4GRkRERJRrimGwLl26wNDQUOmekZERunbtCgA4duyY0r3r16/j/fv3MDMzQ8eOHVXK9fDwgJmZGd69e4cbN25IUmd2cCiNiIhIAgVlKE1bO3fuxMaNG5GQkABbW1u4urqiY8eOaucdpaam4v79+wA073Po6uoKAPjnn3+QmpoKfX19AMCdO3cAANWqVYORkZFKPiMjI1StWhXXrl3DnTt3UL9+fa3rzA72GBEREUlAEGSSPPLb0aNHce7cOVy9ehWHDx/GrFmz0KJFC1y+fFklbUhICJKTkwFA4yqwkiVLAgCSkpLw8uVL8bq/v7/S/azy+vn5SVJndrDHiIiIqABxd3fP8v6ZM2fypN46deqgXr16qFq1KhwcHJCcnIxbt25h+fLlePjwIUaOHIkdO3agcuXKYp6IiAjxaysrK7XlFi5cWPw6MjJSDGYiIyNV7mvKGxUVJUmd2cEeIyIiIgkIadI88suiRYvQuXNnlC1bFqamprC0tISbm5sYDCUmJuLXX39VypOUlCR+/eFcH4XMw2QJCQni14mJiVnmy5w3cz5t6swO9hgRERFJQIoVZUDe9QjllomJCcaPH4+hQ4fi2rVriIyMFHtkMgcgycnJajd/zBzIZF46r0irGBZTR5E3cz5t6swO9hgRERFRlmrWrAkgfUPGoKAg8XrmIavMQ1yZKYbMPkxvaWmpcl9TXkVabevMDgZGREREEhAEaR4FUeYhq9TUVPFrR0dH8V5gYKDavIrrRkZGcHBwEK87OzsDAAICAjTWq8irSKttndnBwIiIiEgCBWWDx7zw5MkT8etixYqJXxsYGKBKlSoAgJs3b6rNq7hetWpVpWXz1atXB5C+pD7z0JdCUlIS/vnnHwBQ2vxRmzqzg4ERERGRBHQ5MFq3bh2A9LPM7O3tle61bt0aALB//36V+UJJSUnYt28fAKBNmzZK9+rWrQsrKyvExcXh0KFDKnV6eXkhLi4O1tbWKvsV5bbO7GBgRERE9IXbsGEDtm7divfv3ytdf//+PX766SecOHECAPDdd9+p5O3RoweKFi2KgIAA/Pzzz+Jqs8TERPz8888IDAyEnZ0dvvnmG6V8hoaGGD58OADgf//7H3x9fcV7vr6+4gq4ESNGwMBAea1YbuvMDpkgFNQRzawZm2R/TwKiL0lqmo5sv0skoZSkkDyvw++rlpKUU/ruKa3yv3r1Cp07dxa/T0pKQlxcHAwMDJR2rx4yZAiGDh0KAJg/fz62bNkCmUwGR0dHWFtbIyEhAS9evEBKSgr09PQwceJEMf2Hbt26hSFDhogn3Ts5OSE4OBiRkZEwMzODp6enOHSWWVpaGsaNG4eTJ08CSO+RAoBnz54BSO/xWbp0KfT0VPtxclvnx3C5PhERkQQKyjBYamqq2tVaKSkpStcz7+/Tvn17AMC9e/fw8uVLPH78GPr6+nByckKdOnXw7bffomLFihrrrFWrFg4ePIhVq1bh8uXLePLkCYoUKYKuXbti1KhRGjdY1NPTw/Lly7Fr1y7s3r0bz58/B5A+N6h79+745ptvIJOpf11zW+fHsMeISMewx4hI1afoMXpRtZUk5ZT556Qk5VDusMeIiIhIAgXhnDPSHgMjIiIiCeTncR4kHa5KIyIiIsrAHiMiIiIJpHEoTScwMCIiIpIA5xjpBg6lEREREWVgjxEREZEECso+RqQdBkZEREQS+Dx3BaQPMTAiIiKSAHuMdAPnGBERERFlYI8RERGRBLhcXzcwMCIiIpIAl+vrBg6lEREREWVgjxEREZEEuCpNNzAwIiIikgDnGOkGDqURERERZWCPERERkQQ4+Vo3MDAiIiKSAOcY6QYOpRERERFlYI8RERGRBDj5Wjd8toGRod5n23SiPBUTfCa/m0D0ReIcI93A6IKIiEgC7DHSDZxjRERERJSBPUZEREQS4KI03cDAiIiISAIcStMNHEojIiIiysAeIyIiIglwVZpuYGBEREQkgbT8bgBJgkNpRERERBnYY0RERCQBARxK0wUMjIiIiCSQxvX6OoFDaUREREQZ2GNEREQkgTQOpekEBkZEREQS4Bwj3cDAiIiISAJcrq8bOMeIiIiIKAN7jIiIiCTAoTTdwMCIiIhIAhxK0w0cSiMiIiLKwB4jIiIiCbDHSDcwMCIiIpIA5xjpBg6lEREREWVgjxEREZEE0thhpBMYGBEREUmAR4LoBg6lEREREWVgjxEREZEEhPxuAEmCgREREZEEuFxfNzAwIiIikkCajHOMdAHnGBERERFlYI8RERGRBDjHSDcwMCIiIpIA5xjpBg6lEREREWVgjxEREZEEuPO1bmBgREREJAHufK0bOJRGRERElIE9RkRERBLgqjTdwMCIiIhIApxjpBsYGBEREemQsLAwXL58Gffv38c///yDR48eITExEXXq1MHWrVuzzJucnIzNmzfDy8sLgYGBMDQ0hIuLC/r27YtWrVplmffhw4f4888/cePGDURFRcHOzg5ubm4YNWoUrK2tC1SdWZEJgvBZ9v6Zm5XO7yYQFUjvA8/kdxOIChxD2zJ5Xscmxz6SlDMg5C/t2rFpExYuXKhy/WOBUWJiIgYOHIhbt25BX18f5cqVQ3x8PAIDAwEAQ4cOxeTJk9XmPXnyJCZOnIjk5GTY2NigWLFi8PPzQ1xcHIoWLYodO3agRIkSBaLOj+HkayIiIgkIEj20ZW5ujgYNGmD48OFYuXIlRo0ala18v/76K27dugUnJyccPnwYXl5eOHXqFFatWgUjIyOsW7cO3t7eKvlCQ0MxdepUJCcnY9SoUbhw4QL27duHCxcuoHHjxggLC8P48eOhrh8mP+r8GAZGREREEkiTSfPQ1tdffw1PT09MnDgRLVu2hI2NzUfzvH37Fjt37gQAzJ8/H2XK/NfD5u7ujiFDhgAAVq5cqZJ3/fr1iI+PR+3atTFu3DgYGKTP0rGwsMDixYthYWGB+/fv4+zZs/leZ3YwMCIiIvrCeXt7Izk5Gc7OzqhXr57K/Z49ewIAHjx4IA5zKZw4cQIA0L17d5V8hQsXRps2bQAAx44dy/c6s4OBERERkQTSJHrkhzt37gAAatWqpfa+vb09nJyclNICwKtXrxAaGgoAqF27ttq8rq6uAIC7d+/me53ZwcCIiIhIAp9zYOTv7w8AKFmypMY0int+fn4q+QwNDVGsWDG1+RQToIOCgpCcnJyvdWYHl+sTEREVIO7u7lneP3NG+pWnkZGRANKHoTRR3IuKihKvRUREiPdkMvUTpKysrAAAaWlpiImJQZEiRfKtzuxgYERERCQB4TPe4DExMRFAei+MJkZGRgCAhISEXOXLnD6/6swOBkZEREQSkGoYLC96hD7G2NgYALIcdkpKSgIAmJiY5Cpf5vT5VWd2cI4RERHRF87S0hLAf8Nb6ijuKdIC/w11RUZGatwzSDH0paenB3Nz83ytMzsYGBEREUngc5587ezsDAAICAjQmEaxZF6RNvPXycnJePXqldp8QUFBAAAnJyel4a/8qDM7GBgRERFJoKDsfJ0b1atXBwDcvn1b7f3Q0FAEBwcrpQUABwcH2NnZAQBu3rypNq/ieuZ8+VVndjAwIiIi+sK5u7vD0NAQ/v7+uHr1qsp9xQ7VlSpVQqlSpZTutW7dGgCwa9culXyRkZE4fvw4AIibLuZnndnBwIiIiEgCBeVIkNywtbVFjx49AAA//PADXrx4Id7z9vbG+vXrAQCjR49WyTt48GCYmJjgxo0bWLZsGVJTUwEA0dHRmDRpEqKjo1GpUiU0b9483+vMDpmQmxPWCgBzs9L53QSiAul94Kdf0UJU0Bnalvl4Ii0tLdlHknImBP6lVf5Xr16hc+fO4vdJSUmIi4uDgYGB0kTkIUOGYOjQoeL3CQkJGDBgAHx9faGvr4/y5csjLi5OnOczaNAgTJs2TW2dx48fx6RJk5CSkqJy0r2trS22b9+u0uuTX3V+jKTL9UNDQ3Hz5k28fv0a8fHxGDNmjJTFExERFVj5NXH6Q6mpqeKqrMxSUlKUrmfeGwhIXxK/ZcsWbNq0CYcOHYK/vz8MDQ1Rp04d9OnTRxy+UqdNmzYoUaIE1q5di5s3b+LJkyews7ND165dMWrUKI0H2eZHnR8jSY9RdHQ05s6diyNHjiAt7b+3xqNHj8Svx40bh1OnTmHfvn1wcXHRtkr2GBFpwB4jIlWfosdosUQ9RpO07DEi7Wg9xyghIQH9+/fHoUOHYGxsjDp16qjdevubb75BWloaTp8+rW2VREREBc7nvCqN/qN1YLRlyxY8fPgQNWrUwPHjx7F582al/QYU6tatC0NDQ1y6dEnbKomIiAqcz3nyNf1H68Do6NGjMDAwwG+//SbuK6COoaEhSpYsqXRCLhEREVFBonVgFBAQACcnJzg4OHw0rYWFBWJjY7WtkoiIqMD5nHe+pv9IsipNX18/W+kiIyNRqFAhKaokIiIqUDg/SDdo3WPk5OSEoKAgxMXFZZkuLCwMAQEBKF2aq8mIiIioYNI6MHJzc0NycjJWrVqVZbrFixdDEAS4u7trWyUREVGBkwZBkgflL62H0gYOHIjdu3djw4YNePfuHbp37y5uzR0REYEnT57A09MTZ8+eRfHixdGrVy+tG01ERFTQcH6QbpBkg8d79+5h5MiRePfuHWQy1bWGgiDA1tYW69evl2RzR4AbPBJpwg0eiVR9ig0e55bqLUk5MwO2SVIO5Y4kh8hWq1YNhw4dwuDBg+Hk5ARBEMSHvb09BgwYgIMHD0oWFBERERU03OBRN+TJIbLx8fGIiopCoUKFlA6skxJ7jIjUY48RkapP0WM0S6Ieo1nsMcpXkh4iq2BqagpTU9O8KJqIiKhA4q7VukHrobRu3bphy5YtePfunRTtISIiIso3WvcYPXjwAA8fPsT//vc/NGjQAB4eHmjRogVMTEykaB8REdFngUvtdYPWgdG8efPg5eWFmzdv4sKFC7h48SJMTU3RqlUrdOzYEQ0aNFC7Uo2IiEiXMCzSDZJNvg4NDcWhQ4fg5eWFJ0+epBcuk8HW1hYdOnSAh4cHKlasKEVVADj5mkgTTr4mUvUpJl//4PytJOXM998uSTmUO3myKu3p06c4ePAgjhw5glevXqVXJJOhbNmy8PDwwLBhw7Sug4ERkXoMjIhUfYrAaLpEgdFCBkb5Kk8Co8yuXbuGw4cP48SJE4iKioJMJsOjR4+0LpeBEZF6DIyIVH2KwGiaszQnO/ziv0OScih3JNngMSuVK1dG9erVUa5cubyuioiIiEgrebKPUUpKCi5cuAAvLy+cO3cOiYmJEAQBhoaGcHNzy4sqiYiI8hUnX+sGSQOj27dvw8vLC8ePH0dkZCQEQYBMJkPNmjXh4eGBtm3bwtLSUsoqiYiICgQeIqsbtA6MXrx4AS8vLxw+fBghISFQTFkqXbo0PDw80LFjRzg5OWndUCIiIqK8pnVg1K5dO8hkMgiCABsbG7Rr1w4eHh6oWrWqFO0jIiL6LHCDR92gdWBkYmICd3d3eHh4oFGjRtDX15eiXURERJ8VhkW6QevA6MqVKzAzM5OiLURERJ8tzjHSDVov12dQRERERLoiT5brExERfWkEDqbphBwFRoqzzsqUKYMjR44oXcsumUyGhw8f5igP5YypqQkaNa6LGjWqonr1yqheoypKlnQEACyY/zsWzF+mMW+jRnXh3qIxatSoCufSJWBjYw1zczNEvI/Eo0dPccjrJDw9dyAhIVFt/jVrf0Wfvl9/tI2FLcohNTVV5fqDRxdRqlTWqxivXLmBVi26f7QO+rJEREbh7KWruHrzDh49eYZXr98gJTUV1laFUdlFDo+27mjRtKHavAeOnMKPC5Z8tI51vy9A/do1VK6fu3QVN+78g4ePn+FV6Bu8j4hEYlIyihS2RIXyZdC6eWN0bO0OAwPNczCTkpKw++AxHPe+gOd+gUhITIStdRHUc62B/j27oGzpUtl6Ha7fvocDR07i9r0HePvuPYyMDGFrUwRVK1ZA2xZN0aiea7bKoZzjUJpuyFFgpFiKn5aWpnItp2VQ3nF1/Qr7D2zKVd5xE4aibVt38fuYmFgkJiahqJ0titrZoknT+hg1ZiC6dBqAZ8/8NJYTH5+AqKhojfc/9j6IjIzSGHyFh0dk/SToi9Ss47dIyRRsGxsZwcDAAKFh7xAa5gPviz5oXM8VS+b/AFMTE7Vl6OnpoYhVYY11GBkaqr3++5pNeOYXIH5fyMwU+np6CHsXjrB34bh09SZ27D2EVb/Nga11EZX8b9+FY+Tkn/DoyXMAgIGBAcxMTfDy9RvsO3wCh096Y+70CWjfSvMGucnJyfhp0TIcOv7fkTAW5oUQn5CAF/5BeOEfhOiYWAZGRB+Ro8Do8ePH2bpG+S88PAJ379zHnTsPcPfOfSz630wUK2b30XxnvS/jzKmLuOJzAy+eByAmJhYAYG1the7dO2HOvGkoXbokduxcgzq122gMcPbuOYwRw6fkuv1Tp8zBtr/25jo/fXlSUlNRtVIFdGrXAg3r1EIJx+IAgJBXoVi7aQf2HT6Bi1dvYvb/VmDRT+rfm8XsbHFy7+Yc193SrRH6dO+EGlUrwdGhGEyMjQEAb8LeYe+h41jtuR0P/32GH+Ytxtol85TyCoKA8T/Mx6Mnz2FibIzvx49Ax9bNYWxshLC34Vi6eiO8jp/BD/OXwLmkEyq7lFepXxAETPxxAc5eugprq8IYO6wfWrk1RmFLCwiCgLfv3uPqrTuIzOLDCmmPy/V1A+cY6aDLl2+gpJNyd//sudOylXfVH55qr4eHR2DNms1ITErCipULULGSHHXr1sTVq7e0bi+RFDYuX4Q6tb5Sue5Y3B5zpo+Hvr4+dh88isMnvDFu+AAUty8qWd2jB/dRe92uqA1GDuqNxKRkrN/6Ny5fu4XXb8JQzO6/us9fuY47/6RPLxg3YgC+9mgj3itqa40FMycjICgEdx88xpJVG7Bh+SKVenYdOIqzl67C0sIcf61dgpJODuI9mUyGorbW6Ni6uVRPlzRgWKQbtF6VduDAAVy8eDFbaS9duoQDBw5oWyV9ROahTqldv+4rfu3oWCzP6iHKKXVBUWZdO7YSv37w+EleN0fJV5VdxK/fhL1TunfhynUA6XMDe3btoDb/gG/T5+1du3UXr16/UbqXmpqKP7fsBACMHNRbKSgiopzTOjD6/vvvsXbt2mylXbt2LaZPn65tlZSPGjasLX79wi8wH1tClDPGRkbi13n54UGdW3fvA0jvvXFyUP5AoQh0Sjo6wNBAfSd+GecS4teXr99Wunft1l2EvnkLAOwVymdpECR5UP6SZCiNE6p1m4mJMRwdi6NL13b4fvp3AIBLF6/B9/Y/GvM0c2sA37veKFHCAUlJSQgKDMG5c1fw59qteP7c/6N1jhs3FD/PmgxbW2vExMTh8eOnOH7MGxs3bEdERJRUT42+IDdu3xO/Ll+mtNo07yMi0X3QWPgFBiMtNQ1Fba3xVZWK6NaxDerUrJaj+uLi4hHyOhRex85g8859ANIDF+siVmrTZxWsZb739IW/0r3b9x4ASB8ytCpsiYNHT2HXwWN49sIfaYIAp+LF0KRBHfTv2UVj3SQNrkrTDZ90jlFYWBhMNKwGoYLFzt4WL/xuqL135MhpjBg2Ocv8Tk4OSElJQVRUDCwtzVG5igsqV3HBkKG9MW3qXKxfty3L/JUqV0B8fAJiY+NhbW2FBg1qo0GD2hg1eiD6fDuKc5soR6KiY7B+6y4AQK2vqqC0hi0h4hMS8fDfZ7C0MEd8SgKCX75G8MvXOHLyLDq3b4lZU8dlueT+7v1H6D18osp1fX09eLRtiR8mjlK551DcHgAQGPwSiYlJMDY2UkmTORgKe6s8FBcQFAIAsCpsick/LcTxMxcAAJYW5khKSMDTF/54+sIfB46ewqpfZ6udvE1E/8lxYPTy5UuEhIQoXYuOjsaNG+r/iAJAQkICbty4AX9/f1SqVCnnraRPLi01DaGhYQAAS0sLmJqmB7T79h7BvLlL8P59pNp8d+88wO3b93DsqDdCQl4hLS0NpqYmaNmqKebO+x5lyzrj92XzEPbmHQ4ePK6S/8jhU/C5chMXL17F27fhAAAbmyLo0bMzZv40EcWK2WHPvo1o1KAD/P2D8ujZky5JS0vD9Lm/IuxdOIyNjDBDTXBS1NYaIwf1RoumDVG6pCOMjIyQmpqKew//xR/r/8LVm744cOQUzExM1OZXMDQ0hE3Gcvyo6GgkJ6cAAL7p1A6De38jrlbLrHH92vh7/xEkJiVh0869GN6/l9L91NRUbNi6W/w+JjZO6X5UdAwA4NGT53jw+CnauDfBpFGDUbyYHZJTUuB9wQez/7cc78Lf47vvZ8Nr258oVIgnFuQFbvCoG2RCDsfBVq5ciT/++EP8XhAEyGSybOUVBAE///wzevXq9fHEH2Fupr4rnNRTbJz4sQ0eNXFwLIYhQ3pj7HdDoK+vh0kTZ8Fz444clWFtbYXzFw+idOmSCAgIRuWKjXOU37V2dZw6vQuGhobYvm0fhg2dlKP8X4r3gWc+nugLsmDJKmzfewgAMGf6eHTt0DpH+dPS0jB+xjx4X/SBnp4eDm3/E6VKOGYrX/DL19j69wH8feAITIyN8cvPU+HWuJ5SOkEQ0HvYBNx7+C8M9PUxanAfdGnfClZWlnjuF4jlf27GhSvXYWBggJSUFDSq54o1i+eK+YeOnwGfG+mLIirKy+LvDcuhp6c8ffTU2UuY8ON8AMDUscPQr2eXHL0GusDQtkye1zHI+eOb22bHRv89kpRDuZPjydcWFhYoXry4+JDJZDA0NFS6lvnh4OCAMmXKoGnTpvjtt98kCYro03sZ8hpzZi/G4EHjYWRkhN+XzUWVqjnb9Tw8PAK//boKAFCqlBO+ql45R/lv3riDvXvSd1xv175FjvLSl+nXlevEoGjad8NyHBQB6Zs+Th4zBEB6sHPu8rVs5yvp5IAfJo3CpNGDERcfj2mz/4ewjJ5QBZlMht8XzESFcmWQkpqK5X9uhlun3qjRtCO+HjAaF65cR6+uHVGhXPqHQUsLc6X8hTKdV9m/Z1eVoAhI32dJsVrtyo3bKvdJGoJE/1H+yvFQWv/+/dG/f3/xexcXF1StWhXbtmU9Z4R0g9fBEwgMDEHJko7o3787pkyenaP816/990u5tHNJ3L3zIGf5r99Gz16dYWVlCRubInj37n2O8tOXY/EfG7B5R/qk58ljhqBvj9z3kpR0ckARK0u8j4hCcMjrHOfv2aUDlq3dhLj4eBw9fQ79e3ZVum9X1AY71i3FgaOncebCFQQGvwQAlHUuia892qBZo3po2TX99+6HvVV2RW3Er8s4l9TYhjKlSiAw+CVevg7NcfuJviRaT75euHAhbGxsPp6QdMbLl69RsqQjypTN3tlNRJ/abyvXY9OO9J3TJ44ajAG9uuVre4yNjVDYwgJh78LFoOdDRkZG6N65Hbp3bqdy7937CLwKTV/WX72Kck+tvGz2phUoeiJkyN7UB8o5rkrTDVoHRl26fHlj1V8654w9VWKiY3Oct3ad/3bk9g/I+eTp2hkHeEZGRrG3iNT6deU6sado4qjBGNRb+3kfgcEv8T5jmwhHB/sc54+NjcP7iPQFC4XMTHOc/8iJswAA+6I2qFurutK9Bpn+Tb3wD0SlCuXUlvEiY7GCowM3Zs0rady6RidovcEj6Q59fc3LkBX69vtGPHPt4sWrOSq/SJHCmDwlfUVPUFBIjofRataqhm5ftwcAHDvqnaO89GXIHBRNHjMkW0HRx9afCIKAxX9sAJA+b6hpg7pK91NSUtVlU+K5fY94wG3tGjnbDykw+CXWbNoOABjSt4fKdgEOxexRN2PX780796l9PifPXkRQyCsAQLOGdVXuE9F/ctRj5O6efup6qVKlsHHjRqVr2SWTyXD69Okc5aGcs7KyVAp09PTSu89NTU1hY/Pf6d4JCYmIzVj+26CBK36cORGenjtx4YIPXmaaS1G2rDP69e+O78alT0J9/twff21VXjnRs1cXeHi0wt87D+LKlRsIyzj6wMTEGC1aNsGcud+jTJn04bcfZyxU+QX+2+JZkMlkOLD/KG7f/kdsl7W1FXr06Iwff5oAIyMjREVFY8H836V4mUiHZJ5TlJOVVy9fv8GkmQvQtUNr1K9dA04OxSCTyZCWloZ/Hv6LVRu34fK19H2zvunUVmUPpCMnvXHq3GV0atcSNb+qDJuMTRTT0tLw9EUAduz1wh6v9K0palSrpPZ0+4PHTiM5ORmN6rnCztYGenp6iI6Jxcmzl7Bs7SZERcegUT1XjUeGTB4zBN8Om4BHT55j6qxfMHHUYBS3L4rklBScveiDWb8sBwCULumEzu24cCGvsL9IN+QoMFLsX2ScaS+OD/c0+pjsLu0n7Vz2OYJSajaxmzBxOCZMHC5+/9fWPRgx/L+Txhs2qoOGjeoAQPoGizGxMCtkBrNM3f/37j1Ez+7DkJCQqFS2vr4ePDq1gUen9EMwY2JikZiQiMJWljDIOOogISER07+fh717j6i0zdy8EPr0/RrDR/RDWloaoqJikJaWBmtrKzHNq1eh6NdnDF68CMjFq0K66tXrN/Dcnh6o6+npYcO23diwbbfG9AN6dcXAb//rTbr/6AnuP0o/P83IyBCFzEwRGxePpKRkMU3n9i0xffxIlbIEATh3+Zq4Ws3U1AQmxkaIiY0T9zECgLq1vsKSeT+o/R346N9n+Gv3QQCAgYEBzExNEB0TK354aOXWCAtnTtH4+7OivBwW/TQVM+b+hmOnz+PY6fOwtDBHQmKi+BxKOjngj19nw8hIdQNJkgaP89ANOQqMzpxJ3x/FINN5Popr9Pnz9b2PwYMmoHGTeqhZsyrs7YvC2toKiYlJeP7cH3fvPMDBA8ewf/8xtccXXDh/FbN+/hV16tZEhQplYW1dBJaFLRAVFYMXLwJw/twVbNywHQEBwWrr37B+G0JDw1CnTg2Uci4Ba2srGBmZ4E3oWzx48BjHj5/F1i27ERUVndcvBX1mMs/tSEtLw7vwrOefxcUniF/bWFthxoSRuHv/ER4/fYH3EZGIio6BkZERHEsVQ/WqFdGlfSvUrKZ+e4kmDWpj1rRxuOF7D/8+fYF3798jKjoGxkbGcHIojioV5Wjr3gRNGtTR2J42LZoiITERd+8/RmjYWyQkJsLezhbVq6TX3bBurY++Bq2bN4ZL+TLYtGMffG7cxpu372BoYAB52dJo2awhenbpwI0dibIhxxs8FhTc4JFIPW7wSKTqU2zw2KtUZ0nK2RFwQJJyKHc+6VlpREREuorL9XVDngZGISEh8PLywps3b1C5cmV07ap+V1YiIiKigkDrwGjHjh1YunQpRo8erbQj9t27dzFo0CDExcWJ56kdPXoU69evZ3BEREQ6h5OvdYPWEcq5c+cQHR2Nli1bKl1ftGgRYmNj4eLigq+//hpWVlbw8fHBnj08HI+IiHQPz0rTDVoHRs+ePYO1tTUcHBzEay9fvoSvry9KliyJ3bt3Y968eVizZg0EQcChQ4e0rZKIiKjASZPoQflL68AoPDwc9vbKW+Rfu5a+n0fbtm3Fpf1fffUVHB0d8eTJE22rJCIiIsoTWs8xSklJQXJystI1X19fyGQy1KmjvG+Hra0tQkN5sjMREemez3T3G/qA1oFR0aJFERwcjLi4OJiZpW8edvHiRejr66NGjRpKaWNiYlC4cGFtqyQiIipwOPlaN2g9lFanTh0kJCRg7ty5+Pfff7Fs2TK8evUKtWrVEgMlAEhKSkJAQADs7Oy0rZKIiIgoT2jdYzR8+HCcOHECBw4cwIEDBwCkn1U0cqTymUIXL15ESkqKSi8SERGRLuDEad2gdWBUunRpbN26FX/88Qf8/f3h4OCAQYMGoV69ekrpDh8+DAsLCzRu3FjbKomIiAocLrXXDTwrjUjH8Kw0IlWf4qy0DiXbS1LO4cAjWuVfsWIFVq5cmWWaWbNmoVevXirXk5OTsXnzZnh5eSEwMBCGhoZwcXFB37590apVqyzLfPjwIf7880/cuHEDUVFRsLOzg5ubG0aNGgVra2uN+bSpMy/wrDQiIiIJFLTJ1zY2NihVqpTae0WLFlW5lpiYiIEDB+LWrVvQ19dHuXLlEB8fj+vXr+P69esYOnQoJk+erLa8kydPYuLEiUhOToaNjQ3Kly8PPz8/bN26FcePH8eOHTtQokQJSevMK5IGRi9fvsTly5fx4sULxMbGolChQihTpgwaNmyotAEkERGRriloAzBNmjTBokWLsp3+119/xa1bt+Dk5IR169ahTJn0XrYzZ85g/PjxWLduHWrWrInmzZsr5QsNDcXUqVORnJyMUaNGYfTo0TAwMEB0dDQmTJiAixcvYvz48dizZw9kMpkkdeYlSQKj2NhYzJs3D15eXkhLS59+pjgfDUifjN2pUyf88MMPKFSokBRVEhERkUTevn2LnTt3AgDmz58vBigA4O7ujiFDhmDVqlVYuXKlSpCyfv16xMfHo3bt2hg3bpx43cLCAosXL4a7uzvu37+Ps2fPKuXVps68pPVy/eTkZAwZMgQHDhxAamoqnJ2d0bJlS/Tu3RstW7aEs7MzUlNTsX//fgwdOlRlM0giIiJd8DkfCeLt7Y3k5GQ4OzurLJ4CgJ49ewIAHjx4gMDAQKV7J06cAAB0795dJV/hwoXRpk0bAMCxY8ckqzMvad1jtGPHDvj6+sLOzg5z5sxBs2bNVNKcP38eP//8M3x9fbFz50707dtX22qJiIgKlIK2Ku3x48eYNGkSwsLCUKhQIVSoUAHt27dH+fLlVdLeuXMHAFCrVi21Zdnb28PJyQnBwcG4c+cOSpYsCQB49eqVeKJF7dq11eZ1dXXF7t27cffuXUnqzGtaB0aHDx+GTCbD6tWrUblyZbVpmjZtij/++APdunXDoUOHGBgREZHOkWrytbu7e5b3z5zJ3srTR48e4dGjR+L33t7eWLNmDfr164dp06ZBX19fvOfv7w8AWQYfJUuWRHBwMPz8/FTyGRoaolixYmrzKSZdBwUFITk5GYaGhlrVmde0DoyeP3+O0qVLawyKFCpXrowyZcrg+fPn2lZJREREGtjZ2eG7775D48aN4eTkBHNzc/j5+WH79u3YuXMnNm/eDAMDA0ydOlXMExkZCQBZHtuluBcVFSVei4iIEO99OLFawcrKCgCQlpaGmJgYFClSRKs685okh8iamJhkK62JiQlSUlK0rZKIiKjAkWpVWnZ7hDTp0aOHyrUKFSpg9uzZcHJywm+//YbNmzfj22+/hZOTE4D0ZfMAxN4cdYyMjAAACQkJ4rWc5MucXps685rWk68dHBzw9OlThIeHZ5kuPDwcT58+RfHixbWtkoiIqMBJgyDJIy8NGjQIdnZ2SElJgbe3t3jd2NgYALJcIJWUlAQASp0hOcmXOb02deY1rQOjpk2bIjk5GZMnT9bY1RUVFYXJkycjJSUFbm5u2lZJREREuaCvr4+vvvoKABAQECBet7S0BPDf8JY6inuKtMB/Q12RkZEae8wUw216enowNzfXus68pvVQ2tChQ+Hl5QUfHx+4ubmhU6dOKF++PGxtbfH27Vs8ffoUBw8eRFxcHGxsbDB06FAp2k1ERFSgFLRVaZoohq4yT21xdnbG7du3lYKlDymWzDs7OyvlA9J7fV69eqV2M+egoCAAgJOTk9KwWW7rzGtaB0Y2NjbYuHEjxo4di6CgIOzYsUMljSAIKFmyJJYvX57leSlERESfq7QCtvO1Jk+fPgUApVVk1atXx759+3D79m21eUJDQxEcHCymVXBwcICdnR3evHmDmzdvwsPDQyXvzZs3VfJpU2de03ooDQBcXFxw5MgRLFq0CG3btoWLiwtKlCgBFxcXtG3bFosWLcLhw4fh4uIiRXVERESUC+fOnRMDo4YNG4rX3d3dYWhoCH9/f1y9elUln2KH6kqVKqmcv9a6dWsAwK5du1TyRUZG4vjx4wAgbvQoRZ15KVeBUWpqKjw9PdGlSxfUqFEDNWrUQM+ePfHu3Tv873//w/79+3Hy5Ens378fS5YsQefOnZVmpRMREekaQaKHNp4+fYqffvoJjx8/VrqelpaGw4cPY9KkSQAANzc3VKtWTbxva2srrmb74Ycf8OLFC/Get7c31q9fDwAYPXq0Sp2DBw+GiYkJbty4gWXLliE1NRUAEB0djUmTJiE6OhqVKlVSOdZDmzrzkkzI4fpCQRAwYsQIXLhwQWWilUwmQ6NGjbBu3TpJG6mOuVnpPK+D6HP0PlC7pb5EusjQtszHE2mpoaM053ldDvH+eCINHj16hM6dOwNI3z/IwcEB+vr6CAwMFCcyu7q6YvXq1SoTmhMSEjBgwAD4+vpCX18f5cuXR1xcnDjPZ9CgQZg2bZraeo8fP45JkyYhJSUFNjY2KFasGPz8/BAXFwdbW1ts375dba+PNnXmlRwHRvv378f06dMBAM2aNUPdunWRlpaG69ev4/z585DJZJg/fz66du2aJw1WYGBEpB4DIyJVnyIwqu8ozaprn5Czuc4bFRWFbdu24c6dO3j+/DnCw8ORlJSEwoULo1KlSujQoQM6dOigtOt1ZklJSdi0aRMOHTqEwMBAGBoaomLFiujTp484ZKbJgwcPsHbtWty8eRNRUVGws7ODm5sbRo0aBRsbG435tKkzL+Q4MBo4cCCuXr2KCRMmYNiwYUr31q5di6VLl6J+/frw9PSUtKEfYmBEpB4DIyJVX0pgRNrL8Ryjx48fw9zcHEOGDFG5N2TIEJibm6uMbRIREek6QRAkeVD+ynFgFBUVhVKlSkFPTzWrvr4+SpUqhejoaEkaR0RE9Ln4HHa+po/LcWCUmpqqtKX3h4yNjcUZ6URERESfE603eCQiIqLPZ+drylquAqNXr15h5cqVGu8B0HgfAMaMGZObaomIiAoszg/SDTlelebi4gKZTKbxvqK4rNI8evQoJ1WqxVVpROpxVRqRqk+xKs21eGNJyrn56qIk5VDu5LjHqHbt2nnRDiIios8aJ07rhhwHRlu3bs2LdhAREX3WOJSmGyQ5RJaIiIhIF3BVGhERkQQ4lKYbGBgRERFJgMv1dQMDIyIiIgmkcY6RTuAcIyIiIqIM7DEiIiKSAIfSdAMDIyIiIglwKE03cCiNiIiIKAN7jIiIiCTAoTTdwMCIiIhIAhxK0w0cSiMiIiLKwB4jIiIiCXAoTTcwMCIiIpIAh9J0A4fSiIiIiDKwx4iIiEgCHErTDQyMiIiIJCAIafndBJIAAyMiIiIJpLHHSCdwjhERERFRBvYYERERSUDgqjSdwMCIiIhIAhxK0w0cSiMiIiLKwB4jIiIiCXAoTTcwMCIiIpIAd77WDRxKIyIiIsrAHiMiIiIJcOdr3cDAiIiISAKcY6QbOJRGRERElIE9RkRERBLgPka6gYERERGRBDiUphsYGBEREUmAy/V1A+cYEREREWVgjxEREZEEOJSmGxgYERERSYCTr3UDh9KIiIiIMrDHiIiISAIcStMNDIyIiIgkwFVpuoFDaUREREQZ2GNEREQkAR4iqxsYGBEREUmAQ2m6gUNpRERERBnYY0RERCQBrkrTDQyMiIiIJMA5RrqBgREREZEE2GOkGzjHiIiIiCgDe4yIiIgkwB4j3cDAiIiISAIMi3QDh9KIiIiIMsgE9v0RERERAWCPEREREZGIgRERERFRBgZGRERERBkYGBERERFlYGBERERElIGBEREREVEGBkZEREREGRgYEREREWVgYERERESUgYERERERUQYGRkREREQZGBgRERERZWBgRAXGtWvXUKFCBfTt2ze/m0KUY8HBwahQoQKaN2+eq/wVKlRAhQoVJG4VEeWUQX434EvXt29fXL9+HQAwfPhwTJw4UW26s2fPYsSIEXB0dIS3t/enbKIkoqKisHnzZgDA2LFj87k19LnL/O9GQV9fH5aWlnBxcYGHhwc6d+4MPb2C8dlv06ZNiI6ORpcuXeDk5JTfzSGiLDAwKkC2bt2Kfv36wdbWNr+bIrmoqCisXLkSgObAyNTUFKVLl0bx4sU/ZdPoM1a8eHHx/ZKYmIiAgAD4+PjAx8cHx44dw6pVq2BoaPhJ2mJoaIjSpUvD3t5e5d6WLVsQEhKCOnXqaAyMSpcunddNJKJsYGBUQOjr6yMuLg5r1qzBjz/+mN/NyRfVqlXD8ePH87sZ9Bnp1q2bUqCdkpKC9evXY+nSpbhw4QK2bNmCwYMHf5K22Nvba/X+5XufqGAoGP3MBA8PDwDAzp078fLly3xuDdHnycDAACNGjECzZs0AAF5eXvnbICL67DAwKiCqVKmCli1bIjk5GStWrMhx/nPnzmHkyJFo2LAhqlSpgoYNG+K7777D3bt3NeZJTEzEypUr0bp1a1StWhWNGjXC9OnT8erVK+zbtw8VKlTA999/r5LvypUrmDdvHjp37ox69eqhSpUqaNq0KSZNmoQHDx6opP/+++/h7u4ufq+YZKp4BAcHA1A/+drHxwcVKlRAo0aNkJaWpvG5TJ06FRUqVMCiRYtU7j158gTTp09H8+bNUbVqVbi6uqJv3744dOiQxvLo81a3bl0AgL+/v3jt7du3WLRoEdq0aYNq1aqhZs2a+Oabb7B582YkJSWpLefFixf4/vvv0bx5c1SpUgU1atRA8+bNMWzYMGzfvl0prbrJ14p/RyEhIQCAfv36Kb339+3bJ6b9cPJ1bGwsqlevjgoVKuD58+can+uePXtQoUIFdO3aVeVeeHg4lixZgo4dO6JGjRqoXr06OnXqhLVr1yI+Pj6LV5Doy8XAqAAZP3489PT0cPDgQbx48SJbedLS0jB9+nQMHz4c3t7eSEtLQ/ny5ZGUlIQTJ06gV69e2LNnj0q++Ph49O/fHytWrIC/vz8cHR1hZ2eHQ4cOoUuXLmKwos6QIUOwdetWvH79GkWLFkW5cuUQHx+Pw4cPo0ePHjh9+rRSemdnZ1SpUkX8vmbNmkoPY2NjjXXVrVsXxYoVQ1hYGHx8fNSmiY+Px6lTpwD81/OmsGvXLnTp0gX79u1DREQEypQpA1NTU1y/fh2TJ0/G9OnTNdZNn68Pg+jHjx/Dw8MDnp6eCA4ORtmyZWFnZ4d79+5hwYIF6NevH2JiYpTy3L9/H926dcP+/fvx7t07ODs7w9nZGfHx8Th//jyWLFny0XbY2NigZs2aMDIyAgDI5XKl976NjY3GvIUKFRI/UGTV86W49+F7/969e2jfvj3Wrl0LPz8/FCtWDPb29nj69CmWLFmCb7/9FpGRkR99DkRfHIHyVZ8+fQS5XC5s3bpVEARBmDJliiCXy4XvvvtOKZ23t7cgl8sFNzc3pesrVqwQ5HK50KpVK+H69evi9bS0NGH79u1CxYoVhcqVKwtPnz5Vyrdo0SJBLpcLDRo0EO7evSteDwsLE/r06SNUrlxZkMvlwrRp01TavH37duHly5dK11JTU4Vjx44J1atXF2rXri3ExsYq3Q8KChLkcrkgl8s1vhZXr14V5HK50KdPH6Xrv/zyiyCXy4WpU6eqzefl5SXI5XKhXbt2Std9fHwEFxcXoXr16sLu3buF1NRU8d61a9eEhg0bCnK5XNi1a5fGNlHBpPh3s3z5crX3hw4dKsjlcsHDw0NISEgQWrRoIcjlcqFfv35CWFiYmO7evXtCo0aN1L6/RowYIcjlcmHKlClCdHS00r2goCDB09NT5Zq6f6OCIAhubm6CXC4Xrl69qvE5qfv3ce7cObHMtLQ0lTyvXr0SXFxchIoVKwpv3rwRr799+1Zo0KCBIJfLhUWLFim1PygoSOjRo4cgl8uFSZMmaWwP0ZeKPUYFzNixY2FoaIgTJ07g4cOHWaZ9//491q9fDyMjI6xatQq1a9cW78lkMvTq1Qt9+/ZFcnKyuFQeAGJiYrBz504AwJw5c1CtWjXxnq2tLZYtW5ZlL06vXr1UVo7p6emhTZs26NevHyIjI3Hu3LmcPO0sderUCQBw6tQpJCQkqNxXDIkp0iksXrwYaWlp+PHHH/H1118rLd2uU6cOZs+eDQBYv369ZG2l/JWSkoK1a9fi/PnzAIAOHTrg6NGjCAwMhJmZGZYtW6a06rNq1aqYM2cOgPSel8w9pX5+fgCAQYMGwdzcXKkeJycnDBgwII+fDdCwYUPY2NggJCQEt27dUrl/+PBhpKWloX79+ihatKh4fePGjXj79i06d+6MadOmKbXfyckJy5Ytg5mZGY4cOYLXr1/n+fMg+pwwMCpgSpQogW7dukEQBCxdujTLtOfPn0d8fDxcXV1RtmxZtWlatGgBAEp7vty6dQtxcXGwsbGBm5ubSh5ra2sxnyb//vsvli1bhjFjxqBv377o1asXevXqJa6s+VhQlxOKuRexsbE4c+aM0r3w8HBcvnwZMpkMHTt2FK+/fv0a9+7dg6mpqdL1zJo2bQpDQ0P4+/sjNDRUsvbSp7N3717xvde1a1fUrVtXHOJq1KgR+vfvjwsXLgBID5ytrKxUynBzc0Pp0qWRlpaGy5cvi9cdHBwAAMeOHYMgCHn/ZNQwMDBAu3btAKgfTtM0jHbixAkAQPfu3dWWa29vj6pVqyItLQ03btyQsslEnz0u1y+ARo0ahQMHDuDChQu4efMmXF1d1ab7999/AQBPnz5Fr1691KZJTEwEAKVPhYpPwnK5XOMGeBUrVsSBAwfU3vvll1/g6emZ5R+LiIgIjfdyw8PDA7/++iu8vLzQvn178fqRI0eQkpKCOnXqKPViPX78WPy6f//+Hy0/NDRU7f4zVLC9evUKr169ApC+5YWFhQXq1auHDh06oFu3btDT0xPf7+XLl9dYjlwuh5+fn9LcvkGDBuHKlStYs2YNDh48iMaNG6NGjRqoW7cuHB0d8/aJZeLh4YGtW7fixIkT+PHHH8X5Sk+ePMG///4LMzMztGzZUkwfFxeHoKAgAOn/VvX19dWWq5iYzh4jImUMjAoge3t7fPvtt9i4cSN+//13/PXXX2rTRUdHAwDCwsIQFhaWZZmZh6Di4uIApE/u1ETTvUOHDmHjxo0wNjbGxIkT0bhxYxQvXhympqaQyWTYs2cPfvjhB6SkpGTZnpzq2LEjFi9ejEuXLiE8PBzW1tZiewDVT8xRUVEA0idm3759+6Plc4XO52nMmDEf3Uk9NjYWALLcOFVxT5EWSO9x8vT0xKpVq3Dr1i3s2rULu3btAgDUqFED33//PapXr67lM/i4atWqoXTp0vDz88OFCxfE3lxFb1GLFi1gZmYmplf8XgCQ5apUBXXD00RfMgZGBdSwYcOwa9cu3LhxAxcvXlSbRvHL8Ntvv8XPP/+c7bIV+TL/EfiQpnuKXqRp06ahd+/eKvel7ilSsLe3R926dcUdjXv37o2AgADcvXsXxsbGaNOmjVJ6xXMsV64cjhw5kidtos+DIsh/+/atxjSKex9+IKhfvz7q16+PmJgY+Pr64saNGzh69Ch8fX0xcOBAeHl5oUSJEnnX+AweHh5YtmwZvLy80KJFCwiCgMOHD4v3MsscJPn4+IgfIogoezjHqIAqUqQIBg4cCAD4/fff1aZRDA08ffo0R2Urjh54+vSpxuGwzENRmSkmp2oa3tP0CVUmk+Wojeoo/gAoPikr/t+sWTNYWFgopZXL5QCAoKAgfiL+wmV+v2vy5MkTAECZMmXU3jc3N0fjxo0xceJEHD16FBUrVkRcXNwn20CyY8eOkMlkOHfuHKKjo3H9+nW8evUKRYsWRYMGDZTSWlhYoFixYgD+e15ElH0MjAqwAQMGoEiRIrh//z5Onjypct/NzQ3Gxsa4efMm7t27l+1ya9WqBTMzM7x9+1bt6rH379+r7EWkYGpqCgBqh+6eP3+Os2fPqs1nYmIifp3bQKVVq1YwMTHBnTt3EBgYqHE1GgCULFkSlSpVQmJiIrZt25ar+kg3NGnSBABw8OBBtT2a58+fh5+fH/T09NCwYcOPlmdkZITKlSsDAN68eZOtNije/7l975coUQI1a9ZEYmIiTpw4Ib7327dvr3YOkaIHddOmTbmqj+hLxsCoADM3N8ewYcMApP9S/5CtrS2GDRsGQRAwYsQInD59WqUHKCQkBBs2bMDu3buVyu3ZsycAYObMmUpB1bt37zB+/HiNv8AVPUVLlixR+qPw+PFjjBw5UuNkbmtra3GY4sNT0bPL3Nxc3PBu/vz5CAgIgJWVlfiH70NTp06Fvr4+lixZgvXr16vMI4qKisLBgwfxyy+/5Ko99Hlo164dSpYsibi4OEyYMAHv3r0T7z148AA//fQTgPQAO/MBr+PHj8fp06fFBQwKd+/eFVdHZt64NCslS5YEAK1WgCl6TPfu3SuuOvtwGE1h6NChsLW1xdmzZzFt2jSVAC4pKQmXLl3Cd999l+v2EOkqzjEq4Hr37o1NmzZpXE4+evRovH//Hn/99RdGjx6NwoULo0SJEhAEAW/evBF7dsaMGaOU77vvvoOvry98fX3xzTffiDtCP3nyBIUKFcLQoUOxatUqlUBn6NChOHr0KB48eAB3d3eULl0aSUlJ8PPzg729PUaNGqV2mwGZTIb27dtj165dGDFiBCpUqCDurbJkyRKlPViy4uHhgSNHjog9XW3bttV4enr9+vWxYMEC/PTTT/j111+xbNkylClTBkZGRggPD0dISAgEQUCdOnWyVTd9noyNjbFixQpxlVnTpk1Rvnx5JCQkiKvQatSooXJ486VLl3Ds2DEYGhqiZMmSMDc3x9u3b8XjPerVq4cuXbpkqw3t27fH2bNnsW7dOpw6dQpFixaFTCbD0KFDNQb2H2rbti3mzZsnLiYoW7as2HP1IVtbW6xbtw4jR47EgQMH4OXlhVKlSqFw4cKIjo5GYGAgkpOTs1Uv0ZeGgVEBZ2xsjFGjRmmcXC2TyTBz5ky0bdsWO3bswO3bt8V5BXZ2dmjbti1atGghHqqpYGpqik2bNmHdunU4dOgQgoKCYGVlhbZt22LcuHHiBnkfbmxnb2+Pv//+G0uXLsXly5fx4sUL2NnZ4dtvv8WYMWPEfOpMnz4dhQoVwpkzZ/D06VPxF/OHn8iz0qhRI1hbWyM8PByA5k/MCp07d0atWrWwZcsWXLlyBYGBgUhKSkKRIkXQoEEDNGvWDK1atcp2/fR5cnFxgZeXF9avX4+zZ8/i2bNnMDAwQNWqVdGhQwd8++234jJ4hV9++QUXL16Er68v3rx5g4CAABQqVAiurq7o0KEDvvnmGxgYZO9XaMeOHREVFYU9e/bAz89PXCqf3cAKAAoXLoxmzZppPP7mQ5UqVcLhw4exY8cOnDlzBi9evEBgYCDMzc1RqVIlNGzYUGmZPxGlkwn5tXMZFWhz5szBtm3bMGPGjGztA0RERKQLOMeIVMTExIhzGDStPiMiItJFDIy+YL///ru4Q65CSEgIRo8ejbdv36J69eoa5zAQERHpIg6lfcFq1KiBuLg4ODo6wtbWFlFRUfD394cgCChatCg2b96s8Qw2IiIiXcTA6Au2ZcsWnD17Fs+fP0dERARkMhkcHR3RtGlTDB48OMsjFIiIiHQRAyMiIiKiDJxjRERERJSBgRERERFRBgZGRERERBkYGBERERFlYGBERERElIGBEREREVEGBkZEREREGRgYEREREWVgYERERESU4f/86qmbZP0/PgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "C_M = confusion_matrix(df_cnn_prediction['reviews.rating_sentiment'], df_cnn_prediction['CNN_Predicted.rating_sentiment'])\n",
        "\n",
        "# Define labels\n",
        "labels = {0: \"Negative\", 1: \"Positive\"}\n",
        "\n",
        "# Plot confusion matrix\n",
        "sns.set(font_scale=1.5)\n",
        "ax = sns.heatmap(C_M, annot=True, fmt=\"d\", xticklabels=labels.values(), yticklabels=labels.values())\n",
        "ax.set_title(\"Confusion Matrix Sentiments\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLvvslAa0YXD",
        "outputId": "f581e46c-9811-4b24-f5b7-46b2ec94237f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9302202456586193\n",
            "0.7779629015269571\n",
            "0.9447513935368419\n",
            "0.9302202456586193\n",
            "0.936301525286603\n",
            "0.9404913172384582\n",
            "0.6065781151170145\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score,balanced_accuracy_score,confusion_matrix\n",
        "\n",
        "Accuracy_CNN_newdata = accuracy_score(df_cnn_prediction['reviews.rating_sentiment'], df_cnn_prediction['CNN_Predicted.rating_sentiment'])\n",
        "Balanced_accuracy_CNN_newdata = balanced_accuracy_score(df_cnn_prediction['reviews.rating_sentiment'], df_cnn_prediction['CNN_Predicted.rating_sentiment'])\n",
        "Precision_CNN_newdata = precision_score(df_cnn_prediction['reviews.rating_sentiment'], df_cnn_prediction['CNN_Predicted.rating_sentiment'],average = 'weighted')\n",
        "Recall_CNN_newdata = recall_score(df_cnn_prediction['reviews.rating_sentiment'], df_cnn_prediction['CNN_Predicted.rating_sentiment'],average = 'weighted')\n",
        "F1_score_CNN_newdata = f1_score(df_cnn_prediction['reviews.rating_sentiment'], df_cnn_prediction['CNN_Predicted.rating_sentiment'],average = 'weighted') #, average='macro'\n",
        "sensitivity_LSTM_newdata = Recall_LSTM_newdata\n",
        "specificity_LSTM_newdata =  C_M[0][0] / (C_M[0][0] + C_M[0][1]) \n",
        "\n",
        "\n",
        "print(Accuracy_CNN_newdata)\n",
        "print(Balanced_accuracy_CNN_newdata)\n",
        "print(Precision_CNN_newdata)\n",
        "print(Recall_CNN_newdata)\n",
        "print(F1_score_CNN_newdata)\n",
        "print(sensitivity_LSTM_newdata)\n",
        "print(specificity_LSTM_newdata)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AQu6Nhhat9d5"
      },
      "source": [
        "# Merging Prediction based on LSTM_CNN for EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYU3N7hFuEou"
      },
      "outputs": [],
      "source": [
        "df_cnn_LSTM = pd.merge(df_cnn_prediction,df_lstm_prediction,on='Srn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ib9rCf_vuuwW"
      },
      "outputs": [],
      "source": [
        "df_cnn_LSTM.to_csv(\"./drive/MyDrive/Prediction_LSTM_CNN.csv\", sep=',', encoding='UTF-8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFYPWbiAe32B"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
